import streamlit as st
import json
import os
from pathlib import Path
from typing import List, Dict, Any
import pandas as pd

# Import from the new directory structure
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.models.chat_manager import ChatManager
from src.models.vectorstore_manager import VectorstoreManager
from src.models.langgraph_agent import ChipChatAgent

# Page configuration
st.set_page_config(
    page_title="ChipChat - ë°ì´í„°ì‹œíŠ¸ ì±—ë´‡",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

def detect_environment():
    """í™˜ê²½ ê°ì§€ (ë¡œì»¬ vs Colab)"""
    try:
        from google.colab import drive
        return "colab"
    except ImportError:
        return "local"

def setup_paths():
    """í™˜ê²½ì— ë”°ë¥¸ ê²½ë¡œ ì„¤ì •"""
    env = detect_environment()
    
    if env == "colab":
        # Google Colab í™˜ê²½
        try:
            from google.colab import drive
            drive.mount('/content/drive')
        except:
            pass
        
        base_path = Path('/content/drive/MyDrive')
        return {
            'vectorstore_path': str(base_path / 'vectorstore'),
            'json_folder_path': str(base_path / 'prep_json'),
            'prompt_templates_path': str(base_path / 'prompt_templates'),
            'chipdb_path': str(base_path / 'prep_json' / 'chipDB.csv')
        }
    else:
        # ë¡œì»¬ í™˜ê²½
        base_path = Path.cwd()
        return {
            'vectorstore_path': str(base_path / 'vectorstore'),
            'json_folder_path': str(base_path / 'prep' / 'prep_json'),
            'prompt_templates_path': str(base_path / 'prompt_templates'),
            'chipdb_path': str(base_path / 'prep' / 'prep_json' / 'chipDB.csv')
        }

def load_api_keys():
    """API í‚¤ ë¡œë“œ"""
    api_keys = {}
    
    # Try environment variables first
    api_keys['openai'] = os.environ.get('OPENAI_API_KEY', '')
    api_keys['anthropic'] = os.environ.get('ANTHROPIC_API_KEY', '')
    api_keys['huggingface'] = os.environ.get('HF_TOKEN', '')
    
    # Try streamlit secrets
    if hasattr(st, 'secrets'):
        api_keys['openai'] = api_keys['openai'] or st.secrets.get("openai_api_key", "")
        api_keys['anthropic'] = api_keys['anthropic'] or st.secrets.get("anthropic_api_key", "")
        api_keys['huggingface'] = api_keys['huggingface'] or st.secrets.get("hf_token", "")
    
    return api_keys

@st.cache_resource
def initialize_managers():
    """ë§¤ë‹ˆì €ë“¤ ì´ˆê¸°í™” (ìºì‹œë¨)"""
    try:
        # Initialize with OpenAI as default
        chat_manager = ChatManager(provider="openai")
        vectorstore_manager = VectorstoreManager()
        return chat_manager, vectorstore_manager, None
    except Exception as e:
        return None, None, str(e)

@st.cache_resource
def load_vectorstore(_vectorstore_manager, vectorstore_path):
    """ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (ìºì‹œë¨)"""
    try:
        if Path(vectorstore_path).exists():
            return _vectorstore_manager.load_vectorstore(vectorstore_path), None
        else:
            # Try loading from JSON files and creating vectorstore
            json_folder = st.session_state.paths['json_folder_path']
            if Path(json_folder).exists():
                json_data = _vectorstore_manager.load_json_files(json_folder)
                if json_data:
                    vectorstore = _vectorstore_manager.create_vectorstore(json_data)
                    # Save for future use
                    Path(vectorstore_path).parent.mkdir(parents=True, exist_ok=True)
                    _vectorstore_manager.save_vectorstore(vectorstore, vectorstore_path)
                    return vectorstore, None
            
            return None, "ë²¡í„°ìŠ¤í† ì–´ë‚˜ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, str(e)

@st.cache_resource
def initialize_agent(_chat_manager, _vectorstore_manager, _vectorstore, chipdb_path):
    """ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ìºì‹œë¨)"""
    try:
        if not Path(chipdb_path).exists():
            return None, f"chipDB.csv not found at {chipdb_path}"
        
        agent = ChipChatAgent(
            csv_path=chipdb_path,
            vectorstore_manager=_vectorstore_manager,
            vectorstore=_vectorstore,
            llm_manager=_chat_manager.llm_manager
        )
        return agent, None
    except Exception as e:
        return None, str(e)

def main():
    st.title("ğŸ’¬ ChipChat - ë°ì´í„°ì‹œíŠ¸ ì±—ë´‡")
    st.markdown("**AI ì—ì´ì „íŠ¸ê°€ ìë™ìœ¼ë¡œ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤**")
    
    # Initialize session state
    if 'paths' not in st.session_state:
        st.session_state.paths = setup_paths()
    
    if 'api_keys' not in st.session_state:
        st.session_state.api_keys = load_api_keys()
    
    # Check API keys
    api_keys_available = any(st.session_state.api_keys.values())
    if not api_keys_available:
        st.error("ğŸš¨ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.markdown("""
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:
        1. **í™˜ê²½ ë³€ìˆ˜**: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `HF_TOKEN`
        2. **Streamlit Secrets**: `.streamlit/secrets.toml` íŒŒì¼
        3. **Colab**: ë…¸íŠ¸ë¶ì˜ 3ë‹¨ê³„ì—ì„œ API í‚¤ ì…ë ¥
        """)
        return
    
    # Initialize managers
    chat_manager, vectorstore_manager, init_error = initialize_managers()
    if init_error:
        st.error(f"ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
        return
    
    # Load vectorstore
    vectorstore, vs_error = load_vectorstore(vectorstore_manager, st.session_state.paths['vectorstore_path'])
    if vs_error:
        st.error(f"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {vs_error}")
        st.info("prep ëª¨ë“ˆì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì‹œíŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # Initialize agent
    agent, agent_error = initialize_agent(
        chat_manager, vectorstore_manager, vectorstore, 
        st.session_state.paths['chipdb_path']
    )
    if agent_error:
        st.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {agent_error}")
        st.info("chipDB.csv íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    
    # Sidebar configuration
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # LLM Provider selection
        provider = st.selectbox(
            "LLM ì œê³µì",
            ["openai", "claude"],
            help="ì‚¬ìš©í•  LLM ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # Model selection
        if provider == "openai":
            model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        else:
            model_options = ["claude-3-sonnet-20240229", "claude-3-haiku-20240307", "claude-3-opus-20240229"]
        
        model_name = st.selectbox("ëª¨ë¸", model_options)
        
        # Update chat manager if provider changed
        if hasattr(st.session_state, 'current_provider') and st.session_state.current_provider != (provider, model_name):
            try:
                chat_manager.switch_llm_provider(provider, model_name)
                st.session_state.current_provider = (provider, model_name)
                st.success(f"âœ… {provider} ({model_name})ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤")
            except Exception as e:
                st.error(f"LLM ì œê³µì ë³€ê²½ ì‹¤íŒ¨: {str(e)}")
        else:
            st.session_state.current_provider = (provider, model_name)
        
        # Mode selection
        mode = st.selectbox(
            "ëª¨ë“œ ì„ íƒ",
            ["ğŸ¤– AI Agent", "ğŸ’¬ Chat", "ğŸ” Retrieval Test", "ğŸ“Š Vectorstore Info"]
        )
        
        # Show agent info if agent mode selected
        if mode == "ğŸ¤– AI Agent" and agent:
            with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ ì •ë³´"):
                st.markdown("**ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ë¶„ë¥˜**")
                st.markdown("â€¢ ë¶€í’ˆ ëª©ë¡ ì§ˆë¬¸")
                st.markdown("â€¢ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ì§ˆë¬¸") 
                st.markdown("â€¢ PDF ì—…ë¡œë“œ ìš”ì²­")
                st.markdown("â€¢ ë³µí•© ì§ˆë¬¸")
        
        # Retrieval parameters (for non-agent modes)
        if mode != "ğŸ¤– AI Agent":
            st.subheader("ê²€ìƒ‰ ì„¤ì •")
            k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜", 1, 20, 5)
            
            if mode == "ğŸ” Retrieval Test":
                threshold = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.0, 1.0, 0.7, 0.05)
            
            # Filters
            st.subheader("í•„í„° ì„¤ì •")
            available_filters = chat_manager.get_available_filters(vectorstore)
            
            selected_filters = {}
            for filter_key, filter_values in available_filters.items():
                if filter_key in ['maker_pn', 'category', 'manufacturer', 'grade']:
                    selected_value = st.selectbox(
                        f"{filter_key}",
                        ["ì „ì²´"] + filter_values,
                        key=f"filter_{filter_key}"
                    )
                    if selected_value != "ì „ì²´":
                        selected_filters[filter_key] = selected_value
    
    # Main content based on mode
    if mode == "ğŸ¤– AI Agent":
        if agent:
            render_agent_mode(agent)
        else:
            st.error("ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. chipDB.csvë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    elif mode == "ğŸ’¬ Chat":
        render_chat_mode(chat_manager, vectorstore, k, selected_filters)
    elif mode == "ğŸ” Retrieval Test":
        render_retrieval_test_mode(chat_manager, vectorstore, k, threshold, selected_filters)
    elif mode == "ğŸ“Š Vectorstore Info":
        render_vectorstore_info_mode(vectorstore_manager, vectorstore)

def render_agent_mode(agent):
    """AI ì—ì´ì „íŠ¸ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ¤– AI Agent Mode")
    st.markdown("**ìŠ¤ë§ˆíŠ¸ ì—ì´ì „íŠ¸ê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìë™ìœ¼ë¡œ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤**")
    
    # Agent info
    with st.expander("ğŸ“‹ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ì„¤ëª…"):
        st.markdown(agent.get_agent_info())
    
    # Query examples
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ” ë¶€í’ˆ ê²€ìƒ‰ ì˜ˆì‹œ:**")
        if st.button("ì „ì•• ë³€í™˜ê¸° ì°¾ê¸°", key="example1"):
            st.session_state.example_query = "ì „ì•• ë³€í™˜ê¸° ê¸°ëŠ¥ì„ í•˜ëŠ” ëª¨ë“  ë¶€í’ˆë“¤ì„ ì•Œë ¤ì¤˜"
        if st.button("ë¡œì§ ê²Œì´íŠ¸ ì°¾ê¸°", key="example2"):
            st.session_state.example_query = "ë¡œì§ ê²Œì´íŠ¸ ê¸°ëŠ¥ ë¶€í’ˆë“¤ ë¦¬ìŠ¤íŠ¸ì—…í•´ì¤˜"
    
    with col2:
        st.markdown("**ğŸ“š ê¸°ìˆ  ì •ë³´ ì˜ˆì‹œ:**")
        if st.button("W25Q32JV íŠ¹ì„±", key="example3"):
            st.session_state.example_query = "W25Q32JVì˜ ì „ê¸°ì  íŠ¹ì„±ì€?"
        if st.button("LM324 ìŠ¤í™", key="example4"):
            st.session_state.example_query = "LM324ì˜ ë™ì‘ ì „ì••ê³¼ ì˜¨ë„ ë²”ìœ„ëŠ”?"
    
    with col3:
        st.markdown("**ğŸ”„ ë³µí•© ì§ˆë¬¸ ì˜ˆì‹œ:**")
        if st.button("ë©”ëª¨ë¦¬ ì¹© ì¶”ì²œ", key="example5"):
            st.session_state.example_query = "32Mbit í”Œë˜ì‹œ ë©”ëª¨ë¦¬ ì¹©ì„ ì°¾ê³  ìƒì„¸ ìŠ¤í™ë„ ì•Œë ¤ì¤˜"
        if st.button("íŒŒì›Œ ì»¨ë²„í„° ë¹„êµ", key="example6"):
            st.session_state.example_query = "3.3V íŒŒì›Œ ì»¨ë²„í„°ë“¤ì„ ì°¾ê³  ê°ê°ì˜ íŠ¹ì§•ì„ ë¹„êµí•´ì¤˜"
    
    # File upload for PDF processing
    st.markdown("### ğŸ“„ ìƒˆ ë°ì´í„°ì‹œíŠ¸ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "PDF ë°ì´í„°ì‹œíŠ¸ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['pdf'],
        help="ìƒˆë¡œìš´ ë¶€í’ˆì˜ ë°ì´í„°ì‹œíŠ¸ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ë©ë‹ˆë‹¤"
    )
    
    # Main query input
    st.markdown("### ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
    
    # Use example query if selected
    default_query = st.session_state.get('example_query', '')
    if default_query:
        del st.session_state.example_query
    
    user_query = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=default_query,
        placeholder="ì˜ˆ: ì „ì•• ë³€í™˜ê¸° ê¸°ëŠ¥ì„ í•˜ëŠ” ëª¨ë“  ë¶€í’ˆë“¤ì„ ì•Œë ¤ì¤˜",
        height=100
    )
    
    col1, col2 = st.columns([3, 1])
    with col1:
        process_query = st.button("ğŸš€ ì—ì´ì „íŠ¸ ì‹¤í–‰", type="primary")
    with col2:
        show_process = st.checkbox("ì²˜ë¦¬ ê³¼ì • í‘œì‹œ", value=False)
    
    # Process query or file upload
    if process_query and (user_query or uploaded_file):
        with st.spinner("ğŸ¤– ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬ ì¤‘..."):
            if show_process:
                st.markdown("**ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„:**")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                status_text.text("1/4 ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
                progress_bar.progress(25)
                
                status_text.text("2/4 ë„êµ¬ ì„ íƒ ì¤‘...")
                progress_bar.progress(50)
                
                status_text.text("3/4 ë°ì´í„° ê²€ìƒ‰ ì¤‘...")
                progress_bar.progress(75)
                
                status_text.text("4/4 ì‘ë‹µ ìƒì„± ì¤‘...")
                progress_bar.progress(100)
            
            # Process through agent
            response = agent.process_query(user_query, uploaded_file)
            
            if show_process:
                status_text.text("âœ… ì™„ë£Œ!")
        
        # Display response
        st.markdown("### ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ")
        st.markdown(response)
        
        # Add to chat history
        if 'agent_history' not in st.session_state:
            st.session_state.agent_history = []
        
        st.session_state.agent_history.append({
            'query': user_query or f"íŒŒì¼ ì—…ë¡œë“œ: {uploaded_file.name if uploaded_file else ''}",
            'response': response
        })
    
    # Show chat history
    if 'agent_history' in st.session_state and st.session_state.agent_history:
        st.markdown("### ğŸ’­ ëŒ€í™” ê¸°ë¡")
        for i, entry in enumerate(reversed(st.session_state.agent_history[-5:]), 1):
            with st.expander(f"ì§ˆë¬¸ {i}: {entry['query'][:50]}..."):
                st.markdown(f"**ì§ˆë¬¸:** {entry['query']}")
                st.markdown(f"**ì‘ë‹µ:** {entry['response']}")

def render_chat_mode(chat_manager, vectorstore, k, filters):
    """ì±„íŒ… ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ’¬ ì±„íŒ…")
    
    # Prompt template management
    templates_folder = Path(st.session_state.paths['prompt_templates_path'])
    templates_folder.mkdir(parents=True, exist_ok=True)
    
    # Load or create default template
    default_template = {
        "pre": "ë‹¹ì‹ ì€ ì „ì ë¶€í’ˆ ë°ì´í„°ì‹œíŠ¸ì— ëŒ€í•´ ì‘ë‹µí•˜ëŠ” ì „ë¬¸ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.",
        "post": "ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•˜ë‹¤ë©´ ê·¸ ì ì„ ëª…ì‹œí•˜ì„¸ìš”."
    }
    
    template_file = templates_folder / "default_template.json"
    if not template_file.exists():
        chat_manager.save_prompt_template(default_template, str(template_file))
    
    # Template selection
    template_files = list(templates_folder.glob("*.json"))
    template_names = [f.stem for f in template_files]
    
    if template_names:
        selected_template = st.selectbox("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿", template_names)
        template = chat_manager.load_prompt_template(str(templates_folder / f"{selected_template}.json"))
    else:
        template = default_template
    
    # Prompt customization
    with st.expander("ğŸ› ï¸ í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•"):
        pre_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì•ë¶€ë¶„)", template["pre"], height=100)
        post_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë’·ë¶€ë¶„)", template["post"], height=100)
    
    # Chat interface
    col1, col2 = st.columns([3, 1])
    
    with col1:
        user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: W25Q32JVì˜ ì „ê¸°ì  íŠ¹ì„±ì€?")
    
    with col2:
        include_metadata = st.checkbox("ë©”íƒ€ë°ì´í„° í¬í•¨", value=False)
    
    if user_input:
        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
            result = chat_manager.get_chat_response(
                query=user_input,
                vectorstore=vectorstore,
                pre_prompt=pre_prompt,
                post_prompt=post_prompt,
                k=k,
                filters=filters if filters else None,
                include_metadata=include_metadata
            )
        
        # Display response
        st.markdown("### ğŸ’¡ ë‹µë³€")
        st.markdown(result['response'])
        
        # Display metadata if requested
        if include_metadata and result.get('source_metadata'):
            st.markdown("### ğŸ“š ì°¸ì¡°ëœ ì†ŒìŠ¤")
            for i, metadata in enumerate(result['source_metadata']):
                with st.expander(f"ì†ŒìŠ¤ {i+1}: {metadata['component']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**íŒŒì¼ëª…**: {metadata['source']}")
                        st.write(f"**ì œì¡°ì‚¬**: {metadata['manufacturer']}")
                        st.write(f"**ì¹´í…Œê³ ë¦¬**: {metadata['category']}")
                    with col2:
                        st.write(f"**ë¶€í’ˆë²ˆí˜¸**: {metadata['maker_pn']}")
                        st.write(f"**Part Number**: {metadata['part_number']}")
        
        st.info(f"ğŸ“Š ì´ {result['sources_found']}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

def render_retrieval_test_mode(chat_manager, vectorstore, k, threshold, filters):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        test_query = st.text_area("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬", placeholder="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    with col2:
        st.metric("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", k)
        st.metric("ìœ ì‚¬ë„ ì„ê³„ê°’", f"{threshold:.2f}")
        if filters:
            st.write("**í™œì„± í•„í„°:**")
            for key, value in filters.items():
                st.write(f"â€¢ {key}: {value}")
    
    if test_query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            results = chat_manager.test_retrieval(
                query=test_query,
                vectorstore=vectorstore,
                k=k,
                threshold=threshold,
                filters=filters if filters else None
            )
        
        st.markdown("### ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")
        
        for i, result in enumerate(results):
            score_color = "ğŸŸ¢" if result['passes_threshold'] else "ğŸŸ¡"
            
            with st.expander(f"{score_color} ê²°ê³¼ {i+1} (ìœ ì‚¬ë„: {result['score']:.3f})"):
                st.markdown("**ë‚´ìš©:**")
                st.markdown(result['content'])
                
                st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                metadata_df = pd.DataFrame([result['metadata']]).T
                metadata_df.columns = ['ê°’']
                st.dataframe(metadata_df)

def render_vectorstore_info_mode(vectorstore_manager, vectorstore):
    """ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ“Š ë²¡í„°ìŠ¤í† ì–´ ì •ë³´")
    
    info = vectorstore_manager.get_vectorstore_info(vectorstore)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", info.get('total_documents', 0))
    
    with col2:
        st.metric("ì„ë² ë”© ëª¨ë¸", info.get('embedding_model', 'Unknown'))
    
    with col3:
        st.metric("ë””ë°”ì´ìŠ¤", info.get('device', 'Unknown'))
    
    # ChipDB info if available
    if Path(st.session_state.paths['chipdb_path']).exists():
        try:
            chipdb = pd.read_csv(st.session_state.paths['chipdb_path'])
            st.markdown("### ğŸ“Š ChipDB ì •ë³´")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ë¶€í’ˆ ìˆ˜", len(chipdb))
            with col2:
                st.metric("ì œì¡°ì‚¬ ìˆ˜", chipdb['maker_pn'].nunique())
            with col3:
                st.metric("ë“±ê¸‰ ì¢…ë¥˜", chipdb['grade'].nunique())
            
            # Show sample data
            st.markdown("### ğŸ” ChipDB ìƒ˜í”Œ ë°ì´í„°")
            st.dataframe(chipdb.head(10))
            
        except Exception as e:
            st.error(f"ChipDB ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # Available metadata keys
    if 'available_metadata_keys' in info:
        st.markdown("### ğŸ·ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° í‚¤")
        cols = st.columns(3)
        for i, key in enumerate(info['available_metadata_keys']):
            with cols[i % 3]:
                st.code(key)

if __name__ == "__main__":
    main() 
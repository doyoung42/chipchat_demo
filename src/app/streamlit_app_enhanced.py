import streamlit as st
import json
import os
import time
from pathlib import Path
from typing import List, Dict, Any
import pandas as pd

# Import from the new directory structure
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.models.chat_manager import ChatManager
from src.models.vectorstore_manager import VectorstoreManager
from src.models.langgraph_agent import ChipChatAgent

# Page configuration
st.set_page_config(
    page_title="ChipChat Enhanced - ê°œì„ ëœ ë²„ì „",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

def detect_environment():
    """í™˜ê²½ ê°ì§€ (ë¡œì»¬ vs Colab)"""
    try:
        from google.colab import drive
        return "colab"
    except ImportError:
        return "local"

def setup_paths():
    """í™˜ê²½ì— ë”°ë¥¸ ê²½ë¡œ ì„¤ì •"""
    env = detect_environment()
    
    if env == "colab":
        # Google Colab í™˜ê²½
        try:
            from google.colab import drive
            drive.mount('/content/drive')
        except:
            pass
        
        base_path = Path('/content/drive/MyDrive')
        return {
            'vectorstore_path': str(base_path / 'vectorstore'),
            'json_folder_path': str(base_path / 'prep_json'),
            'prompt_templates_path': str(base_path / 'prompt_templates'),
            'chipdb_path': str(base_path / 'prep_json' / 'chipDB.csv')
        }
    else:
        # ë¡œì»¬ í™˜ê²½
        base_path = Path.cwd()
        return {
            'vectorstore_path': str(base_path / 'vectorstore'),
            'json_folder_path': str(base_path / 'prep' / 'prep_json'),
            'prompt_templates_path': str(base_path / 'prompt_templates'),
            'chipdb_path': str(base_path / 'prep' / 'prep_json' / 'chipDB.csv')
        }

def load_api_keys():
    """API í‚¤ ë¡œë“œ"""
    api_keys = {}
    
    # Try environment variables first
    api_keys['openai'] = os.environ.get('OPENAI_API_KEY', '')
    api_keys['anthropic'] = os.environ.get('ANTHROPIC_API_KEY', '')
    api_keys['huggingface'] = os.environ.get('HF_TOKEN', '')
    
    # Try streamlit secrets
    if hasattr(st, 'secrets'):
        api_keys['openai'] = api_keys['openai'] or st.secrets.get("openai_api_key", "")
        api_keys['anthropic'] = api_keys['anthropic'] or st.secrets.get("anthropic_api_key", "")
        api_keys['huggingface'] = api_keys['huggingface'] or st.secrets.get("hf_token", "")
    
    return api_keys

@st.cache_resource
def initialize_managers_with_progress():
    """ë§¤ë‹ˆì €ë“¤ ì´ˆê¸°í™” (ì§„í–‰ ìƒí™© í‘œì‹œ)"""
    progress_container = st.empty()
    status_container = st.empty()
    
    try:
        # 1. ChatManager ì´ˆê¸°í™”
        progress_container.progress(10)
        status_container.info("ğŸ”„ 1/5 ChatManager ì´ˆê¸°í™” ì¤‘...")
        time.sleep(0.5)  # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ëŒ€ê¸°
        
        from src.models.chat_manager import ChatManager
        chat_manager = ChatManager(provider="openai")
        
        progress_container.progress(30)
        status_container.success("âœ… 1/5 ChatManager ì´ˆê¸°í™” ì™„ë£Œ")
        time.sleep(0.5)
        
        # 2. VectorstoreManager ì´ˆê¸°í™” (ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë¶€ë¶„)
        progress_container.progress(40)
        status_container.info("ğŸ”„ 2/5 VectorstoreManager ì´ˆê¸°í™” ì¤‘... (ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘, ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        start_time = time.time()
        from src.models.vectorstore_manager import VectorstoreManager
        vectorstore_manager = VectorstoreManager()
        elapsed = time.time() - start_time
        
        progress_container.progress(80)
        status_container.success(f"âœ… 2/5 VectorstoreManager ì´ˆê¸°í™” ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")
        time.sleep(0.5)
        
        progress_container.progress(100)
        status_container.success("âœ… ëª¨ë“  ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ!")
        
        # ìƒíƒœ í‘œì‹œ ì œê±°
        time.sleep(2)
        progress_container.empty()
        status_container.empty()
        
        return chat_manager, vectorstore_manager, None
        
    except Exception as e:
        progress_container.empty()
        status_container.error(f"âŒ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None, str(e)

@st.cache_resource
def load_vectorstore_with_progress(_vectorstore_manager, vectorstore_path):
    """ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (ì§„í–‰ ìƒí™© í‘œì‹œ)"""
    progress_container = st.empty()
    status_container = st.empty()
    
    try:
        progress_container.progress(20)
        status_container.info("ğŸ”„ 3/5 ë²¡í„°ìŠ¤í† ì–´ í™•ì¸ ì¤‘...")
        
        if Path(vectorstore_path).exists():
            progress_container.progress(50)
            status_container.info("ğŸ”„ 3/5 ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘...")
            
            vectorstore = _vectorstore_manager.load_vectorstore(vectorstore_path)
            
            progress_container.progress(100)
            status_container.success("âœ… 3/5 ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ!")
            
        else:
            # Try loading from JSON files and creating vectorstore
            progress_container.progress(30)
            status_container.info("ğŸ”„ 3/5 JSON íŒŒì¼ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
            
            json_folder = st.session_state.paths['json_folder_path']
            if Path(json_folder).exists():
                json_data = _vectorstore_manager.load_json_files(json_folder)
                if json_data:
                    progress_container.progress(70)
                    status_container.info("ğŸ”„ 3/5 ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
                    
                    vectorstore = _vectorstore_manager.create_vectorstore(json_data)
                    # Save for future use
                    Path(vectorstore_path).parent.mkdir(parents=True, exist_ok=True)
                    _vectorstore_manager.save_vectorstore(vectorstore, vectorstore_path)
                    
                    progress_container.progress(100)
                    status_container.success("âœ… 3/5 ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
                else:
                    raise Exception("JSON ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            else:
                raise Exception("JSON í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        time.sleep(1)
        progress_container.empty()
        status_container.empty()
        
        return vectorstore, None
        
    except Exception as e:
        progress_container.empty()
        status_container.error(f"âŒ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, str(e)

@st.cache_resource
def initialize_agent_with_progress(_chat_manager, _vectorstore_manager, _vectorstore, chipdb_path):
    """ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì§„í–‰ ìƒí™© í‘œì‹œ)"""
    progress_container = st.empty()
    status_container = st.empty()
    
    try:
        progress_container.progress(20)
        status_container.info("ğŸ”„ 4/5 ChipDB.csv í™•ì¸ ì¤‘...")
        
        if not Path(chipdb_path).exists():
            raise Exception(f"chipDB.csv not found at {chipdb_path}")
        
        progress_container.progress(50)
        status_container.info("ğŸ”„ 4/5 LangGraph ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        
        from src.models.langgraph_agent import ChipChatAgent
        agent = ChipChatAgent(
            csv_path=chipdb_path,
            vectorstore_manager=_vectorstore_manager,
            vectorstore=_vectorstore,
            llm_manager=_chat_manager.llm_manager
        )
        
        progress_container.progress(100)
        status_container.success("âœ… 4/5 LangGraph ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
        
        time.sleep(1)
        progress_container.empty()
        status_container.empty()
        
        return agent, None
        
    except Exception as e:
        progress_container.empty()
        status_container.error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, str(e)

def main():
    st.title("ğŸ’¬ ChipChat Enhanced - ê°œì„ ëœ ë²„ì „")
    st.markdown("**ë¡œë”© ì§„í–‰ ìƒí™©ì„ ìƒì„¸íˆ í‘œì‹œí•˜ëŠ” ê°œì„ ëœ ë²„ì „ì…ë‹ˆë‹¤**")
    
    # Loading status indicator
    if 'initialization_complete' not in st.session_state:
        st.session_state.initialization_complete = False
    
    # Initialize session state
    if 'paths' not in st.session_state:
        st.session_state.paths = setup_paths()
    
    if 'api_keys' not in st.session_state:
        st.session_state.api_keys = load_api_keys()
    
    # Check API keys
    api_keys_available = any(st.session_state.api_keys.values())
    if not api_keys_available:
        st.error("ğŸš¨ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.markdown("""
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:
        1. **í™˜ê²½ ë³€ìˆ˜**: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `HF_TOKEN`
        2. **Streamlit Secrets**: `.streamlit/secrets.toml` íŒŒì¼
        3. **Colab**: ë…¸íŠ¸ë¶ì˜ 3ë‹¨ê³„ì—ì„œ API í‚¤ ì…ë ¥
        """)
        return
    
    # Show loading indicator if not initialized
    if not st.session_state.initialization_complete:
        st.info("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... ì•„ë˜ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        # Overall progress
        overall_progress = st.progress(0)
        overall_status = st.empty()
        
        overall_status.info("ğŸš€ ì´ˆê¸°í™” ì‹œì‘...")
        overall_progress.progress(5)
        
        # Initialize managers
        overall_status.info("ğŸ”„ 1-2/5 ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        chat_manager, vectorstore_manager, init_error = initialize_managers_with_progress()
        
        if init_error:
            st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
            return
        
        overall_progress.progress(40)
        
        # Load vectorstore
        overall_status.info("ğŸ”„ 3/5 ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘...")
        vectorstore, vs_error = load_vectorstore_with_progress(vectorstore_manager, st.session_state.paths['vectorstore_path'])
        
        if vs_error:
            st.error(f"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {vs_error}")
            st.info("prep ëª¨ë“ˆì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì‹œíŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return
        
        overall_progress.progress(70)
        
        # Initialize agent
        overall_status.info("ğŸ”„ 4/5 AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        agent, agent_error = initialize_agent_with_progress(
            chat_manager, vectorstore_manager, vectorstore, 
            st.session_state.paths['chipdb_path']
        )
        
        overall_progress.progress(90)
        
        # Finalize
        overall_status.info("ğŸ”„ 5/5 ë§ˆë¬´ë¦¬ ì¤‘...")
        overall_progress.progress(100)
        
        # Store in session state
        st.session_state.chat_manager = chat_manager
        st.session_state.vectorstore_manager = vectorstore_manager
        st.session_state.vectorstore = vectorstore
        st.session_state.agent = agent
        st.session_state.initialization_complete = True
        
        overall_status.success("âœ… ëª¨ë“  ì´ˆê¸°í™” ì™„ë£Œ! ì•±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        time.sleep(1)
        overall_progress.empty()
        overall_status.empty()
        
        st.rerun()  # Refresh to show the main interface
    
    # Main interface (only shown after initialization)
    if st.session_state.initialization_complete:
        chat_manager = st.session_state.chat_manager
        vectorstore_manager = st.session_state.vectorstore_manager
        vectorstore = st.session_state.vectorstore
        agent = st.session_state.agent
        
        # Sidebar configuration
        with st.sidebar:
            st.header("âš™ï¸ ì„¤ì •")
            
            # System status
            st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
            st.success("âœ… ëª¨ë“  êµ¬ì„± ìš”ì†Œ ë¡œë“œë¨")
            
            # LLM Provider selection
            provider = st.selectbox(
                "LLM ì œê³µì",
                ["openai", "claude"],
                help="ì‚¬ìš©í•  LLM ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # Model selection
            if provider == "openai":
                model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
            else:
                model_options = ["claude-3-sonnet-20240229", "claude-3-haiku-20240307", "claude-3-opus-20240229"]
            
            model_name = st.selectbox("ëª¨ë¸", model_options)
            
            # Mode selection
            mode = st.selectbox(
                "ëª¨ë“œ ì„ íƒ",
                ["ğŸ¤– AI Agent", "ğŸ’¬ Chat", "ğŸ” Retrieval Test", "ğŸ“Š Vectorstore Info"]
            )
            
            # Reset button
            if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™”"):
                for key in ['initialization_complete', 'chat_manager', 'vectorstore_manager', 'vectorstore', 'agent']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
        
        # Main content based on mode
        if mode == "ğŸ¤– AI Agent":
            if agent:
                render_agent_mode(agent)
            else:
                st.error("ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì¬ì´ˆê¸°í™”í•´ë³´ì„¸ìš”.")
        elif mode == "ğŸ’¬ Chat":
            render_chat_mode(chat_manager, vectorstore)
        elif mode == "ğŸ” Retrieval Test":
            render_retrieval_test_mode(chat_manager, vectorstore)
        elif mode == "ğŸ“Š Vectorstore Info":
            render_vectorstore_info_mode(vectorstore_manager, vectorstore)

def render_agent_mode(agent):
    """AI ì—ì´ì „íŠ¸ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ¤– AI Agent Mode")
    st.markdown("**ìŠ¤ë§ˆíŠ¸ ì—ì´ì „íŠ¸ê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìë™ìœ¼ë¡œ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤**")
    
    # Query input
    user_query = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ì „ì•• ë³€í™˜ê¸° ê¸°ëŠ¥ì„ í•˜ëŠ” ëª¨ë“  ë¶€í’ˆë“¤ì„ ì•Œë ¤ì¤˜",
        height=100
    )
    
    if st.button("ğŸš€ ì—ì´ì „íŠ¸ ì‹¤í–‰", type="primary") and user_query:
        with st.spinner("ğŸ¤– ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬ ì¤‘..."):
            response = agent.process_query(user_query)
        
        st.markdown("### ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ")
        st.markdown(response)

def render_chat_mode(chat_manager, vectorstore):
    """ì±„íŒ… ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ’¬ ì±„íŒ…")
    
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: W25Q32JVì˜ ì „ê¸°ì  íŠ¹ì„±ì€?")
    
    if user_input:
        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
            result = chat_manager.get_chat_response(
                query=user_input,
                vectorstore=vectorstore,
                k=5
            )
        
        st.markdown("### ğŸ’¡ ë‹µë³€")
        st.markdown(result['response'])

def render_retrieval_test_mode(chat_manager, vectorstore):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    test_query = st.text_area("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬", placeholder="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”")
    k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜", 1, 20, 5)
    
    if test_query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            results = chat_manager.test_retrieval(
                query=test_query,
                vectorstore=vectorstore,
                k=k
            )
        
        st.markdown("### ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")
        for i, result in enumerate(results):
            with st.expander(f"ê²°ê³¼ {i+1} (ìœ ì‚¬ë„: {result['score']:.3f})"):
                st.markdown("**ë‚´ìš©:**")
                st.markdown(result['content'])
                
                st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                metadata_df = pd.DataFrame([result['metadata']]).T
                metadata_df.columns = ['ê°’']
                st.dataframe(metadata_df)

def render_vectorstore_info_mode(vectorstore_manager, vectorstore):
    """ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ëª¨ë“œ ë Œë”ë§"""
    st.header("ğŸ“Š ë²¡í„°ìŠ¤í† ì–´ ì •ë³´")
    
    info = vectorstore_manager.get_vectorstore_info(vectorstore)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", info.get('total_documents', 0))
    
    with col2:
        st.metric("ì„ë² ë”© ëª¨ë¸", info.get('embedding_model', 'Unknown'))
    
    with col3:
        st.metric("ë””ë°”ì´ìŠ¤", info.get('device', 'Unknown'))

if __name__ == "__main__":
    main() 
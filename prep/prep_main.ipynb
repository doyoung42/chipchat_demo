{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# ğŸ“Š PDF ë°ì´í„°ì‹œíŠ¸ ì „ì²˜ë¦¬ ë„êµ¬\n",
        "\n",
        "**ë°ì´í„°ì‹œíŠ¸ PDFë¥¼ ë¶„ì„í•˜ì—¬ ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  JSON í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ PDF ë°ì´í„°ì‹œíŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‚˜ì¤‘ì— ì±—ë´‡ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” JSON íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ë¶„í•  ë°©ì‹ìœ¼ë¡œ PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
        "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title âœ… 1ë‹¨ê³„: Google Drive ì—°ë™ { display-mode: \"form\" }\n",
        "#@markdown Google Driveë¥¼ ì—°ë™í•˜ì—¬ PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬ëœ JSON íŒŒì¼ê³¼ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ”„ Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# í´ë” ê²½ë¡œ ì„¤ì •\n",
        "pdf_folder = Path('/content/drive/MyDrive/datasheets')\n",
        "pre_json_folder = Path('/content/drive/MyDrive/prep_json/pre_json')\n",
        "result_json_folder = Path('/content/drive/MyDrive/prep_json')\n",
        "vectorstore_folder = Path('/content/drive/MyDrive/vectorstore')\n",
        "\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "pdf_folder.mkdir(parents=True, exist_ok=True)\n",
        "pre_json_folder.mkdir(parents=True, exist_ok=True)\n",
        "result_json_folder.mkdir(parents=True, exist_ok=True)\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nâœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“ PDF í´ë”: {pdf_folder}\")\n",
        "print(f\"ğŸ“ ì¤‘ê°„ JSON í´ë”: {pre_json_folder}\")\n",
        "print(f\"ğŸ“ ìµœì¢… JSON í´ë”: {result_json_folder}\")\n",
        "print(f\"ğŸ“ ë²¡í„° ìŠ¤í† ì–´ í´ë”: {vectorstore_folder}\")\n",
        "\n",
        "# PDF íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
        "print(f\"\\nï¿½ï¿½ ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ\")\n",
        "for pdf in pdf_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
        "    print(f\" - {pdf.name}\")\n",
        "    \n",
        "if len(pdf_files) > 5:\n",
        "    print(f\" ... ì™¸ {len(pdf_files) - 5}ê°œ\")\n",
        "\n",
        "if not pdf_files:\n",
        "    print(f\"\\nâš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. '{pdf_folder}' í´ë”ì— PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“¥ 2ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
        "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "print(\"ğŸ“¥ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
        "\n",
        "# GitHub ì €ì¥ì†Œ í´ë¡ \n",
        "!git clone https://github.com/doyoung42/chipchat.git\n",
        "%cd chipchat/prep\n",
        "\n",
        "# requirements.txt ì„¤ì¹˜\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "models_path = Path('misc/models.json')\n",
        "param_path = Path('misc/param.json')\n",
        "\n",
        "with open(models_path, 'r') as f:\n",
        "    models = json.load(f)\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
        "print(\"\\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:\")\n",
        "print(\"\\nOpenAI ëª¨ë¸:\")\n",
        "for model in models[\"openai_models\"]:\n",
        "    print(f\"â€¢ {model}\")\n",
        "print(\"\\nClaude ëª¨ë¸:\")\n",
        "for model in models[\"claude_models\"]:\n",
        "    print(f\"â€¢ {model}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ í˜„ì¬ PDF ì²˜ë¦¬ ì„¤ì •:\")\n",
        "print(f\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: {params['pdf_processing']['pages_per_chunk']}\")\n",
        "print(f\"â€¢ ì¶œë ¥ í˜•ì‹:\")\n",
        "print(f\"  - í•„í„°ë§ëœ PDF ì €ì¥: {params['pdf_processing']['output_formats']['save_filtered_pdf']}\")\n",
        "print(f\"  - ì¹´í…Œê³ ë¦¬ë³„ ì‹œë§¨í‹± ì²­í‚¹: í™œì„±í™”ë¨\")\n",
        "print(f\"  - í˜ì´ì§€ ìš”ì•½ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: í™œì„±í™”ë¨\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”‘ 3ë‹¨ê³„: API í‚¤ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown API í‚¤ë¥¼ ì…ë ¥í•˜ê³  ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# API í‚¤ ì…ë ¥\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# LLM ëª¨ë¸ ì„ íƒ\n",
        "llm_model = \"claude-3-sonnet-20240229\" #@param [\"claude-3-5-sonnet-20241022\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\", \"gpt-3.5-turbo-0125\", \"gpt-4o-mini-2024-07-18\"] {type:\"string\"}\n",
        "\n",
        "# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"â€¢ OpenAI API í‚¤: https://platform.openai.com/api-keys\")\n",
        "    print(\"â€¢ Claude API í‚¤: https://console.anthropic.com/keys\")\n",
        "    print(\"â€¢ HuggingFace í† í°: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # key.json íŒŒì¼ì— ì €ì¥\n",
        "    key_path = Path('misc/key.json')\n",
        "    key_path.parent.mkdir(exist_ok=True)\n",
        "    \n",
        "    # ëª¨ë¸ íƒ€ì… ê²°ì •\n",
        "    if llm_model.startswith(\"claude\"):\n",
        "        provider = \"claude\"\n",
        "    else:\n",
        "        provider = \"openai\"\n",
        "    \n",
        "    with open(key_path, 'w') as f:\n",
        "        json.dump({\n",
        "            'openai_api_key': openai_api_key,\n",
        "            'anthropic_api_key': claude_api_key,\n",
        "            'huggingface_api_key': hf_token,\n",
        "            'selected_models': {\n",
        "                provider: llm_model\n",
        "            }\n",
        "        }, f, indent=2)\n",
        "    \n",
        "    print(\"âœ… API í‚¤ì™€ ì„ íƒëœ ëª¨ë¸ì´ key.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“Š 4ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown PDF ì²˜ë¦¬ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# param.json íŒŒì¼ ë¡œë“œ\n",
        "param_path = Path('misc/param.json')\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "# í˜„ì¬ ì„¤ì •ê°’ í‘œì‹œ\n",
        "print(\"ğŸ“‹ í˜„ì¬ PDF ì²˜ë¦¬ ì„¤ì •:\")\n",
        "print(f\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: {params['pdf_processing']['pages_per_chunk']}\")\n",
        "print(f\"â€¢ ì¶œë ¥ í˜•ì‹:\")\n",
        "print(f\"  - í•„í„°ë§ëœ PDF ì €ì¥: {params['pdf_processing']['output_formats']['save_filtered_pdf']}\")\n",
        "print(f\"  - ì¹´í…Œê³ ë¦¬ë³„ ì‹œë§¨í‹± ì²­í‚¹: í™œì„±í™”ë¨\")\n",
        "print(f\"  - í˜ì´ì§€ ìš”ì•½ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: í™œì„±í™”ë¨\")\n",
        "\n",
        "# ì„¤ì •ê°’ ìˆ˜ì •\n",
        "pages_per_chunk = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "save_filtered_pdf = True #@param {type:\"boolean\"}\n",
        "save_summary_only = True #@param {type:\"boolean\"} \n",
        "save_combined = True #@param {type:\"boolean\"}\n",
        "\n",
        "# ì„¤ì •ê°’ ì—…ë°ì´íŠ¸\n",
        "params[\"pdf_processing\"][\"pages_per_chunk\"] = pages_per_chunk\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_filtered_pdf\"] = save_filtered_pdf\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_summary_only\"] = save_summary_only\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_combined\"] = save_combined\n",
        "\n",
        "# í´ë” ê²½ë¡œ ì—…ë°ì´íŠ¸\n",
        "params[\"pdf_processing\"][\"folders\"][\"pdf_folder\"] = str(pdf_folder)\n",
        "params[\"pdf_processing\"][\"folders\"][\"pre_json_folder\"] = str(result_json_folder / \"pre_json\")\n",
        "params[\"pdf_processing\"][\"folders\"][\"result_json_folder\"] = str(result_json_folder)\n",
        "params[\"vectorstore\"][\"folders\"][\"vectorstore_folder\"] = str(vectorstore_folder)\n",
        "\n",
        "# param.json íŒŒì¼ì— ì €ì¥\n",
        "param_path = Path('misc/param.json')\n",
        "param_path.parent.mkdir(exist_ok=True)\n",
        "\n",
        "with open(param_path, 'w') as f:\n",
        "    json.dump(params, f, indent=2)\n",
        "\n",
        "print(\"\\nâœ… PDF ì²˜ë¦¬ ì„¤ì •ì´ param.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"\\nğŸ“ ì„¤ì • ì„¤ëª…:\")\n",
        "print(\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: PDFë¥¼ ëª‡ í˜ì´ì§€ì”© ë¬¶ì–´ì„œ ì²˜ë¦¬í• ì§€ ì„¤ì •í•©ë‹ˆë‹¤.\")\n",
        "print(\"â€¢ í•„í„°ë§ëœ PDF ì €ì¥: ìœ ìš©í•œ ì •ë³´ê°€ ìˆëŠ” í˜ì´ì§€ë§Œ ëª¨ì•„ì„œ PDFë¡œ ì €ì¥í•©ë‹ˆë‹¤.\")\n",
        "print(\"â€¢ ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬: ë‚´ìš©ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤:\")\n",
        "print(\"  - ì œí’ˆ ìš”ì•½(Product summary)\")\n",
        "print(\"  - ì „ê¸°ì  íŠ¹ì„±(Electrical Characteristics)\")\n",
        "print(\"  - ì‘ìš© íšŒë¡œ ì˜ˆì‹œ(Application circuits)\")\n",
        "print(\"  - ê¸°ê³„ì  íŠ¹ì„±(Mechanical Characteristics)\")\n",
        "print(\"  - ì‹ ë¢°ì„± ë° í™˜ê²½ ì‹œí—˜ ì¡°ê±´(Reliability, Environmental conditions)\")\n",
        "print(\"  - íŒ¨í‚¤ì§• ì •ë³´(Packaging)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“„ 5ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ { display-mode: \"form\" }\n",
        "#@markdown PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.pdf_processor import PDFProcessor\n",
        "from src.llm_manager import LLMManager\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# key.jsonì—ì„œ ì„ íƒëœ ëª¨ë¸ ì •ë³´ ë¡œë“œ\n",
        "key_path = Path('misc/key.json')\n",
        "with open(key_path, 'r') as f:\n",
        "    keys = json.load(f)\n",
        "selected_models = keys.get('selected_models', {})\n",
        "\n",
        "# ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ provider ê²°ì •\n",
        "if any(model.startswith('claude') for model in selected_models.values()):\n",
        "    provider = \"claude\"\n",
        "    model_name = selected_models.get('claude')\n",
        "else:\n",
        "    provider = \"openai\"\n",
        "    model_name = selected_models.get('openai')\n",
        "\n",
        "# LLM Manager ì´ˆê¸°í™”\n",
        "llm_manager = LLMManager(provider=provider, model_name=model_name)\n",
        "\n",
        "# PDF Processor ì´ˆê¸°í™”\n",
        "processor = PDFProcessor(llm_manager)\n",
        "\n",
        "# PDF ì²˜ë¦¬ ì‹œì‘\n",
        "print(\"ğŸ”„ PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...\")\n",
        "processor.process_pdf_folder()\n",
        "print(\"âœ… PDF íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB2"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ” 6ë‹¨ê³„: ë²¡í„° ìŠ¤í† ì–´ ìƒì„± { display-mode: \"form\" }\n",
        "#@markdown ì²˜ë¦¬ëœ JSON íŒŒì¼ë“¤ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.vectorstore_manager import VectorstoreManager\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Vectorstore Manager ì´ˆê¸°í™”\n",
        "vectorstore_manager = VectorstoreManager()\n",
        "\n",
        "# JSON íŒŒì¼ ë¡œë“œ\n",
        "json_folder = Path(default_params[\"pdf_processing\"][\"folders\"][\"result_json_folder\"])\n",
        "json_files = list(json_folder.glob(\"*_R1.json\"))  # R1 íŒŒì¼ë§Œ ì‚¬ìš©\n",
        "\n",
        "if not json_files:\n",
        "    print(\"âŒ ì²˜ë¦¬ëœ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 5ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    print(f\"ğŸ“„ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ\")\n",
        "    \n",
        "    # JSON ë°ì´í„° ë¡œë“œ\n",
        "    json_data = []\n",
        "    for json_file in json_files:\n",
        "        try:\n",
        "            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                json_data.append(data)\n",
        "            print(f\"âœ… {json_file.name} ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ {json_file.name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
        "    \n",
        "    if json_data:\n",
        "        print(\"\\nğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...\")\n",
        "        try:\n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
        "            vectorstore = vectorstore_manager.create_vectorstore(json_data)\n",
        "            \n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥\n",
        "            vectorstore_manager.save_vectorstore(vectorstore, \"datasheet_vectors\")\n",
        "            \n",
        "            print(\"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!\")\n",
        "            print(f\"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {vectorstore_folder}/datasheet_vectors\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
        "    else:\n",
        "        print(\"âŒ ë¡œë“œëœ JSON ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "prep_main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# ğŸ“Š PDF ë°ì´í„°ì‹œíŠ¸ ì „ì²˜ë¦¬ ë„êµ¬\n",
        "\n",
        "**ë°ì´í„°ì‹œíŠ¸ PDFë¥¼ ë¶„ì„í•˜ì—¬ ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  JSON í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ PDF ë°ì´í„°ì‹œíŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‚˜ì¤‘ì— ì±—ë´‡ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” JSON íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ë¶„í•  ë°©ì‹ìœ¼ë¡œ PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
        "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title âœ… 1ë‹¨ê³„: Google Drive ì—°ë™ { display-mode: \"form\" }\n",
        "#@markdown Google Driveë¥¼ ì—°ë™í•˜ì—¬ PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬ëœ JSON íŒŒì¼ê³¼ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# í™˜ê²½ ì„ íƒ í† ê¸€\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown âœ… ì²´í¬: Google Drive ì‚¬ìš© (Colab í™˜ê²½) | âŒ ì²´í¬í•´ì œ: ë¡œì»¬ í™˜ê²½ ì‚¬ìš©\n",
        "\n",
        "# í™˜ê²½ë³„ ì„¤ì •\n",
        "if use_google_drive:\n",
        "    # Google Drive í™˜ê²½\n",
        "    print(\"ğŸŒ Google Drive í™˜ê²½ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤...\")\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        print(\"ğŸ”„ Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
        "        drive.mount('/content/drive')\n",
        "        \n",
        "        # Google Drive í´ë” ê²½ë¡œ ì„¤ì •\n",
        "        base_path = Path('/content/drive/MyDrive')\n",
        "        pdf_folder = base_path / 'datasheets'\n",
        "        pre_json_folder = base_path / 'prep_json' / 'pre_json'\n",
        "        result_json_folder = base_path / 'prep_json'\n",
        "        vectorstore_folder = base_path / 'vectorstore'\n",
        "        \n",
        "        print(\"âœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"âš ï¸ Google Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. ë¡œì»¬ í™˜ê²½ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤...\")\n",
        "        use_google_drive = False\n",
        "        \n",
        "if not use_google_drive:\n",
        "    # ë¡œì»¬ í™˜ê²½\n",
        "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤...\")\n",
        "    \n",
        "    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ ë¡œì»¬ í´ë” ì„¤ì • (./ ê¸°ì¤€)\n",
        "    base_path = Path.cwd()  # prep í´ë”ì—ì„œ ./ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •\n",
        "    pdf_folder = base_path / 'datasheets'\n",
        "    pre_json_folder = base_path / 'prep_json' / 'pre_json'\n",
        "    result_json_folder = base_path / 'prep_json'\n",
        "    vectorstore_folder = base_path / 'vectorstore'\n",
        "    \n",
        "    print(\"âœ… ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
        "\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "pdf_folder.mkdir(parents=True, exist_ok=True)\n",
        "pre_json_folder.mkdir(parents=True, exist_ok=True)\n",
        "result_json_folder.mkdir(parents=True, exist_ok=True)\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# param.json íŒŒì¼ ì—…ë°ì´íŠ¸ (í™˜ê²½ì— ë§ëŠ” ê²½ë¡œë¡œ)\n",
        "param_file = Path('misc/param.json')\n",
        "if param_file.exists():\n",
        "    with open(param_file, 'r') as f:\n",
        "        params = json.load(f)\n",
        "    \n",
        "    # í™˜ê²½ì— ë”°ë¥¸ ê²½ë¡œ ì„¤ì •\n",
        "    if use_google_drive:\n",
        "        # Google Drive ê²½ë¡œ\n",
        "        base_path_str = '/content/drive/MyDrive'\n",
        "        params['pdf_processing']['folders']['pdf_folder'] = f'{base_path_str}/datasheets'\n",
        "        params['pdf_processing']['folders']['pre_json_folder'] = f'{base_path_str}/prep_json/pre_json'\n",
        "        params['pdf_processing']['folders']['result_json_folder'] = f'{base_path_str}/prep_json'\n",
        "        params['vectorstore']['folders']['vectorstore_folder'] = f'{base_path_str}/vectorstore'\n",
        "    else:\n",
        "        # ë¡œì»¬ ê²½ë¡œ (ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€)\n",
        "        params['pdf_processing']['folders']['pdf_folder'] = './datasheets'\n",
        "        params['pdf_processing']['folders']['pre_json_folder'] = './prep_json/pre_json'\n",
        "        params['pdf_processing']['folders']['result_json_folder'] = './prep_json'\n",
        "        params['vectorstore']['folders']['vectorstore_folder'] = './vectorstore'\n",
        "    \n",
        "    # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥\n",
        "    with open(param_file, 'w') as f:\n",
        "        json.dump(params, f, indent=4)\n",
        "    \n",
        "    print(f\"âœ… param.jsonì´ {env_type} í™˜ê²½ì— ë§ê²Œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ğŸ“‹ ì„¤ì •ëœ ê²½ë¡œë“¤:\")\n",
        "    print(f\"  â€¢ PDF í´ë”: {params['pdf_processing']['folders']['pdf_folder']}\")\n",
        "    print(f\"  â€¢ ì¤‘ê°„ JSON í´ë”: {params['pdf_processing']['folders']['pre_json_folder']}\")\n",
        "    print(f\"  â€¢ ìµœì¢… JSON í´ë”: {params['pdf_processing']['folders']['result_json_folder']}\")\n",
        "    print(f\"  â€¢ ë²¡í„°ìŠ¤í† ì–´ í´ë”: {params['vectorstore']['folders']['vectorstore_folder']}\")\n",
        "else:\n",
        "    print(\"âš ï¸ param.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "# ì„¤ì •ëœ í´ë” ê²½ë¡œ ì¶œë ¥\n",
        "env_type = \"Google Drive\" if use_google_drive else \"ë¡œì»¬\"\n",
        "print(f\"\\nâœ… {env_type} í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“ PDF í´ë”: {pdf_folder}\")\n",
        "print(f\"ğŸ“ ì¤‘ê°„ JSON í´ë”: {pre_json_folder}\")\n",
        "print(f\"ğŸ“ ìµœì¢… JSON í´ë”: {result_json_folder}\")\n",
        "print(f\"ğŸ“ ë²¡í„° ìŠ¤í† ì–´ í´ë”: {vectorstore_folder}\")\n",
        "\n",
        "# PDF íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
        "print(f\"\\nï¿½ï¿½ ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ\")\n",
        "for pdf in pdf_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
        "    print(f\" - {pdf.name}\")\n",
        "    \n",
        "if len(pdf_files) > 5:\n",
        "    print(f\" ... ì™¸ {len(pdf_files) - 5}ê°œ\")\n",
        "\n",
        "if not pdf_files:\n",
        "    print(f\"\\nâš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. '{pdf_folder}' í´ë”ì— PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“¥ 2ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
        "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "print(\"ğŸ“¥ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
        "\n",
        "# GitHub ì €ì¥ì†Œ í´ë¡ \n",
        "!git clone https://github.com/doyoung42/chipchat_demo.git\n",
        "%cd chipchat_demo/prep\n",
        "\n",
        "# requirements.txt ì„¤ì¹˜\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "models_path = Path('misc/models.json')\n",
        "param_path = Path('misc/param.json')\n",
        "\n",
        "with open(models_path, 'r') as f:\n",
        "    models = json.load(f)\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
        "print(\"\\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:\")\n",
        "print(\"\\nOpenAI ëª¨ë¸:\")\n",
        "for model in models[\"openai_models\"]:\n",
        "    print(f\"â€¢ {model}\")\n",
        "print(\"\\nClaude ëª¨ë¸:\")\n",
        "for model in models[\"claude_models\"]:\n",
        "    print(f\"â€¢ {model}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ í˜„ì¬ PDF ì²˜ë¦¬ ì„¤ì •:\")\n",
        "print(f\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: {params['pdf_processing']['pages_per_chunk']}\")\n",
        "print(f\"â€¢ ì¶œë ¥ í˜•ì‹:\")\n",
        "print(f\"  - í•„í„°ë§ëœ PDF ì €ì¥: {params['pdf_processing']['output_formats']['save_filtered_pdf']}\")\n",
        "print(f\"  - ì¹´í…Œê³ ë¦¬ë³„ ì‹œë§¨í‹± ì²­í‚¹: í™œì„±í™”ë¨\")\n",
        "print(f\"  - í˜ì´ì§€ ìš”ì•½ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: í™œì„±í™”ë¨\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”‘ 3ë‹¨ê³„: API í‚¤ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown API í‚¤ë¥¼ ì…ë ¥í•˜ê³  ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# API í‚¤ ì…ë ¥\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# LLM ëª¨ë¸ ì„ íƒ\n",
        "llm_model = \"claude-3-sonnet-20240229\" #@param [\"claude-3-5-sonnet-20241022\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\", \"gpt-3.5-turbo-0125\", \"gpt-4o-mini-2024-07-18\"] {type:\"string\"}\n",
        "\n",
        "# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"â€¢ OpenAI API í‚¤: https://platform.openai.com/api-keys\")\n",
        "    print(\"â€¢ Claude API í‚¤: https://console.anthropic.com/keys\")\n",
        "    print(\"â€¢ HuggingFace í† í°: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # key.json íŒŒì¼ì— ì €ì¥\n",
        "    key_path = Path('misc/key.json')\n",
        "    key_path.parent.mkdir(exist_ok=True)\n",
        "    \n",
        "    # ëª¨ë¸ íƒ€ì… ê²°ì •\n",
        "    if llm_model.startswith(\"claude\"):\n",
        "        provider = \"claude\"\n",
        "    else:\n",
        "        provider = \"openai\"\n",
        "    \n",
        "    with open(key_path, 'w') as f:\n",
        "        json.dump({\n",
        "            'openai_api_key': openai_api_key,\n",
        "            'anthropic_api_key': claude_api_key,\n",
        "            'huggingface_api_key': hf_token,\n",
        "            'selected_models': {\n",
        "                provider: llm_model\n",
        "            }\n",
        "        }, f, indent=2)\n",
        "    \n",
        "    print(\"âœ… API í‚¤ì™€ ì„ íƒëœ ëª¨ë¸ì´ key.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“Š 4ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown PDF ì²˜ë¦¬ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# 1ë‹¨ê³„ì—ì„œ ì •ì˜í•œ ë³€ìˆ˜ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
        "print(\"ğŸ“‹ 1ë‹¨ê³„ ë³€ìˆ˜ í™•ì¸:\")\n",
        "try:\n",
        "    print(f\"â€¢ pdf_folder ì¡´ì¬: {pdf_folder}\")\n",
        "    print(f\"â€¢ result_json_folder ì¡´ì¬: {result_json_folder}\")\n",
        "    print(f\"â€¢ vectorstore_folder ì¡´ì¬: {vectorstore_folder}\")\n",
        "    print(f\"â€¢ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "except NameError as e:\n",
        "    print(f\"âŒ ë³€ìˆ˜ ì—†ìŒ: {e}\")\n",
        "    print(\"ğŸ’¡ 1ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”!\")\n",
        "\n",
        "# param.json íŒŒì¼ ë¡œë“œ\n",
        "param_path = Path('misc/param.json')\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "# í˜„ì¬ ì„¤ì •ê°’ í‘œì‹œ\n",
        "print(\"ğŸ“‹ í˜„ì¬ PDF ì²˜ë¦¬ ì„¤ì •:\")\n",
        "print(f\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: {params['pdf_processing']['pages_per_chunk']}\")\n",
        "print(f\"â€¢ ì¶œë ¥ í˜•ì‹:\")\n",
        "print(f\"  - í•„í„°ë§ëœ PDF ì €ì¥: {params['pdf_processing']['output_formats']['save_filtered_pdf']}\")\n",
        "print(f\"  - ì¹´í…Œê³ ë¦¬ë³„ ì‹œë§¨í‹± ì²­í‚¹: í™œì„±í™”ë¨\")\n",
        "print(f\"  - í˜ì´ì§€ ìš”ì•½ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: í™œì„±í™”ë¨\")\n",
        "\n",
        "# ì„¤ì •ê°’ ìˆ˜ì •\n",
        "pages_per_chunk = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "save_filtered_pdf = True #@param {type:\"boolean\"}\n",
        "save_summary_only = True #@param {type:\"boolean\"} \n",
        "save_combined = True #@param {type:\"boolean\"}\n",
        "\n",
        "# ì„¤ì •ê°’ ì—…ë°ì´íŠ¸\n",
        "params[\"pdf_processing\"][\"pages_per_chunk\"] = pages_per_chunk\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_filtered_pdf\"] = save_filtered_pdf\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_summary_only\"] = save_summary_only\n",
        "params[\"pdf_processing\"][\"output_formats\"][\"save_combined\"] = save_combined\n",
        "\n",
        "# í´ë” ê²½ë¡œ ì—…ë°ì´íŠ¸ (1ë‹¨ê³„ì—ì„œ ì •ì˜í•œ ë³€ìˆ˜ë“¤ ì‚¬ìš©)\n",
        "params[\"pdf_processing\"][\"folders\"][\"pdf_folder\"] = str(pdf_folder)\n",
        "params[\"pdf_processing\"][\"folders\"][\"pre_json_folder\"] = str(result_json_folder / \"pre_json\")\n",
        "params[\"pdf_processing\"][\"folders\"][\"result_json_folder\"] = str(result_json_folder)\n",
        "params[\"vectorstore\"][\"folders\"][\"vectorstore_folder\"] = str(vectorstore_folder)\n",
        "\n",
        "# ê²½ë¡œ ê²€ì¦\n",
        "print(f\"ğŸ” pdf_folder: {pdf_folder}\")\n",
        "print(f\"ğŸ” result_json_folder: {result_json_folder}\")\n",
        "print(f\"ğŸ” vectorstore_folder: {vectorstore_folder}\")\n",
        "print(f\"ğŸ” param.jsonì— ì €ì¥ë  vectorstore ê²½ë¡œ: {params['vectorstore']['folders']['vectorstore_folder']}\")\n",
        "\n",
        "# param.json íŒŒì¼ì— ì €ì¥\n",
        "param_path = Path('misc/param.json')\n",
        "param_path.parent.mkdir(exist_ok=True)\n",
        "\n",
        "with open(param_path, 'w') as f:\n",
        "    json.dump(params, f, indent=2)\n",
        "\n",
        "# ì €ì¥ í›„ í™•ì¸\n",
        "print(f\"ğŸ“ param.json íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {param_path.absolute()}\")\n",
        "with open(param_path, 'r') as f:\n",
        "    saved_params = json.load(f)\n",
        "actual_vectorstore_path = saved_params.get('vectorstore', {}).get('folders', {}).get('vectorstore_folder', 'NOT_FOUND')\n",
        "print(f\"ğŸ” ì‹¤ì œ ì €ì¥ëœ vectorstore ê²½ë¡œ: {actual_vectorstore_path}\")\n",
        "\n",
        "if actual_vectorstore_path != str(vectorstore_folder):\n",
        "    print(f\"âš ï¸ ê²½ë¡œ ë¶ˆì¼ì¹˜ ë°œê²¬!\")\n",
        "    print(f\"   ì˜ˆìƒ: {vectorstore_folder}\")\n",
        "    print(f\"   ì‹¤ì œ: {actual_vectorstore_path}\")\n",
        "else:\n",
        "    print(f\"âœ… ê²½ë¡œ ì €ì¥ ì„±ê³µ!\")\n",
        "\n",
        "print(\"\\nâœ… PDF ì²˜ë¦¬ ì„¤ì •ì´ param.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"\\nğŸ“ ì„¤ì • ì„¤ëª…:\")\n",
        "print(\"â€¢ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜: PDFë¥¼ ëª‡ í˜ì´ì§€ì”© ë¬¶ì–´ì„œ ì²˜ë¦¬í• ì§€ ì„¤ì •í•©ë‹ˆë‹¤.\")\n",
        "print(\"â€¢ í•„í„°ë§ëœ PDF ì €ì¥: ìœ ìš©í•œ ì •ë³´ê°€ ìˆëŠ” í˜ì´ì§€ë§Œ ëª¨ì•„ì„œ PDFë¡œ ì €ì¥í•©ë‹ˆë‹¤.\")\n",
        "print(\"â€¢ ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬: ë‚´ìš©ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤:\")\n",
        "print(\"  - ì œí’ˆ ìš”ì•½(Product summary)\")\n",
        "print(\"  - ì „ê¸°ì  íŠ¹ì„±(Electrical Characteristics)\")\n",
        "print(\"  - ì‘ìš© íšŒë¡œ ì˜ˆì‹œ(Application circuits)\")\n",
        "print(\"  - ê¸°ê³„ì  íŠ¹ì„±(Mechanical Characteristics)\")\n",
        "print(\"  - ì‹ ë¢°ì„± ë° í™˜ê²½ ì‹œí—˜ ì¡°ê±´(Reliability, Environmental conditions)\")\n",
        "print(\"  - íŒ¨í‚¤ì§• ì •ë³´(Packaging)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ğŸ“‹ 4-1ë‹¨ê³„: ë¶€í’ˆ ì •ë³´ CSV íŒŒì¼ í™•ì¸ { display-mode: \"form\" }\n",
        "#@markdown PDF í´ë” ë‚´ pdf_filenames.csv íŒŒì¼ì„ ê²€ì‚¬í•˜ê³  ë¶€í’ˆ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# PDF í´ë” ë‚´ CSV íŒŒì¼ ê²½ë¡œ\n",
        "csv_path = os.path.join(pdf_folder, 'pdf_filenames.csv')\n",
        "\n",
        "# CSV íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
        "if os.path.exists(csv_path):\n",
        "    # CSV íŒŒì¼ ë¡œë“œ\n",
        "    df = pd.read_csv(csv_path)\n",
        "    \n",
        "    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "    required_columns = ['maker pn']\n",
        "    optional_columns = ['fake_grade', 'final_fake_code']\n",
        "    \n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    missing_optional = [col for col in optional_columns if col not in df.columns]\n",
        "    \n",
        "    print(f\"âœ… PDF í´ë”ì—ì„œ pdf_filenames.csv íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"ğŸ“Š ì´ {len(df)} ê°œì˜ ë¶€í’ˆ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤.\\n\")\n",
        "    \n",
        "    # ì»¬ëŸ¼ í™•ì¸\n",
        "    print(\"ğŸ“‹ CSV íŒŒì¼ ì»¬ëŸ¼ ì •ë³´:\")\n",
        "    for col in df.columns:\n",
        "        print(f\"â€¢ {col}\")\n",
        "    \n",
        "    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "    if missing_columns:\n",
        "        print(f\"\\nâš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}\")\n",
        "        print(\"  íŠ¹ì • ë¶€í’ˆ ë²ˆí˜¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ 'maker pn' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    \n",
        "    # ì˜µì…˜ ì»¬ëŸ¼ í™•ì¸\n",
        "    if missing_optional:\n",
        "        print(f\"\\nğŸ” ì˜µì…˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_optional)}\")\n",
        "        print(\"  JSON ê²°ê³¼ì— gradeì™€ spec ì •ë³´ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ 'fake_grade'ì™€ 'final_fake_code' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    \n",
        "    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
        "    print(\"\\nğŸ“„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "    display(df.head(5))\n",
        "    \n",
        "    # CSV í˜•ì‹ ì„¤ëª…\n",
        "    print(\"\\nğŸ“ CSV íŒŒì¼ í˜•ì‹ ì„¤ëª…:\")\n",
        "    print(\"â€¢ íŒŒì¼ëª… ì»¬ëŸ¼: PDF íŒŒì¼ëª…ì„ í¬í•¨í•˜ëŠ” ì»¬ëŸ¼\")\n",
        "    print(\"â€¢ maker pn: ë°ì´í„°ì‹œíŠ¸ì—ì„œ ì°¾ì„ íŠ¹ì • ë¶€í’ˆ ë²ˆí˜¸\")\n",
        "    print(\"â€¢ fake_grade: JSON ê²°ê³¼ì— ì¶”ê°€ë  ë“±ê¸‰ ì •ë³´\")\n",
        "    print(\"â€¢ final_fake_code: JSON ê²°ê³¼ì— ì¶”ê°€ë  ì‚¬ì–‘ ì½”ë“œ\")\n",
        "\n",
        "else:\n",
        "    print(f\"âš ï¸ PDF í´ë”ì—ì„œ pdf_filenames.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}\")\n",
        "    print(\"\\nğŸ’¡ CSV íŒŒì¼ í˜•ì‹ ì˜ˆì‹œ:\")\n",
        "    print(\"íŒŒì¼ëª…, maker pn, fake_grade, final_fake_code\")\n",
        "    print(\"example.pdf, ABC123, A, 12345\")\n",
        "    print(\"multi_component.pdf, XYZ789, B, 67890\")\n",
        "    \n",
        "    # ì˜ˆì‹œ CSV ë°ì´í„° ìƒì„±\n",
        "    example_data = {\n",
        "        'file': ['example1.pdf', 'example2.pdf', 'example3.pdf'],\n",
        "        'maker pn': ['LM324', 'NE555', 'ATmega328'],\n",
        "        'fake_grade': ['A', 'B', 'C'],\n",
        "        'final_fake_code': ['12345', '67890', '54321']\n",
        "    }\n",
        "    \n",
        "    example_df = pd.DataFrame(example_data)\n",
        "    print(\"\\nğŸ“Š CSV íŒŒì¼ ì˜ˆì‹œ:\")\n",
        "    display(example_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“„ 5ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ { display-mode: \"form\" }\n",
        "#@markdown PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.pdf_processor import PDFProcessor\n",
        "from src.llm_manager import LLMManager\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# key.jsonì—ì„œ ì„ íƒëœ ëª¨ë¸ ì •ë³´ ë¡œë“œ\n",
        "key_path = Path('misc/key.json')\n",
        "with open(key_path, 'r') as f:\n",
        "    keys = json.load(f)\n",
        "selected_models = keys.get('selected_models', {})\n",
        "\n",
        "# ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ provider ê²°ì •\n",
        "if any(model.startswith('claude') for model in selected_models.values()):\n",
        "    provider = \"claude\"\n",
        "    model_name = selected_models.get('claude')\n",
        "else:\n",
        "    provider = \"openai\"\n",
        "    model_name = selected_models.get('openai')\n",
        "\n",
        "# LLM Manager ì´ˆê¸°í™”\n",
        "llm_manager = LLMManager(provider=provider, model_name=model_name)\n",
        "\n",
        "# PDF Processor ì´ˆê¸°í™”\n",
        "processor = PDFProcessor(llm_manager)\n",
        "\n",
        "# PDF ì²˜ë¦¬ ì‹œì‘\n",
        "print(\"ğŸ”„ PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...\")\n",
        "processor.process_pdf_folder()\n",
        "print(\"âœ… PDF íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB2"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“Š 6ë‹¨ê³„: í›„ì²˜ë¦¬ - JSON ë³‘í•© ë° ì •ê·œí™” { display-mode: \"form\" }\n",
        "#@markdown ì²˜ë¦¬ëœ JSON íŒŒì¼ë“¤ì„ CSV ë©”íƒ€ë°ì´í„°ì™€ ë³‘í•©í•˜ê³  í•„ë“œëª…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.post_processor import PostProcessor\n",
        "from pathlib import Path\n",
        "\n",
        "# PostProcessor ì´ˆê¸°í™” (Google Drive ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)\n",
        "post_processor = PostProcessor()\n",
        "\n",
        "print(\"ğŸ”„ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘...\")\n",
        "print(\"ğŸ“‹ ì²˜ë¦¬ ë‹¨ê³„:\")\n",
        "print(\"  1. JSON íŒŒì¼ê³¼ CSV ë©”íƒ€ë°ì´í„° ë³‘í•©\")\n",
        "print(\"  2. í•„ë“œëª… ì •ê·œí™” (filename â†’ part number, fake_grade â†’ grade)\")\n",
        "print(\"  3. ë°ì´í„°ì…‹ ê²€ì¦ ë° ì •ë¦¬\")\n",
        "print(\"  4. ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF íŒŒì¼ ë¶„ë¦¬\")\n",
        "\n",
        "# ì™„ì „í•œ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "try:\n",
        "    post_processor.run_complete_postprocessing()\n",
        "    \n",
        "    # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n",
        "    print(\"\\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:\")\n",
        "    summary = post_processor.get_processing_summary()\n",
        "    \n",
        "    for key, value in summary.items():\n",
        "        print(f\"â€¢ {key.replace('_', ' ').title()}: {value}\")\n",
        "        \n",
        "    print(\"\\nâœ… í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ìµœì¢… JSON íŒŒì¼ ìœ„ì¹˜: {post_processor.final_json_folder}\")\n",
        "    print(f\"ğŸ“ ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF íŒŒì¼ ìœ„ì¹˜: {post_processor.not_processed_folder}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "    print(\"ğŸ’¡ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:\")\n",
        "    print(\"  - CSV íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸\")\n",
        "    print(\"  - í•„ìˆ˜ ì»¬ëŸ¼ (final_fake_code, fake_grade, maker pn)ì´ ìˆëŠ”ì§€ í™•ì¸\")\n",
        "    print(\"  - JSON íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ğŸ” 7ë‹¨ê³„: ìµœì¢… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± { display-mode: \"form\" }\n",
        "#@markdown í›„ì²˜ë¦¬ê°€ ì™„ë£Œëœ JSON íŒŒì¼ë“¤ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.vectorstore_manager import VectorstoreManager\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# param.json ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…)\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "param_path = Path('misc/param.json')\n",
        "if param_path.exists():\n",
        "    with open(param_path, 'r') as f:\n",
        "        current_params = json.load(f)\n",
        "    print(f\"ğŸ” param.jsonì˜ vectorstore ê²½ë¡œ: {current_params.get('vectorstore', {}).get('folders', {}).get('vectorstore_folder', 'NOT_FOUND')}\")\n",
        "else:\n",
        "    print(\"âŒ param.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "# Vectorstore Manager ì´ˆê¸°í™” (param.jsonì—ì„œ ê²½ë¡œ ìë™ ì¸ì‹)\n",
        "print(\"ğŸ”„ VectorstoreManager ì´ˆê¸°í™” ì¤‘...\")\n",
        "\n",
        "# ì–´ë–¤ ëª¨ë“ˆì´ importë˜ëŠ”ì§€ í™•ì¸\n",
        "from src.vectorstore_manager import VectorstoreManager\n",
        "import inspect\n",
        "print(f\"ğŸ” VectorstoreManager ìœ„ì¹˜: {inspect.getfile(VectorstoreManager)}\")\n",
        "\n",
        "vectorstore_manager = VectorstoreManager()\n",
        "\n",
        "# ì´ˆê¸°í™” í›„ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ê²½ë¡œ í™•ì¸\n",
        "print(f\"ğŸ” VectorstoreManagerê°€ ì‚¬ìš©í•˜ëŠ” ê²½ë¡œ: {vectorstore_manager.params['folders']['vectorstore_folder']}\")\n",
        "print(f\"ğŸ” VectorstoreManager model_name: {getattr(vectorstore_manager, 'model_name', 'NOT_FOUND')}\")\n",
        "\n",
        "# param.jsonì—ì„œ ê²½ë¡œ ì½ì–´ì˜¤ê¸°\n",
        "param_path = Path('misc/param.json')\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "result_json_folder = Path(params['pdf_processing']['folders']['result_json_folder'])\n",
        "\n",
        "# ìµœì¢… ì²˜ë¦¬ëœ JSON íŒŒì¼ ë¡œë“œ\n",
        "final_json_folder = result_json_folder / 'final_json'\n",
        "json_files = list(final_json_folder.glob(\"*.json\"))\n",
        "\n",
        "if not json_files:\n",
        "    print(\"âŒ ìµœì¢… ì²˜ë¦¬ëœ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ 6ë‹¨ê³„ í›„ì²˜ë¦¬ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    \n",
        "    # ëŒ€ì•ˆìœ¼ë¡œ ì›ë³¸ JSON íŒŒì¼ í™•ì¸\n",
        "    original_json_folder = result_json_folder\n",
        "    original_files = list(original_json_folder.glob(\"*_combined.json\"))\n",
        "    \n",
        "    if original_files:\n",
        "        print(f\"\\nğŸ” ì›ë³¸ JSON íŒŒì¼ ë°œê²¬: {len(original_files)}ê°œ\")\n",
        "        print(\"ì›ë³¸ íŒŒì¼ë¡œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n",
        "        json_files = original_files\n",
        "        final_json_folder = original_json_folder\n",
        "    else:\n",
        "        print(\"âŒ ì²˜ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 5ë‹¨ê³„ì™€ 6ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "if json_files:\n",
        "    print(f\"ğŸ“„ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ\")\n",
        "    \n",
        "    # JSON ë°ì´í„° ë¡œë“œ\n",
        "    json_data = []\n",
        "    for json_file in json_files:\n",
        "        try:\n",
        "            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                json_data.append(data)\n",
        "            print(f\"âœ… {json_file.name} ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ {json_file.name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
        "    \n",
        "    if json_data:\n",
        "        print(f\"\\nğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘... (ì´ {len(json_data)}ê°œ íŒŒì¼)\")\n",
        "        try:\n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
        "            vectorstore = vectorstore_manager.create_vectorstore(json_data)\n",
        "            \n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥\n",
        "            vectorstore_name = \"datasheet_vectors_final\"\n",
        "            vectorstore_manager.save_vectorstore(vectorstore, vectorstore_name)\n",
        "            \n",
        "            print(\"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!\")\n",
        "            print(f\"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {vectorstore_folder}/{vectorstore_name}\")\n",
        "            print(f\"ğŸ“Š ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜: {len(json_data)}\")\n",
        "            \n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ì •ë³´ ì¶œë ¥\n",
        "            print(\"\\nğŸ“‹ ë²¡í„° ìŠ¤í† ì–´ ì •ë³´:\")\n",
        "            try:\n",
        "                model_name = getattr(vectorstore_manager, 'model_name', 'Unknown')\n",
        "                print(f\"â€¢ ì‚¬ìš©ëœ ì„ë² ë”© ëª¨ë¸: {model_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"â€¢ ì‚¬ìš©ëœ ì„ë² ë”© ëª¨ë¸: í™•ì¸ ì‹¤íŒ¨ ({str(e)})\")\n",
        "            print(f\"â€¢ ì €ì¥ í˜•ì‹: FAISS\")\n",
        "            print(f\"â€¢ ë””ë°”ì´ìŠ¤: CPU ì „ìš©\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
        "            print(\"ğŸ’¡ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:\")\n",
        "            print(\"  - HuggingFace í† í°ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
        "            print(\"  - GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸\")\n",
        "            print(\"  - JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\")\n",
        "    else:\n",
        "        print(\"âŒ ë¡œë“œëœ JSON ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ğŸ“‹ 8ë‹¨ê³„: ì²˜ë¦¬ ì™„ë£Œ ì ê²€ ë° ìš”ì•½ { display-mode: \"form\" }\n",
        "#@markdown ì „ì²´ ì²˜ë¦¬ ê³¼ì •ì„ ì‹¤ì œë¡œ ì ê²€í•˜ê³  ìš”ì•½ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ” PDF ë°ì´í„°ì‹œíŠ¸ ì „ì²˜ë¦¬ ê²°ê³¼ ì ê²€ ì¤‘...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ì ê²€ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "check_results = []\n",
        "total_score = 0\n",
        "max_score = 0\n",
        "\n",
        "def add_check(name, passed, details=\"\", critical=False):\n",
        "    global total_score, max_score\n",
        "    score = 2 if critical else 1\n",
        "    max_score += score\n",
        "    if passed:\n",
        "        total_score += score\n",
        "        status = \"âœ…\"\n",
        "    else:\n",
        "        status = \"âŒ\" if critical else \"âš ï¸\"\n",
        "    \n",
        "    check_results.append({\n",
        "        'name': name,\n",
        "        'status': status,\n",
        "        'passed': passed,\n",
        "        'details': details,\n",
        "        'critical': critical\n",
        "    })\n",
        "\n",
        "# 1. ì›ë³¸ PDF íŒŒì¼ ì ê²€\n",
        "print(\"\\n1ï¸âƒ£ ì›ë³¸ PDF íŒŒì¼ ì ê²€...\")\n",
        "if pdf_folder.exists():\n",
        "    pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
        "    add_check(\"ì›ë³¸ PDF íŒŒì¼\", len(pdf_files) > 0, f\"{len(pdf_files)}ê°œ íŒŒì¼ ë°œê²¬\", critical=True)\n",
        "else:\n",
        "    add_check(\"ì›ë³¸ PDF íŒŒì¼\", False, \"PDF í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\", critical=True)\n",
        "\n",
        "# 2. ì²˜ë¦¬ëœ JSON íŒŒì¼ ì ê²€\n",
        "print(\"2ï¸âƒ£ ì²˜ë¦¬ëœ JSON íŒŒì¼ ì ê²€...\")\n",
        "prep_json_folder = result_json_folder\n",
        "if prep_json_folder.exists():\n",
        "    combined_json_files = list(prep_json_folder.glob(\"*_combined.json\"))\n",
        "    add_check(\"ì²˜ë¦¬ëœ JSON íŒŒì¼\", len(combined_json_files) > 0, f\"{len(combined_json_files)}ê°œ íŒŒì¼ ìƒì„±\", critical=True)\n",
        "    \n",
        "    # JSON íŒŒì¼ ë‚´ìš© ìƒ˜í”Œ ì ê²€\n",
        "    if combined_json_files:\n",
        "        try:\n",
        "            with open(combined_json_files[0], 'r', encoding='utf-8') as f:\n",
        "                sample_data = json.load(f)\n",
        "            \n",
        "            has_required_fields = all(key in sample_data for key in ['filename', 'category_chunks', 'page_summaries'])\n",
        "            add_check(\"JSON êµ¬ì¡° ìœ íš¨ì„±\", has_required_fields, \n",
        "                     \"í•„ìˆ˜ í•„ë“œ (filename, category_chunks, page_summaries) í™•ì¸\")\n",
        "        except Exception as e:\n",
        "            add_check(\"JSON êµ¬ì¡° ìœ íš¨ì„±\", False, f\"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}\")\n",
        "else:\n",
        "    add_check(\"ì²˜ë¦¬ëœ JSON íŒŒì¼\", False, \"prep_json í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\", critical=True)\n",
        "\n",
        "# 3. í›„ì²˜ë¦¬ëœ ìµœì¢… JSON íŒŒì¼ ì ê²€\n",
        "print(\"3ï¸âƒ£ í›„ì²˜ë¦¬ëœ ìµœì¢… JSON íŒŒì¼ ì ê²€...\")\n",
        "final_json_folder = result_json_folder / 'final_json'\n",
        "if final_json_folder.exists():\n",
        "    final_json_files = list(final_json_folder.glob(\"*.json\"))\n",
        "    add_check(\"ìµœì¢… JSON íŒŒì¼\", len(final_json_files) > 0, f\"{len(final_json_files)}ê°œ íŒŒì¼ ìƒì„±\")\n",
        "    \n",
        "    # ì •ê·œí™”ëœ í•„ë“œ ì ê²€\n",
        "    if final_json_files:\n",
        "        try:\n",
        "            with open(final_json_files[0], 'r', encoding='utf-8') as f:\n",
        "                sample_final = json.load(f)\n",
        "            \n",
        "            has_normalized_fields = 'part number' in sample_final or 'grade' in sample_final.get('metadata', {})\n",
        "            add_check(\"í•„ë“œëª… ì •ê·œí™”\", has_normalized_fields, \"part number, grade í•„ë“œ ì •ê·œí™” í™•ì¸\")\n",
        "        except Exception as e:\n",
        "            add_check(\"í•„ë“œëª… ì •ê·œí™”\", False, f\"ìµœì¢… JSON ì ê²€ ì˜¤ë¥˜: {str(e)}\")\n",
        "else:\n",
        "    add_check(\"ìµœì¢… JSON íŒŒì¼\", False, \"final_json í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\")\n",
        "\n",
        "# 4. ë²¡í„° ìŠ¤í† ì–´ ì ê²€\n",
        "print(\"4ï¸âƒ£ ë²¡í„° ìŠ¤í† ì–´ ì ê²€...\")\n",
        "vectorstore_path = vectorstore_folder / 'datasheet_vectors_final'\n",
        "if vectorstore_path.exists():\n",
        "    # FAISS ì¸ë±ìŠ¤ íŒŒì¼ë“¤ í™•ì¸\n",
        "    index_file = vectorstore_path / 'index.faiss'\n",
        "    pkl_file = vectorstore_path / 'index.pkl'\n",
        "    \n",
        "    faiss_files_exist = index_file.exists() and pkl_file.exists()\n",
        "    add_check(\"ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼\", faiss_files_exist, \n",
        "             f\"FAISS ì¸ë±ìŠ¤ íŒŒì¼ {'ì¡´ì¬' if faiss_files_exist else 'ëˆ„ë½'}\", critical=True)\n",
        "    \n",
        "    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
        "    if faiss_files_exist:\n",
        "        try:\n",
        "            from src.vectorstore_manager import VectorstoreManager\n",
        "            test_vm = VectorstoreManager()\n",
        "            test_vectorstore = test_vm.load_vectorstore('datasheet_vectors_final')\n",
        "            \n",
        "            # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "            test_results = test_vectorstore.similarity_search(\"test\", k=1)\n",
        "            add_check(\"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ\", True, f\"ë¡œë“œ ì„±ê³µ, {len(test_results)}ê°œ ê²€ìƒ‰ ê²°ê³¼\")\n",
        "            \n",
        "            # ë²¡í„° ìŠ¤í† ì–´ ì •ë³´ í™•ì¸\n",
        "            if hasattr(test_vectorstore, 'index') and hasattr(test_vectorstore.index, 'ntotal'):\n",
        "                doc_count = test_vectorstore.index.ntotal\n",
        "                add_check(\"ë²¡í„° ìŠ¤í† ì–´ ë‚´ìš©\", doc_count > 0, f\"ì´ {doc_count}ê°œ ë¬¸ì„œ ë²¡í„°í™”ë¨\")\n",
        "            else:\n",
        "                add_check(\"ë²¡í„° ìŠ¤í† ì–´ ë‚´ìš©\", False, \"ë¬¸ì„œ ê°œìˆ˜ í™•ì¸ ë¶ˆê°€\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            add_check(\"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ\", False, f\"ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
        "else:\n",
        "    add_check(\"ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼\", False, \"datasheet_vectors_final í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\", critical=True)\n",
        "\n",
        "# param.jsonì—ì„œ ê²½ë¡œ ì½ì–´ì˜¤ê¸°\n",
        "param_path = Path('misc/param.json')\n",
        "with open(param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "pdf_folder = Path(params['pdf_processing']['folders']['pdf_folder'])\n",
        "result_json_folder = Path(params['pdf_processing']['folders']['result_json_folder'])\n",
        "\n",
        "# 5. ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF ì ê²€\n",
        "print(\"5ï¸âƒ£ ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF ì ê²€...\")\n",
        "not_processed_folder = pdf_folder / 'notprocessed'\n",
        "if not_processed_folder.exists():\n",
        "    not_processed_files = list(not_processed_folder.glob(\"*.pdf\"))\n",
        "    add_check(\"ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF\", True, f\"{len(not_processed_files)}ê°œ íŒŒì¼ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)\")\n",
        "else:\n",
        "    add_check(\"ì²˜ë¦¬ë˜ì§€ ì•Šì€ PDF\", True, \"notprocessed í´ë” ì—†ìŒ (ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ë¨)\")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“Š ì ê²€ ê²°ê³¼ ìš”ì•½:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for result in check_results:\n",
        "    details_str = f\" - {result['details']}\" if result['details'] else \"\"\n",
        "    print(f\"{result['status']} {result['name']}{details_str}\")\n",
        "\n",
        "# ì ìˆ˜ ê³„ì‚°\n",
        "score_percentage = (total_score / max_score * 100) if max_score > 0 else 0\n",
        "print(f\"\\nğŸ¯ ì „ì²´ ì ìˆ˜: {total_score}/{max_score} ({score_percentage:.1f}%)\")\n",
        "\n",
        "# ìƒíƒœ íŒì •\n",
        "critical_failures = [r for r in check_results if not r['passed'] and r['critical']]\n",
        "if critical_failures:\n",
        "    print(\"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
        "    for failure in critical_failures:\n",
        "        print(f\"   â€¢ {failure['name']}: {failure['details']}\")\n",
        "    print(\"\\nğŸ’¡ ìœ„ ë¬¸ì œë“¤ì„ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "elif score_percentage >= 80:\n",
        "    print(\"âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(\"\\nğŸ“ ì£¼ìš” íŒŒì¼ ìœ„ì¹˜:\")\n",
        "    print(f\"â€¢ ì›ë³¸ PDF: {pdf_folder}\")\n",
        "    print(f\"â€¢ ìµœì¢… JSON: {final_json_folder}\")\n",
        "    print(f\"â€¢ ë²¡í„° ìŠ¤í† ì–´: {vectorstore_path}\")\n",
        "    \n",
        "    print(\"\\nğŸš€ ì´ì œ ì±—ë´‡ ì‹œìŠ¤í…œì—ì„œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
        "else:\n",
        "    print(\"âš ï¸ ì¼ë¶€ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ ê²½ê³ ì‚¬í•­ë“¤ì„ ê²€í† í•˜ê³  í•„ìš”ì‹œ í•´ë‹¹ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "prep_main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

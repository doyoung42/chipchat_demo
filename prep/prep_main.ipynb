{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# ğŸ“Š PDF ë°ì´í„°ì‹œíŠ¸ ì „ì²˜ë¦¬ ë„êµ¬\n",
        "\n",
        "**ë°ì´í„°ì‹œíŠ¸ PDFë¥¼ ë¶„ì„í•˜ì—¬ ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  JSON í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ PDF ë°ì´í„°ì‹œíŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‚˜ì¤‘ì— ì±—ë´‡ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” JSON íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ë¶„í•  ë°©ì‹ìœ¼ë¡œ PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
        "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title âœ… 1ë‹¨ê³„: Google Drive ì—°ë™ { display-mode: \"form\" }\n",
        "#@markdown Google Driveë¥¼ ì—°ë™í•˜ì—¬ PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬ëœ JSON íŒŒì¼ê³¼ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ”„ Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# í´ë” ê²½ë¡œ ì„¤ì •\n",
        "pdf_folder = Path('/content/drive/MyDrive/datasheets')\n",
        "result_json_folder = Path('/content/drive/MyDrive/prep_json')\n",
        "vectorstore_folder = Path('/content/drive/MyDrive/vectorstore')\n",
        "\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "#pdf_folder.mkdir(parents=True, exist_ok=True)\n",
        "result_json_folder.mkdir(parents=True, exist_ok=True)\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nâœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“ PDF í´ë”: {pdf_folder}\")\n",
        "print(f\"ğŸ“ JSON ì €ì¥ í´ë”: {result_json_folder}\")\n",
        "print(f\"ğŸ“ ë²¡í„° ìŠ¤í† ì–´ í´ë”: {vectorstore_folder}\")\n",
        "\n",
        "# PDF íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
        "print(f\"\\nğŸ“„ ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ\")\n",
        "for pdf in pdf_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
        "    print(f\" - {pdf.name}\")\n",
        "    \n",
        "if len(pdf_files) > 5:\n",
        "    print(f\" ... ì™¸ {len(pdf_files) - 5}ê°œ\")\n",
        "\n",
        "if not pdf_files:\n",
        "    print(\"\\nâš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. '{pdf_folder}' í´ë”ì— PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“¥ 2ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
        "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ“¥ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
        "\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”‘ 3ë‹¨ê³„: API í‚¤ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì—¬ PDF ë¶„ì„ì„ ìœ„í•œ LLMì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "import os\n",
        "\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"â€¢ OpenAI API í‚¤: https://platform.openai.com/api-keys\")\n",
        "    print(\"â€¢ Claude API í‚¤: https://console.anthropic.com/keys\")\n",
        "    print(\"â€¢ HuggingFace í† í°: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
        "    if openai_api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        print(\"âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
        "        \n",
        "    if claude_api_key:\n",
        "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
        "        print(\"âœ… Claude API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
        "    \n",
        "    if hf_token:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        print(\"âœ… HuggingFace í† í° ì„¤ì • ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“Š 4ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ ì„¤ì • { display-mode: \"form\" }\n",
        "#@markdown PDF ì²˜ë¦¬ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "# ì²­í¬ í¬ê¸° ì„¤ì • (í•œ ë²ˆì— ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜)\n",
        "chunk_size = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "provider = \"openai\" #@param [\"openai\", \"claude\"]\n",
        "\n",
        "print(f\"ğŸ“ PDF ì²˜ë¦¬ ì„¤ì •:\")\n",
        "print(f\" - ì²­í¬ í¬ê¸°: {chunk_size} í˜ì´ì§€\")\n",
        "print(f\" - LLM ì œê³µì: {provider}\")\n",
        "\n",
        "# API í‚¤ í™•ì¸\n",
        "if provider == \"openai\" and \"OPENAI_API_KEY\" not in os.environ:\n",
        "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 3ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "elif provider == \"claude\" and \"ANTHROPIC_API_KEY\" not in os.environ:\n",
        "    print(\"âŒ Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 3ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    print(\"âœ… ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“„ 5ë‹¨ê³„: PDF íŒŒì¼ ì²˜ë¦¬ (ë‹¨ì¼ íŒŒì¼) { display-mode: \"form\" }\n",
        "#@markdown ì„ íƒí•œ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.pdf_processor import PDFProcessor\n",
        "import json\n",
        "import os\n",
        "\n",
        "# í•„ìš”í•œ API í‚¤ ì„¤ì • í™•ì¸\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\" if provider == \"openai\" else \"ANTHROPIC_API_KEY\", \"\")\n",
        "claude_api_key = os.environ.get(\"ANTHROPIC_API_KEY\", \"\") if provider == \"claude\" else None\n",
        "\n",
        "if not api_key:\n",
        "    print(f\"âŒ {provider.capitalize()} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 3ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    # PDF ì²˜ë¦¬ê¸° ì´ˆê¸°í™”\n",
        "    processor = PDFProcessor(api_key, provider, claude_api_key, chunk_size)\n",
        "    \n",
        "    # ì²˜ë¦¬í•  PDF íŒŒì¼ ì„ íƒ\n",
        "    if not pdf_files:\n",
        "        print(\"âŒ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Google Driveì— íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "    else:\n",
        "        print(\"ğŸ“ ì²˜ë¦¬í•  PDF íŒŒì¼ ëª©ë¡:\")\n",
        "        for i, pdf in enumerate(pdf_files):\n",
        "            print(f\"{i+1}. {pdf.name}\")\n",
        "            \n",
        "        # PDF ì¸ë±ìŠ¤ ì…ë ¥ (1ë¶€í„° ì‹œì‘)\n",
        "        pdf_index = 1  #@param {type:\"integer\"}\n",
        "        \n",
        "        if pdf_index < 1 or pdf_index > len(pdf_files):\n",
        "            print(f\"âŒ ì˜ëª»ëœ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤. 1ì—ì„œ {len(pdf_files)} ì‚¬ì´ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "        else:\n",
        "            # ì„ íƒí•œ PDF ì²˜ë¦¬\n",
        "            selected_pdf = pdf_files[pdf_index-1]\n",
        "            print(f\"\\nğŸ” '{selected_pdf.name}' íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...\")\n",
        "            print(f\"âš™ï¸ ì²˜ë¦¬ ë°©ì‹: ì²­í¬ í¬ê¸° {chunk_size} í˜ì´ì§€ë¡œ ë¶„í•  ì²˜ë¦¬\")\n",
        "            print(\"â³ ì´ ì‘ì—…ì€ ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...\")\n",
        "            \n",
        "            try:\n",
        "                features, useful_pages = processor.process_pdf(str(selected_pdf))\n",
        "                \n",
        "                # ê²°ê³¼ ì €ì¥\n",
        "                if features:\n",
        "                    output_file = result_json_folder / f\"{selected_pdf.stem}.json\"\n",
        "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                        json.dump(features, f, indent=2, ensure_ascii=False)\n",
        "                        \n",
        "                    print(f\"\\nâœ… ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "                    print(f\"ğŸ“„ ì¶”ì¶œëœ ìœ ìš©í•œ í˜ì´ì§€: {useful_pages}\")\n",
        "                    print(f\"ğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}\")\n",
        "                    print(\"\\nğŸ“Š ì¶”ì¶œëœ ì •ë³´ ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "                    print(json.dumps(features, indent=2, ensure_ascii=False)[:500] + '...')\n",
        "                else:\n",
        "                    print(\"âŒ ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB2"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”„ 6ë‹¨ê³„: ëª¨ë“  PDF íŒŒì¼ ì¼ê´„ ì²˜ë¦¬ { display-mode: \"form\" }\n",
        "#@markdown ëª¨ë“  PDF íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n",
        "\n",
        "import os\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# í•„ìš”í•œ API í‚¤ ì„¤ì • í™•ì¸\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\" if provider == \"openai\" else \"ANTHROPIC_API_KEY\", \"\")\n",
        "claude_api_key = os.environ.get(\"ANTHROPIC_API_KEY\", \"\") if provider == \"claude\" else None\n",
        "\n",
        "if not api_key:\n",
        "    print(f\"âŒ {provider.capitalize()} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 3ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    # PDF ì²˜ë¦¬ê¸° ì´ˆê¸°í™”\n",
        "    processor = PDFProcessor(api_key, provider, claude_api_key, chunk_size)\n",
        "    \n",
        "    # ì²˜ë¦¬í•  PDF íŒŒì¼ í™•ì¸\n",
        "    if not pdf_files:\n",
        "        print(\"âŒ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Google Driveì— íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "    else:\n",
        "        # ì¼ê´„ ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸\n",
        "        confirm = True  #@param {type:\"boolean\"}\n",
        "        \n",
        "        if confirm:\n",
        "            print(f\"ğŸ”„ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...\")\n",
        "            print(f\"âš™ï¸ ì²˜ë¦¬ ë°©ì‹: ì²­í¬ í¬ê¸° {chunk_size} í˜ì´ì§€ë¡œ ë¶„í•  ì²˜ë¦¬\")\n",
        "            print(\"â³ ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...\")\n",
        "            \n",
        "            # ì²˜ë¦¬ ê²°ê³¼ ì €ì¥\n",
        "            results = {}\n",
        "            \n",
        "            # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ\n",
        "            for pdf in tqdm(pdf_files, desc=\"PDF ì²˜ë¦¬ ì¤‘\"):\n",
        "                try:\n",
        "                    features, useful_pages = processor.process_pdf(str(pdf))\n",
        "                    \n",
        "                    if features:\n",
        "                        # ê²°ê³¼ ì €ì¥\n",
        "                        output_file = result_json_folder / f\"{pdf.stem}.json\"\n",
        "                        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                            json.dump(features, f, indent=2, ensure_ascii=False)\n",
        "                        \n",
        "                        results[pdf.name] = {\n",
        "                            \"status\": \"ì„±ê³µ\",\n",
        "                            \"useful_pages\": useful_pages,\n",
        "                            \"output_file\": str(output_file)\n",
        "                        }\n",
        "                    else:\n",
        "                        results[pdf.name] = {\n",
        "                            \"status\": \"ì‹¤íŒ¨\",\n",
        "                            \"reason\": \"ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
        "                        }\n",
        "                except Exception as e:\n",
        "                    results[pdf.name] = {\n",
        "                        \"status\": \"ì˜¤ë¥˜\",\n",
        "                        \"reason\": str(e)\n",
        "                    }\n",
        "            \n",
        "            # ê²°ê³¼ ìš”ì•½\n",
        "            success_count = sum(1 for result in results.values() if result[\"status\"] == \"ì„±ê³µ\")\n",
        "            failed_count = len(results) - success_count\n",
        "            \n",
        "            print(f\"\\nâœ… ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(results)}ê°œ ì¤‘ {success_count}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨\")\n",
        "            print(f\"ğŸ’¾ ê²°ê³¼ê°€ '{result_json_folder}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "            \n",
        "            if failed_count > 0:\n",
        "                print(\"\\nâš ï¸ ì‹¤íŒ¨í•œ íŒŒì¼:\")\n",
        "                for name, result in results.items():\n",
        "                    if result[\"status\"] != \"ì„±ê³µ\":\n",
        "                        print(f\" - {name}: {result.get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\")\n",
        "        else:\n",
        "            print(\"âŒ ì¼ê´„ ì²˜ë¦¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDvBVwkBAuMC"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”„ 7ë‹¨ê³„: ë²¡í„° ìŠ¤í† ì–´ ìƒì„± { display-mode: \"form\" }\n",
        "#@markdown ì²˜ë¦¬ëœ JSON íŒŒì¼ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "from src.vectorstore_manager import VectorstoreManager\n",
        "import os\n",
        "\n",
        "# HF í† í° ê°€ì ¸ì˜¤ê¸°\n",
        "hf_token = os.environ.get(\"HF_TOKEN\", \"\")\n",
        "if not hf_token:\n",
        "    print(\"âŒ HuggingFace í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 3ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    # ë²¡í„° ìŠ¤í† ì–´ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "    vectorstore_manager = VectorstoreManager(hf_token=hf_token)\n",
        "    \n",
        "    # JSON íŒŒì¼ í™•ì¸\n",
        "    if not result_json_folder.exists():\n",
        "        print(\"âŒ JSON í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        # JSON íŒŒì¼ ë¡œë“œ\n",
        "        try:\n",
        "            json_data = vectorstore_manager.load_json_files(str(result_json_folder))\n",
        "            \n",
        "            if not json_data:\n",
        "                print(\"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDF íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\")\n",
        "            else:\n",
        "                print(f\"âœ… {len(json_data)}ê°œì˜ JSON íŒŒì¼ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "                print(\"\\nğŸ”„ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "                \n",
        "                # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
        "                vectorstore = vectorstore_manager.create_vectorstore(json_data)\n",
        "                \n",
        "                # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥\n",
        "                print(\"\\nğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "                vectorstore_manager.save_vectorstore(vectorstore, str(vectorstore_folder))\n",
        "                \n",
        "                print(f\"\\nâœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {vectorstore_folder}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!\n",
        "\n",
        "PDF íŒŒì¼ ì²˜ë¦¬ì™€ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ì²˜ë¦¬ëœ JSON íŒŒì¼ì€ Google Driveì˜ `prep_json` í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "- ë²¡í„° ìŠ¤í† ì–´ëŠ” Google Driveì˜ `vectorstore` í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì œ ChipChat ëª¨ë“ˆì—ì„œ ì´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ë°ì´í„°ì‹œíŠ¸ì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

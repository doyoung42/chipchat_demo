{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# 💬 ChipChat - 데이터시트 챗봇\n",
        "\n",
        "**전처리된 데이터시트 JSON 파일을 기반으로 질의응답을 수행하는 챗봇입니다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 시작하기 전에\n",
        "\n",
        "이 노트북은 Google Colab에서 개선된 ChipChat 앱을 실행하는 방법을 제공합니다.\n",
        "\n",
        "⚠️ **중요**: 이 노트북은 반드시 **새로운 Colab 세션**에서 실행해주세요.\n",
        "- 이전에 `prep_main.ipynb`를 실행했다면, 새로운 세션을 시작해주세요.\n",
        "- 이는 의존성 충돌과 경로 문제를 방지하기 위함입니다.\n",
        "\n",
        "## ✨ 새로운 기능들 (v2.0)\n",
        "- 🤖 **AI Agent 시스템**: LangGraph 기반 스마트 에이전트\n",
        "- 🔧 **3가지 Tool 자동 선택**: chipDB 검색, 벡터스토어 검색, PDF 처리\n",
        "- 📊 **ChipDB.csv 연동**: 부품 사양 요약 데이터베이스 활용\n",
        "- 🎯 **다중 LLM 지원**: OpenAI와 Claude 모델 선택 가능\n",
        "- 📄 **실시간 PDF 업로드**: 새 데이터시트 자동 처리 및 통합\n",
        "- 🔍 **고급 필터링**: 부품번호, 제조사, 카테고리별 검색\n",
        "- 🛠️ **프롬프트 커스터마이징**: 시스템 프롬프트 자유 수정\n",
        "- 🏷️ **메타데이터 추적**: 소스 정보 표시\n",
        "\n",
        "## 📋 사용 방법\n",
        "아래 셀들을 **순서대로 실행**만 하면 됩니다. (각 셀의 ▶️ 버튼을 클릭)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ✅ 1단계: Google Drive 연동 { display-mode: \"form\" }\n",
        "#@markdown Google Drive를 연동하여 전처리된 JSON 파일과 벡터 스토어를 관리합니다.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔄 Google Drive 마운트 중...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 폴더 설정\n",
        "prep_json_folder = Path('/content/drive/MyDrive/prep_json')  # chipDB.csv 위치\n",
        "vectorstore_folder = Path('/content/drive/MyDrive/vectorstore')\n",
        "prompt_templates_folder = Path('/content/drive/MyDrive/prompt_templates')\n",
        "\n",
        "# 필요한 폴더들 생성\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "prompt_templates_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\n✅ Google Drive 연동 완료!\")\n",
        "print(f\"📁 전처리 데이터 폴더: {prep_json_folder}\")\n",
        "print(f\"📁 벡터 스토어 폴더: {vectorstore_folder}\")\n",
        "print(f\"📁 프롬프트 템플릿 폴더: {prompt_templates_folder}\")\n",
        "\n",
        "# chipDB.csv 파일 확인\n",
        "chipdb_file = prep_json_folder / 'chipDB.csv'\n",
        "if chipdb_file.exists():\n",
        "    # 파일 크기 확인 (적절한 단위로 표시)\n",
        "    file_size_bytes = chipdb_file.stat().st_size\n",
        "    if file_size_bytes < 1024:\n",
        "        file_size_str = f\"{file_size_bytes} bytes\"\n",
        "    elif file_size_bytes < 1024 * 1024:\n",
        "        file_size_str = f\"{file_size_bytes / 1024:.1f} KB\"\n",
        "    else:\n",
        "        file_size_str = f\"{file_size_bytes / 1024 / 1024:.1f} MB\"\n",
        "    \n",
        "    print(f\"\\n📊 chipDB.csv 발견: {file_size_str}\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ chipDB.csv 파일이 없습니다: {chipdb_file}\")\n",
        "\n",
        "# Vectorstore 파일 확인 (하위 폴더 포함)\n",
        "vectorstore_files = []\n",
        "for ext in ['*.index', '*.faiss', '*.pkl', '*.parquet']:\n",
        "    vectorstore_files.extend(list(vectorstore_folder.glob(f\"**/{ext}\")))\n",
        "\n",
        "print(f\"\\n🗄️ 발견된 Vectorstore 파일: {len(vectorstore_files)}개\")\n",
        "vectorstore_folders = set()\n",
        "for vs_file in vectorstore_files[:10]:  # 처음 10개만 표시\n",
        "    relative_path = vs_file.relative_to(vectorstore_folder)\n",
        "    vectorstore_folders.add(str(relative_path.parent))\n",
        "    print(f\" - {relative_path}\")\n",
        "\n",
        "if len(vectorstore_files) > 10:\n",
        "    print(f\" ... 외 {len(vectorstore_files) - 10}개\")\n",
        "\n",
        "# 발견된 vectorstore 폴더들 표시\n",
        "if vectorstore_folders and vectorstore_folders != {'.'}:\n",
        "    print(f\"\\n📁 Vectorstore 폴더들:\")\n",
        "    for folder in sorted(vectorstore_folders):\n",
        "        if folder != '.':\n",
        "            print(f\" - {folder}\")\n",
        "\n",
        "# 상태 확인 및 경고\n",
        "if not chipdb_file.exists() and not vectorstore_files:\n",
        "    print(\"\\n⚠️ chipDB.csv와 Vectorstore가 모두 없습니다.\")\n",
        "    print(\"💡 prep_main.ipynb를 먼저 실행하여 데이터를 전처리해주세요.\")\n",
        "elif not chipdb_file.exists():\n",
        "    print(\"\\n⚠️ chipDB.csv 파일이 없습니다. prep_main.ipynb로 chipDB.csv를 생성해주세요.\")\n",
        "elif not vectorstore_files:\n",
        "    print(\"\\n⚠️ Vectorstore가 없습니다. prep_main.ipynb로 Vectorstore를 생성해주세요.\")\n",
        "else:\n",
        "    print(\"\\n✅ chipDB.csv와 Vectorstore가 모두 준비되었습니다!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 📥 2단계: 필요한 라이브러리 설치 { display-mode: \"form\" }\n",
        "#@markdown 필요한 라이브러리들을 설치합니다.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"📥 필요한 라이브러리 설치 중...\")\n",
        "\n",
        "# GitHub 저장소 클론\n",
        "try:\n",
        "    if not Path('chipchat').exists():\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat_demo.git'], check=True)\n",
        "        print(\"✅ GitHub 저장소 클론 완료\")\n",
        "    else:\n",
        "        print(\"✅ GitHub 저장소 이미 존재\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ GitHub 클론 실패: {str(e)}\")\n",
        "\n",
        "# 디렉토리 이동\n",
        "os.chdir('chipchat_demo')\n",
        "\n",
        "# requirements.txt 설치\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
        "    print(\"✅ Requirements 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Requirements 설치 실패: {str(e)}\")\n",
        "\n",
        "# 추가 패키지 설치 (Colab 전용)\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
        "    print(\"✅ pyngrok 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ pyngrok 설치 실패: {str(e)}\")\n",
        "\n",
        "# 현재 디렉토리 설정\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "# 새로운 디렉토리 구조 추가\n",
        "src_dir = current_dir / 'src'\n",
        "if src_dir.exists():\n",
        "    sys.path.append(str(src_dir))\n",
        "    for subdir in ['config', 'models', 'utils', 'app']:\n",
        "        subdir_path = src_dir / subdir\n",
        "        if subdir_path.exists():\n",
        "            sys.path.append(str(subdir_path))\n",
        "\n",
        "print(\"\\n✅ 라이브러리 설치 및 경로 설정 완료!\")\n",
        "print(\"\\n📋 지원되는 LLM 모델:\")\n",
        "print(\"🔸 OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
        "print(\"🔸 Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 🔑 3단계: API 키 설정 { display-mode: \"form\" }\n",
        "#@markdown AI 서비스의 API 키를 입력하여 챗봇을 설정합니다.\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# API 키 유효성 검사\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"⚠️ API 키가 입력되지 않았습니다.\")\n",
        "    print(\"💡 최소 하나 이상의 API 키를 입력해주세요.\")\n",
        "    print(\"• OpenAI API 키: https://platform.openai.com/api-keys\")\n",
        "    print(\"• Claude API 키: https://console.anthropic.com/keys\")\n",
        "    print(\"• HuggingFace 토큰: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # 환경 변수 설정\n",
        "    if openai_api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        print(\"✅ OpenAI API 키 설정 완료!\")\n",
        "        \n",
        "    if claude_api_key:\n",
        "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
        "        print(\"✅ Claude API 키 설정 완료!\")\n",
        "    \n",
        "    if hf_token:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        print(\"✅ HuggingFace 토큰 설정 완료!\")\n",
        "    \n",
        "    # Streamlit 시크릿 파일 생성\n",
        "    secrets_dir = Path(\".streamlit\")\n",
        "    secrets_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    secrets = {}\n",
        "    if openai_api_key:\n",
        "        secrets[\"openai_api_key\"] = openai_api_key\n",
        "    if claude_api_key:\n",
        "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
        "    if hf_token:\n",
        "        secrets[\"hf_token\"] = hf_token\n",
        "    \n",
        "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
        "        for key, value in secrets.items():\n",
        "            f.write(f'{key} = \"{value}\"\\n')\n",
        "    \n",
        "    # 토큰 저장\n",
        "    try:\n",
        "        from src.config.token_manager import TokenManager\n",
        "        token_manager = TokenManager()\n",
        "        \n",
        "        if openai_api_key:\n",
        "            token_manager.set_token('openai', openai_api_key)\n",
        "        \n",
        "        if claude_api_key:\n",
        "            token_manager.set_token('anthropic', claude_api_key)\n",
        "        \n",
        "        if hf_token:\n",
        "            token_manager.set_token('huggingface', hf_token)\n",
        "            \n",
        "        print(\"✅ 토큰 관리자에 API 키 저장 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 토큰 저장 중 오류가 발생했습니다: {str(e)}\")\n",
        "    \n",
        "    # 기본 프롬프트 템플릿 생성\n",
        "    default_template = {\n",
        "        \"pre\": \"당신은 전자 부품 데이터시트에 대해 응답하는 도우미입니다. 제공된 컨텍스트 정보를 기반으로 질문에 답변하세요.\",\n",
        "        \"post\": \"검색된 정보를 바탕으로 명확하고 간결하게 답변해주세요.\"\n",
        "    }\n",
        "    \n",
        "    template_file = prompt_templates_folder / \"default_template.json\"\n",
        "    if not template_file.exists():\n",
        "        with open(template_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(default_template, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "        print(\"✅ 기본 프롬프트 템플릿이 생성되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title 📊 4단계: Streamlit 서버 실행 { display-mode: \"form\" }\n",
        "#@markdown Streamlit 서비스를 실행하여 웹 인터페이스를 제공합니다.\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# 환경 변수 설정\n",
        "os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
        "os.environ['JSON_FOLDER_PATH'] = str(prep_json_folder)  # chipDB.csv가 있는 폴더\n",
        "os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
        "\n",
        "# Streamlit 실행 함수\n",
        "def run_streamlit():\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \n",
        "        \"src/app/streamlit_app.py\",\n",
        "        \"--server.port=8501\", \n",
        "        \"--server.address=0.0.0.0\",  # 외부 접속 허용\n",
        "        \"--server.headless=true\",\n",
        "        \"--browser.serverAddress=localhost\",\n",
        "        \"--browser.gatherUsageStats=false\"\n",
        "    ]\n",
        "    process = subprocess.Popen(\n",
        "        cmd, \n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE\n",
        "    )\n",
        "    \n",
        "    return process\n",
        "\n",
        "# ngrok 사용 여부 선택\n",
        "use_ngrok = False #@param {type:\"boolean\"}\n",
        "ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Streamlit 서버 실행\n",
        "print(\"🚀 Streamlit 서버를 시작합니다...\")\n",
        "process = run_streamlit()\n",
        "time.sleep(8)  # 서버 시작 대기\n",
        "\n",
        "if use_ngrok and ngrok_token:\n",
        "    # ngrok 사용 (외부 접속 가능한 공개 URL)\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "        public_url = ngrok.connect(8501).public_url\n",
        "        print(f\"\\n✅ 서버가 시작되었습니다! (ngrok 사용)\")\n",
        "        print(f\"\\n🔗 다음 URL을 통해 ChipChat에 접속할 수 있습니다:\")\n",
        "        print(f\"📱 {public_url}\")\n",
        "        print(\"\\n이 URL은 세션이 유지되는 동안에만 유효합니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ngrok 연결 실패: {str(e)}\")\n",
        "        print(\"Google Colab 내장 기능을 사용합니다.\")\n",
        "        use_ngrok = False\n",
        "\n",
        "if not use_ngrok:\n",
        "    # Google Colab 내장 기능 사용 (권장)\n",
        "    print(f\"\\n✅ 서버가 시작되었습니다! (Colab 내장 기능 사용)\")\n",
        "    print(f\"\\n🔗 ChipChat에 접속하는 방법:\")\n",
        "    print(f\"1️⃣ 포트 8501에서 실행 중입니다\")\n",
        "    print(f\"2️⃣ 아래 버튼을 클릭하거나, 왼쪽 사이드바에서 '포트' 탭을 확인하세요\")\n",
        "    \n",
        "    # Colab의 포트 포워딩 기능 활용\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_window(8501)\n",
        "\n",
        "print(f\"\\n💡 팁: 앱이 로딩되는데 몇 초 정도 걸릴 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title 🛑 5단계: 서버 중지 { display-mode: \"form\" }\n",
        "#@markdown 작업을 마치면 서버를 중지합니다.\n",
        "\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "\n",
        "# 서버 중지 여부 확인\n",
        "stop_server = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if stop_server:\n",
        "    # ngrok 터널 종료 (ngrok 사용한 경우에만)\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.kill()\n",
        "        print(\"✅ ngrok 터널이 종료되었습니다.\")\n",
        "    except ImportError:\n",
        "        # pyngrok이 import되지 않은 경우 (정상적인 상황)\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        # ngrok 관련 다른 오류\n",
        "        print(f\"ℹ️ ngrok 종료: {str(e)}\")\n",
        "    \n",
        "    # Streamlit 프로세스 종료\n",
        "    try:\n",
        "        # 모든 streamlit 프로세스 종료\n",
        "        subprocess.run(['pkill', '-f', 'streamlit'], check=False)\n",
        "        print(\"✅ Streamlit 서버가 종료되었습니다.\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Streamlit 서버 종료 중 오류가 발생했습니다.\")\n",
        "        print(\"💡 수동으로 런타임을 재시작하여 서버를 종료할 수 있습니다.\")\n",
        "    \n",
        "    print(\"\\n🔄 런타임을 재시작하면 모든 프로세스가 완전히 종료됩니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuVxGUEAuMB"
      },
      "source": [
        "---\n",
        "\n",
        "## 🛠️ 문제 해결\n",
        "\n",
        "**애플리케이션이 실행되지 않는 경우:**\n",
        "\n",
        "1. **API 키 확인**: OpenAI API 키가 올바르게 입력되었는지 확인\n",
        "2. **세션 재시작**: 런타임 → 세션 재시작 후 처음부터 다시 실행\n",
        "3. **JSON 파일 확인**: 전처리된 JSON 파일이 Google Drive에 존재하는지 확인\n",
        "\n",
        "**사용 중 문제가 발생하는 경우:**\n",
        "- 브라우저를 새로고침하세요\n",
        "- 네트워크 연결 상태를 확인하세요\n",
        "\n",
        "---\n",
        "\n",
        "## 📞 지원\n",
        "\n",
        "추가 도움이 필요하시면 GitHub 이슈를 등록해주세요:\n",
        "🔗 https://github.com/doyoung42/chipchat/issues\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

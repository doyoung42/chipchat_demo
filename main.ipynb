{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# 💬 ChipChat - 데이터시트 챗봇\n",
        "\n",
        "**전처리된 데이터시트 JSON 파일을 기반으로 질의응답을 수행하는 챗봇입니다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 시작하기 전에\n",
        "\n",
        "이 노트북은 Google Colab에서 개선된 ChipChat 앱을 실행하는 방법을 제공합니다.\n",
        "\n",
        "⚠️ **중요**: 이 노트북은 반드시 **새로운 Colab 세션**에서 실행해주세요.\n",
        "- 이전에 `prep_main.ipynb`를 실행했다면, 새로운 세션을 시작해주세요.\n",
        "- 이는 의존성 충돌과 경로 문제를 방지하기 위함입니다.\n",
        "\n",
        "## ✨ 새로운 기능들 (v2.0)\n",
        "- 🤖 **AI Agent 시스템**: LangGraph 기반 스마트 에이전트\n",
        "- 🔧 **3가지 Tool 자동 선택**: chipDB 검색, 벡터스토어 검색, PDF 처리\n",
        "- 📊 **ChipDB.csv 연동**: 부품 사양 요약 데이터베이스 활용\n",
        "- 🎯 **다중 LLM 지원**: OpenAI와 Claude 모델 선택 가능\n",
        "- 📄 **실시간 PDF 업로드**: 새 데이터시트 자동 처리 및 통합\n",
        "- 🔍 **고급 필터링**: 부품번호, 제조사, 카테고리별 검색\n",
        "- 🛠️ **프롬프트 커스터마이징**: 시스템 프롬프트 자유 수정\n",
        "- 🏷️ **메타데이터 추적**: 소스 정보 표시\n",
        "\n",
        "## 📋 사용 방법\n",
        "아래 셀들을 **순서대로 실행**만 하면 됩니다. (각 셀의 ▶️ 버튼을 클릭)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ✅ 1단계: Google Drive 연동 { display-mode: \"form\" }\n",
        "#@markdown Google Drive를 연동하여 전처리된 JSON 파일과 벡터 스토어를 관리합니다.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔄 Google Drive 마운트 중...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# JSON 및 벡터 스토어 폴더 설정\n",
        "json_folder = Path('/content/drive/MyDrive/json_key')\n",
        "vectorstore_folder = Path('/content/drive/MyDrive/vectorstore')\n",
        "prompt_templates_folder = Path('/content/drive/MyDrive/prompt_templates')\n",
        "\n",
        "# 폴더가 없으면 생성\n",
        "json_folder.mkdir(parents=True, exist_ok=True)\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "prompt_templates_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\n✅ Google Drive 연동 완료!\")\n",
        "print(f\"📁 JSON 폴더: {json_folder}\")\n",
        "print(f\"📁 벡터 스토어 폴더: {vectorstore_folder}\")\n",
        "print(f\"📁 프롬프트 템플릿 폴더: {prompt_templates_folder}\")\n",
        "\n",
        "# Vectorestore 생성 확인\n",
        "vectorstore_files = list(json_folder.glob(\"*.json\"))\n",
        "print(f\"\\n📄 발견된 store : {len(vectorstore_files)}개\")\n",
        "for json_file in vectorstore_files[:5]:  # 처음 5개만 표시\n",
        "    print(f\" - {json_file.name}\")\n",
        "    \n",
        "if len(vectorstore_files) > 5:\n",
        "    print(f\" ... 외 {len(vectorstore_files) - 5}개\")\n",
        "\n",
        "if not vectorstore_files:\n",
        "    print(\"\\n⚠️ Vectorstore가 없습니다. PDF 전처리 모듈을 먼저 실행하여 Vectorstore를 생성해주세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 📥 2단계: 필요한 라이브러리 설치 { display-mode: \"form\" }\n",
        "#@markdown 필요한 라이브러리들을 설치합니다.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"📥 필요한 라이브러리 설치 중...\")\n",
        "\n",
        "# GitHub 저장소 클론\n",
        "try:\n",
        "    if not Path('chipchat').exists():\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat.git'], check=True)\n",
        "        print(\"✅ GitHub 저장소 클론 완료\")\n",
        "    else:\n",
        "        print(\"✅ GitHub 저장소 이미 존재\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ GitHub 클론 실패: {str(e)}\")\n",
        "\n",
        "# 디렉토리 이동\n",
        "os.chdir('chipchat')\n",
        "\n",
        "# requirements.txt 설치\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
        "    print(\"✅ Requirements 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Requirements 설치 실패: {str(e)}\")\n",
        "\n",
        "# 추가 패키지 설치 (Colab 전용)\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
        "    print(\"✅ pyngrok 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ pyngrok 설치 실패: {str(e)}\")\n",
        "\n",
        "# 현재 디렉토리 설정\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "# 새로운 디렉토리 구조 추가\n",
        "src_dir = current_dir / 'src'\n",
        "if src_dir.exists():\n",
        "    sys.path.append(str(src_dir))\n",
        "    for subdir in ['config', 'models', 'utils', 'app']:\n",
        "        subdir_path = src_dir / subdir\n",
        "        if subdir_path.exists():\n",
        "            sys.path.append(str(subdir_path))\n",
        "\n",
        "print(\"\\n✅ 라이브러리 설치 및 경로 설정 완료!\")\n",
        "print(\"\\n📋 지원되는 LLM 모델:\")\n",
        "print(\"🔸 OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
        "print(\"🔸 Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 🔑 3단계: API 키 설정 { display-mode: \"form\" }\n",
        "#@markdown AI 서비스의 API 키를 입력하여 챗봇을 설정합니다.\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# API 키 유효성 검사\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"⚠️ API 키가 입력되지 않았습니다.\")\n",
        "    print(\"💡 최소 하나 이상의 API 키를 입력해주세요.\")\n",
        "    print(\"• OpenAI API 키: https://platform.openai.com/api-keys\")\n",
        "    print(\"• Claude API 키: https://console.anthropic.com/keys\")\n",
        "    print(\"• HuggingFace 토큰: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # 환경 변수 설정\n",
        "    if openai_api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        print(\"✅ OpenAI API 키 설정 완료!\")\n",
        "        \n",
        "    if claude_api_key:\n",
        "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
        "        print(\"✅ Claude API 키 설정 완료!\")\n",
        "    \n",
        "    if hf_token:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        print(\"✅ HuggingFace 토큰 설정 완료!\")\n",
        "    \n",
        "    # Streamlit 시크릿 파일 생성\n",
        "    secrets_dir = Path(\".streamlit\")\n",
        "    secrets_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    secrets = {}\n",
        "    if openai_api_key:\n",
        "        secrets[\"openai_api_key\"] = openai_api_key\n",
        "    if claude_api_key:\n",
        "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
        "    if hf_token:\n",
        "        secrets[\"hf_token\"] = hf_token\n",
        "    \n",
        "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
        "        for key, value in secrets.items():\n",
        "            f.write(f'{key} = \"{value}\"\\n')\n",
        "    \n",
        "    # 토큰 저장\n",
        "    try:\n",
        "        from src.config.token_manager import TokenManager\n",
        "        token_manager = TokenManager()\n",
        "        \n",
        "        if openai_api_key:\n",
        "            token_manager.set_token('openai', openai_api_key)\n",
        "        \n",
        "        if claude_api_key:\n",
        "            token_manager.set_token('anthropic', claude_api_key)\n",
        "        \n",
        "        if hf_token:\n",
        "            token_manager.set_token('huggingface', hf_token)\n",
        "            \n",
        "        print(\"✅ 토큰 관리자에 API 키 저장 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 토큰 저장 중 오류가 발생했습니다: {str(e)}\")\n",
        "    \n",
        "    # 기본 프롬프트 템플릿 생성\n",
        "    default_template = {\n",
        "        \"pre\": \"당신은 전자 부품 데이터시트에 대해 응답하는 도우미입니다. 제공된 컨텍스트 정보를 기반으로 질문에 답변하세요.\",\n",
        "        \"post\": \"검색된 정보를 바탕으로 명확하고 간결하게 답변해주세요.\"\n",
        "    }\n",
        "    \n",
        "    template_file = prompt_templates_folder / \"default_template.json\"\n",
        "    if not template_file.exists():\n",
        "        with open(template_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(default_template, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "        print(\"✅ 기본 프롬프트 템플릿이 생성되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title 📊 4단계: Streamlit 서버 실행 { display-mode: \"form\" }\n",
        "#@markdown Streamlit 서비스를 실행하여 웹 인터페이스를 제공합니다.\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 환경 변수 설정\n",
        "os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
        "os.environ['JSON_FOLDER_PATH'] = str(json_folder)\n",
        "os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
        "\n",
        "# Streamlit 실행 함수\n",
        "def run_streamlit():\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \n",
        "        \"src/app/streamlit_app.py\",  # 경로 변경\n",
        "        \"--server.port=8501\", \n",
        "        \"--server.address=localhost\"\n",
        "    ]\n",
        "    process = subprocess.Popen(\n",
        "        cmd, \n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE\n",
        "    )\n",
        "    \n",
        "    return process\n",
        "\n",
        "# Ngrok 설정 (공개 URL 만들기)\n",
        "ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if ngrok_token:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Streamlit 서버 실행\n",
        "print(\"🚀 Streamlit 서버를 시작합니다...\")\n",
        "process = run_streamlit()\n",
        "time.sleep(5)  # 서버 시작 대기\n",
        "\n",
        "# Ngrok 터널 설정\n",
        "try:\n",
        "    public_url = ngrok.connect(8501).public_url\n",
        "    print(f\"\\n✅ 서버가 시작되었습니다!\")\n",
        "    print(f\"\\n🔗 다음 URL을 통해 AutoDataSheet에 접속할 수 있습니다:\")\n",
        "    print(f\"📱 {public_url}\")\n",
        "    print(\"\\n이 URL은 세션이 유지되는 동안에만 유효합니다.\")\n",
        "    print(\"URL을 클릭하면 AutoDataSheet 웹 인터페이스로 이동합니다.\")\n",
        "except Exception as e:\n",
        "    # ngrok이 실패하면 Colab의 웹 프록시 사용\n",
        "    print(\"\\n⚠️ ngrok 연결 중 오류가 발생했습니다. Colab의 웹 프록시를 사용합니다.\")\n",
        "    \n",
        "    from google.colab.output import eval_js\n",
        "    url = eval_js('google.colab.kernel.proxyPort(8501)')\n",
        "    \n",
        "    print(f\"\\n✅ 서버가 시작되었습니다!\")\n",
        "    print(f\"\\n🔗 다음 URL을 통해 AutoDataSheet에 접속할 수 있습니다:\")\n",
        "    print(f\"📱 {url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title 🛑 5단계: 서버 중지 { display-mode: \"form\" }\n",
        "#@markdown 작업을 마치면 서버를 중지합니다.\n",
        "\n",
        "import os\n",
        "import signal\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 서버 중지 여부 확인\n",
        "stop_server = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if stop_server:\n",
        "    # ngrok 터널 종료\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "        print(\"✅ ngrok 터널이 종료되었습니다.\")\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Streamlit 프로세스 종료\n",
        "    try:\n",
        "        # 모든 streamlit 프로세스 종료\n",
        "        !pkill -f streamlit\n",
        "        print(\"✅ Streamlit 서버가 종료되었습니다.\")\n",
        "    except:\n",
        "        print(\"⚠️ Streamlit 서버 종료 중 오류가 발생했습니다.\")\n",
        "        print(\"💡 수동으로 런타임을 재시작하여 서버를 종료할 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuVxGUEAuMB"
      },
      "source": [
        "---\n",
        "\n",
        "## 🛠️ 문제 해결\n",
        "\n",
        "**애플리케이션이 실행되지 않는 경우:**\n",
        "\n",
        "1. **API 키 확인**: OpenAI API 키가 올바르게 입력되었는지 확인\n",
        "2. **세션 재시작**: 런타임 → 세션 재시작 후 처음부터 다시 실행\n",
        "3. **JSON 파일 확인**: 전처리된 JSON 파일이 Google Drive에 존재하는지 확인\n",
        "\n",
        "**사용 중 문제가 발생하는 경우:**\n",
        "- 브라우저를 새로고침하세요\n",
        "- 네트워크 연결 상태를 확인하세요\n",
        "\n",
        "---\n",
        "\n",
        "## 📞 지원\n",
        "\n",
        "추가 도움이 필요하시면 GitHub 이슈를 등록해주세요:\n",
        "🔗 https://github.com/doyoung42/chipchat/issues\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💬 ChipChat - 데이터시트 챗봇\n",
    "\n",
    "**전처리된 데이터시트 JSON 파일을 기반으로 질의응답을 수행하는 챗봇입니다.**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 시작하기 전에\n",
    "\n",
    "이 노트북은 ChipChat 앱을 실행하는 방법을 제공합니다.\n",
    "로컬 환경과 Google Colab 환경 모두에서 사용할 수 있습니다.\n",
    "\n",
    "## ✨ 주요 기능들\n",
    "- 🤖 **AI Agent 시스템**: LangGraph 기반 스마트 에이전트\n",
    "- 🔧 **3가지 Tool 자동 선택**: chipDB 검색, 벡터스토어 검색, PDF 처리\n",
    "- 📊 **ChipDB.csv 연동**: 부품 사양 요약 데이터베이스 활용\n",
    "- 🎯 **다중 LLM 지원**: OpenAI와 Claude 모델 선택 가능\n",
    "- 📄 **실시간 PDF 업로드**: 새 데이터시트 자동 처리 및 통합\n",
    "- 🔍 **고급 필터링**: 부품번호, 제조사, 카테고리별 검색\n",
    "- 🛠️ **프롬프트 커스터마이징**: 시스템 프롬프트 자유 수정\n",
    "- 🏷️ **메타데이터 추적**: 소스 정보 표시\n",
    "\n",
    "## 📋 사용 방법\n",
    "아래 셀들을 **순서대로 실행**만 하면 됩니다. (각 셀의 ▶️ 버튼을 클릭)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ✅ 1단계: 환경 설정 { display-mode: \"form\" }\n",
    "#@markdown 로컬 또는 Google Drive 환경을 선택하고 설정을 관리합니다.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 환경 선택 토글\n",
    "use_google_drive = False #@param {type:\"boolean\"}\n",
    "#@markdown ✅ 체크: Google Drive 사용 (Colab 환경) | ❌ 체크해제: 로컬 환경 사용\n",
    "\n",
    "# config.json 파일 경로\n",
    "config_file = Path('config.json')\n",
    "\n",
    "if config_file.exists():\n",
    "    # 기존 config.json 로드\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # 환경 설정 업데이트\n",
    "    config['environment']['use_google_drive'] = use_google_drive\n",
    "    \n",
    "    # 업데이트된 설정 저장\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(\"✅ config.json 업데이트 완료!\")\n",
    "else:\n",
    "    print(\"❌ config.json 파일이 없습니다. 기본 설정을 생성합니다.\")\n",
    "    \n",
    "    # 기본 config.json 생성\n",
    "    default_config = {\n",
    "        \"environment\": {\n",
    "            \"use_google_drive\": use_google_drive,\n",
    "            \"description\": \"Environment selection: true for Google Drive (Colab), false for local\"\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"google_drive\": {\n",
    "                \"base_path\": \"/content/drive/MyDrive\",\n",
    "                \"prep_json_folder\": \"/content/drive/MyDrive/prep_json\",\n",
    "                \"vectorstore_folder\": \"/content/drive/MyDrive/vectorstore\",\n",
    "                \"prompt_templates_folder\": \"/content/drive/MyDrive/prompt_templates\",\n",
    "                \"model_cache_folder\": \"/content/drive/MyDrive/hf_model_cache\",\n",
    "                \"logs_folder\": \"/content/drive/MyDrive/chipchat_logs\"\n",
    "            },\n",
    "            \"local\": {\n",
    "                \"base_path\": \".\",\n",
    "                \"prep_json_folder\": \"./prep_json\",\n",
    "                \"vectorstore_folder\": \"./vectorstore\",\n",
    "                \"prompt_templates_folder\": \"./prompt_templates\",\n",
    "                \"model_cache_folder\": \"./hf_model_cache\",\n",
    "                \"logs_folder\": \"./logs\"\n",
    "            }\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            \"supported_llm\": {\n",
    "                \"openai\": [\"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"],\n",
    "                \"claude\": [\"claude-3-sonnet\", \"claude-3-haiku\", \"claude-3-opus\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(default_config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    config = default_config\n",
    "    print(\"✅ 기본 config.json 생성 완료!\")\n",
    "\n",
    "# 현재 환경 설정 표시\n",
    "env_type = \"Google Drive\" if use_google_drive else \"로컬\"\n",
    "current_paths = config['paths']['google_drive' if use_google_drive else 'local']\n",
    "\n",
    "print(f\"\\n🌐 {env_type} 환경으로 설정되었습니다!\")\n",
    "print(f\"📋 설정된 경로들:\")\n",
    "for key, path in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        print(f\"  • {key.replace('_', ' ').title()}: {path}\")\n",
    "\n",
    "# Google Drive 마운트 (필요한 경우)\n",
    "if use_google_drive:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        print(\"\\n🔄 Google Drive 마운트 중...\")\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"✅ Google Drive 연동 완료!\")\n",
    "    except ImportError:\n",
    "        print(\"⚠️ Google Colab 환경이 아닙니다. 환경 설정을 로컬로 변경합니다.\")\n",
    "        config['environment']['use_google_drive'] = False\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "        current_paths = config['paths']['local']\n",
    "        print(\"💻 로컬 환경으로 전환되었습니다.\")\n",
    "\n",
    "# 필요한 디렉토리 생성\n",
    "print(\"\\n📁 필요한 디렉토리 생성 중...\")\n",
    "for key, path_str in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        path = Path(path_str)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  ✅ {path}\")\n",
    "\n",
    "print(\"\\n🎉 환경 설정이 완료되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 📥 2단계: 필요한 라이브러리 설치 { display-mode: \"form\" }\n",
    "#@markdown 필요한 라이브러리들을 설치합니다.\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"📥 필요한 라이브러리 설치 중...\")\n",
    "\n",
    "# GitHub 저장소 클론 (로컬 환경이 아닌 경우)\n",
    "try:\n",
    "    if not Path('src').exists():  # src 폴더가 없으면 클론 필요\n",
    "        print(\"🔄 GitHub 저장소 클론 중...\")\n",
    "        subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat_demo.git', 'temp_clone'], check=True)\n",
    "        \n",
    "        # 필요한 파일들 복사\n",
    "        import shutil\n",
    "        if Path('temp_clone/src').exists():\n",
    "            shutil.copytree('temp_clone/src', 'src', dirs_exist_ok=True)\n",
    "        if Path('temp_clone/requirements.txt').exists():\n",
    "            shutil.copy2('temp_clone/requirements.txt', 'requirements.txt')\n",
    "        \n",
    "        # 임시 폴더 삭제\n",
    "        shutil.rmtree('temp_clone')\n",
    "        print(\"✅ 필요한 파일들 복사 완료\")\n",
    "    else:\n",
    "        print(\"✅ 소스 코드 이미 존재\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ GitHub 클론 실패: {str(e)}\")\n",
    "    print(\"💡 로컬 환경에서 이미 파일들이 존재한다고 가정합니다.\")\n",
    "\n",
    "# requirements.txt 설치\n",
    "if Path('requirements.txt').exists():\n",
    "    try:\n",
    "        subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
    "        print(\"✅ Requirements 설치 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Requirements 설치 실패: {str(e)}\")\n",
    "else:\n",
    "    print(\"⚠️ requirements.txt 파일을 찾을 수 없습니다.\")\n",
    "    print(\"💡 기본 라이브러리들만 사용합니다.\")\n",
    "\n",
    "# 추가 패키지 설치 (Colab 전용)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
    "    print(\"✅ pyngrok 설치 완료\")\n",
    "except ImportError:\n",
    "    print(\"💻 로컬 환경: pyngrok 설치 생략\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ pyngrok 설치 실패: {str(e)}\")\n",
    "\n",
    "# Python path 설정\n",
    "import sys\n",
    "current_dir = Path(os.getcwd())\n",
    "sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir / 'src'))\n",
    "\n",
    "# 새로운 디렉토리 구조 추가\n",
    "src_dir = current_dir / 'src'\n",
    "if src_dir.exists():\n",
    "    sys.path.append(str(src_dir))\n",
    "    for subdir in ['config', 'models', 'utils', 'app']:\n",
    "        subdir_path = src_dir / subdir\n",
    "        if subdir_path.exists():\n",
    "            sys.path.append(str(subdir_path))\n",
    "\n",
    "print(\"\\n✅ 라이브러리 설치 및 경로 설정 완료!\")\n",
    "print(\"\\n📋 지원되는 LLM 모델:\")\n",
    "print(\"🔸 OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
    "print(\"🔸 Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🚀 2-1단계: 로깅 시스템 초기화 및 모델 사전 다운로드 { display-mode: \"form\" }\n",
    "#@markdown HuggingFace 모델을 캐싱하여 빠른 로딩을 지원합니다.\n",
    "\n",
    "import time\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.model_cache import get_model_cache\n",
    "\n",
    "# 로깅 시스템 초기화\n",
    "print(\"📊 로깅 시스템 초기화 중...\")\n",
    "logger = get_logger()\n",
    "logger.log_system_info()\n",
    "logger.info(\"Main notebook 실행 시작\")\n",
    "\n",
    "# 모델 캐시 시스템 초기화\n",
    "print(\"\\n🗄️ 모델 캐시 시스템 초기화 중...\")\n",
    "model_cache = get_model_cache()\n",
    "cache_info = model_cache.get_cache_info()\n",
    "\n",
    "print(f\"📁 캐시 디렉토리: {cache_info['cache_dir']}\")\n",
    "print(f\"📦 캐시된 모델 수: {cache_info['model_count']}\")\n",
    "print(f\"💾 전체 캐시 크기: {cache_info['total_size_mb']:.2f} MB\")\n",
    "\n",
    "if cache_info['models']:\n",
    "    print(\"\\n✅ 캐시된 모델:\")\n",
    "    for model in cache_info['models']:\n",
    "        print(f\"  - {model}\")\n",
    "\n",
    "# 모델 사전 다운로드 옵션\n",
    "download_model = True #@param {type:\"boolean\"}\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" #@param {type:\"string\"}\n",
    "\n",
    "if download_model:\n",
    "    print(f\"\\n🔄 모델 다운로드 또는 캐시 확인: {model_name}\")\n",
    "    \n",
    "    @logger.measure_time(\"모델 준비\")\n",
    "    def prepare_model():\n",
    "        # 캐시 확인\n",
    "        if model_cache.is_model_cached(model_name):\n",
    "            print(\"✅ 모델이 이미 캐시되어 있습니다.\")\n",
    "            # 캐시에서 로드\n",
    "            if model_cache.load_model_from_cache(model_name):\n",
    "                print(\"✅ 캐시에서 모델 로드 완료!\")\n",
    "                return True\n",
    "        \n",
    "        # 캐시에 없으면 다운로드\n",
    "        print(\"📥 모델을 다운로드합니다...\")\n",
    "        try:\n",
    "            from langchain_huggingface import HuggingFaceEmbeddings\n",
    "            \n",
    "            # 모델 다운로드 (초기화를 통해)\n",
    "            start_time = time.time()\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            download_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"✅ 모델 다운로드 완료! (소요 시간: {download_time:.2f}초)\")\n",
    "            \n",
    "            # 캐시에 저장\n",
    "            print(\"💾 모델을 캐시에 저장 중...\")\n",
    "            if model_cache.save_model_to_cache(model_name):\n",
    "                print(\"✅ 모델 캐시 저장 완료!\")\n",
    "            else:\n",
    "                print(\"⚠️ 모델 캐시 저장 실패 (다음 실행 시 다시 다운로드됩니다)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"모델 준비 실패: {e}\")\n",
    "            print(f\"❌ 모델 준비 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # 모델 준비 실행\n",
    "    success = prepare_model()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 모델 준비 완료! 이제 Streamlit 앱이 더 빠르게 로드됩니다.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 모델 준비에 실패했습니다. 하지만 계속 진행할 수 있습니다.\")\n",
    "\n",
    "# 성능 요약 표시\n",
    "print(\"\\n📊 현재까지의 성능 요약:\")\n",
    "perf_summary = logger.get_performance_summary()\n",
    "for op, stats in perf_summary.items():\n",
    "    print(f\"\\n🔹 {op}:\")\n",
    "    print(f\"   - 평균 시간: {stats['avg_time']:.2f}초\")\n",
    "    print(f\"   - 성공: {stats['success_count']}회, 실패: {stats['fail_count']}회\")\n",
    "\n",
    "print(\"\\n✅ 모든 준비가 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🔑 3단계: API 키 설정 { display-mode: \"form\" }\n",
    "#@markdown AI 서비스의 API 키를 입력하여 챗봇을 설정합니다.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "openai_api_key = \"\" #@param {type:\"string\"}\n",
    "claude_api_key = \"\" #@param {type:\"string\"}\n",
    "hf_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# API 키 유효성 검사\n",
    "if not openai_api_key and not claude_api_key and not hf_token:\n",
    "    print(\"⚠️ API 키가 입력되지 않았습니다.\")\n",
    "    print(\"💡 최소 하나 이상의 API 키를 입력해주세요.\")\n",
    "    print(\"• OpenAI API 키: https://platform.openai.com/api-keys\")\n",
    "    print(\"• Claude API 키: https://console.anthropic.com/keys\")\n",
    "    print(\"• HuggingFace 토큰: https://huggingface.co/settings/tokens\")\n",
    "else:\n",
    "    # 환경 변수 설정\n",
    "    if openai_api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        print(\"✅ OpenAI API 키 설정 완료!\")\n",
    "        \n",
    "    if claude_api_key:\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
    "        print(\"✅ Claude API 키 설정 완료!\")\n",
    "    \n",
    "    if hf_token:\n",
    "        os.environ[\"HF_TOKEN\"] = hf_token\n",
    "        print(\"✅ HuggingFace 토큰 설정 완료!\")\n",
    "    \n",
    "    # Streamlit 시크릿 파일 생성\n",
    "    secrets_dir = Path(\".streamlit\")\n",
    "    secrets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    secrets = {}\n",
    "    if openai_api_key:\n",
    "        secrets[\"openai_api_key\"] = openai_api_key\n",
    "    if claude_api_key:\n",
    "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
    "    if hf_token:\n",
    "        secrets[\"hf_token\"] = hf_token\n",
    "    \n",
    "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
    "        for key, value in secrets.items():\n",
    "            f.write(f'{key} = \"{value}\"\\n')\n",
    "    \n",
    "    # 토큰 저장\n",
    "    try:\n",
    "        from src.config.token_manager import TokenManager\n",
    "        token_manager = TokenManager()\n",
    "        \n",
    "        if openai_api_key:\n",
    "            token_manager.set_token('openai', openai_api_key)\n",
    "        \n",
    "        if claude_api_key:\n",
    "            token_manager.set_token('anthropic', claude_api_key)\n",
    "        \n",
    "        if hf_token:\n",
    "            token_manager.set_token('huggingface', hf_token)\n",
    "            \n",
    "        print(\"✅ 토큰 관리자에 API 키 저장 완료!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 토큰 저장 중 오류가 발생했습니다: {str(e)}\")\n",
    "    \n",
    "    # 기본 프롬프트 템플릿 생성\n",
    "    default_template = {\n",
    "        \"pre\": \"당신은 전자 부품 데이터시트에 대해 응답하는 도우미입니다. 제공된 컨텍스트 정보를 기반으로 질문에 답변하세요.\",\n",
    "        \"post\": \"검색된 정보를 바탕으로 명확하고 간결하게 답변해주세요.\"\n",
    "    }\n",
    "    \n",
    "    # config.json에서 경로 읽기\n",
    "    try:\n",
    "        from src.utils.config_manager import get_config_manager\n",
    "        config = get_config_manager()\n",
    "        prompt_templates_folder = Path(config.get_path('prompt_templates_folder'))\n",
    "    except:\n",
    "        prompt_templates_folder = Path('./prompt_templates')\n",
    "    \n",
    "    template_file = prompt_templates_folder / \"default_template.json\"\n",
    "    if not template_file.exists():\n",
    "        with open(template_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(default_template, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        print(\"✅ 기본 프롬프트 템플릿이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 📊 4단계: Streamlit 서버 실행 { display-mode: \"form\" }\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# 간소화된 ChipChat 앱 실행\n",
    "app_file = \"src/app/streamlit_app.py\"\n",
    "port = 8501\n",
    "\n",
    "print(f\"🎯 ChipChat 멀티턴 챗봇 실행\")\n",
    "print(f\"📝 설명: LangGraph 기반 멀티에이전트 챗봇\")\n",
    "print(f\"📁 파일: {app_file}\")\n",
    "print(f\"🌐 포트: {port}\")\n",
    "print(f\"\")\n",
    "print(f\"✨ 주요 기능:\")\n",
    "print(f\"  • 🤖 자동 도구 선택 (ChipDB, Vectorstore)\")\n",
    "print(f\"  • 💬 멀티턴 대화 지원\")\n",
    "print(f\"  • 🔧 LLM 모델 선택 가능\")\n",
    "print(f\"  • 📊 실시간 성능 모니터링\")\n",
    "\n",
    "# config.json에서 경로 읽기\n",
    "try:\n",
    "    from src.utils.config_manager import get_config_manager\n",
    "    config = get_config_manager()\n",
    "    vectorstore_folder = config.get_path('vectorstore_folder')\n",
    "    prep_json_folder = config.get_path('prep_json_folder')\n",
    "    prompt_templates_folder = config.get_path('prompt_templates_folder')\n",
    "except:\n",
    "    vectorstore_folder = './vectorstore'\n",
    "    prep_json_folder = './prep_json'\n",
    "    prompt_templates_folder = './prompt_templates'\n",
    "\n",
    "# 환경 변수 설정\n",
    "os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
    "os.environ['JSON_FOLDER_PATH'] = str(prep_json_folder)\n",
    "os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
    "\n",
    "# 로깅 정보 표시\n",
    "if 'logger' in globals():\n",
    "    logger.info(\"Streamlit 앱 시작 준비\", extra={\n",
    "        \"vectorstore_path\": str(vectorstore_folder),\n",
    "        \"json_folder_path\": str(prep_json_folder),\n",
    "        \"prompt_templates_path\": str(prompt_templates_folder),\n",
    "        \"port\": port\n",
    "    })\n",
    "\n",
    "# 로그 출력 함수\n",
    "def print_output(process):\n",
    "    \"\"\"실시간으로 프로세스 출력을 표시 (중요한 로그만)\"\"\"\n",
    "    important_keywords = [\n",
    "        'You can now view your Streamlit app',\n",
    "        'Local URL:',\n",
    "        'Network URL:', \n",
    "        'External URL:',\n",
    "        'ERROR',\n",
    "        'CRITICAL',\n",
    "        'WARNING',\n",
    "        'started server',\n",
    "        'Server started',\n",
    "        'Running on',\n",
    "        'ModuleNotFoundError',\n",
    "        'ImportError',\n",
    "        'Exception'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            if line:\n",
    "                line_text = line.strip() if isinstance(line, str) else line.decode('utf-8').strip()\n",
    "                \n",
    "                # 중요한 키워드가 포함된 로그만 표시\n",
    "                if line_text and any(keyword.lower() in line_text.lower() for keyword in important_keywords):\n",
    "                    print(f\"📋 [Streamlit] {line_text}\")\n",
    "                elif 'streamlit' in line_text.lower() and ('ready' in line_text.lower() or 'starting' in line_text.lower()):\n",
    "                    print(f\"📋 [Streamlit] {line_text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 로그 출력 중 오류: {e}\")\n",
    "\n",
    "# 서버 상태 확인 함수\n",
    "def check_server_status(port, max_attempts=30):\n",
    "    \"\"\"서버가 실제로 시작되었는지 확인\"\"\"\n",
    "    print(f\"🔍 포트 {port}에서 서버 시작 상태를 확인 중...\")\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = requests.get(f\"http://localhost:{port}\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✅ 서버가 정상적으로 시작되었습니다! (시도 {attempt + 1}/{max_attempts})\")\n",
    "                return True\n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(f\"⏳ 서버 시작 대기 중... ({attempt + 1}/{max_attempts})\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"❌ 서버 시작 확인 실패 (시도 {attempt + 1}/{max_attempts})\")\n",
    "    return False\n",
    "\n",
    "# Streamlit 실행 함수\n",
    "def run_streamlit_unified(app_file, port):\n",
    "    print(\"🔧 Streamlit 명령어 설정 중...\")\n",
    "    cmd = [\n",
    "        \"streamlit\", \"run\", \n",
    "        app_file,\n",
    "        f\"--server.port={port}\", \n",
    "        \"--server.address=0.0.0.0\",\n",
    "        \"--server.headless=true\",\n",
    "        \"--browser.serverAddress=localhost\",\n",
    "        \"--browser.gatherUsageStats=false\",\n",
    "        \"--logger.level=info\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"📋 실행 명령어: {' '.join(cmd)}\")\n",
    "    print(\"🚀 Streamlit 프로세스 시작...\")\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        cmd, \n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    return process\n",
    "\n",
    "# ngrok 사용 여부 선택\n",
    "use_ngrok = False #@param {type:\"boolean\"}\n",
    "ngrok_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "print(\"\\n📝 현재 설정:\")\n",
    "print(f\"  • 포트: {port}\")\n",
    "print(f\"  • Vectorstore 경로: {vectorstore_folder}\")\n",
    "print(f\"  • JSON 폴더 경로: {prep_json_folder}\")\n",
    "print(f\"  • 프롬프트 템플릿 경로: {prompt_templates_folder}\")\n",
    "print(f\"  • ngrok 사용: {use_ngrok}\")\n",
    "\n",
    "# 기존 Streamlit 프로세스 종료\n",
    "print(\"\\n🔄 기존 Streamlit 프로세스 정리 중...\")\n",
    "try:\n",
    "    subprocess.run(['pkill', '-f', 'streamlit'], check=False, capture_output=True)\n",
    "    time.sleep(2)\n",
    "    print(\"✅ 기존 프로세스 정리 완료\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 프로세스 정리 중 오류 (무시 가능): {e}\")\n",
    "\n",
    "# 통합 Streamlit 서버 실행\n",
    "process = run_streamlit_unified(app_file, port)\n",
    "\n",
    "# 별도 스레드에서 로그 출력\n",
    "log_thread = threading.Thread(target=print_output, args=(process,), daemon=True)\n",
    "log_thread.start()\n",
    "\n",
    "# 서버 시작 상태 확인\n",
    "server_started = check_server_status(port)\n",
    "\n",
    "if server_started:\n",
    "    if use_ngrok and ngrok_token:\n",
    "        # ngrok 사용 (외부 접속 가능한 공개 URL)\n",
    "        try:\n",
    "            print(\"\\n🌐 ngrok 터널 생성 중...\")\n",
    "            from pyngrok import ngrok\n",
    "            ngrok.set_auth_token(ngrok_token)\n",
    "            public_url = ngrok.connect(port).public_url\n",
    "            print(f\"✅ ngrok 터널 생성 완료!\")\n",
    "            print(f\"\\n🔗 다음 URL을 통해 ChipChat에 접속할 수 있습니다:\")\n",
    "            print(f\"📱 {public_url}\")\n",
    "            print(\"\\n📌 이 URL은 세션이 유지되는 동안에만 유효합니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ngrok 연결 실패: {str(e)}\")\n",
    "            print(\"🔄 Google Colab 내장 기능으로 전환합니다.\")\n",
    "            use_ngrok = False\n",
    "\n",
    "    if not use_ngrok:\n",
    "        # Google Colab 내장 기능 사용\n",
    "        print(f\"\\n✅ 서버가 성공적으로 시작되었습니다!\")\n",
    "        print(f\"\\n🔗 ChipChat에 접속하는 방법:\")\n",
    "        print(f\"1️⃣ 포트 {port}에서 실행 중입니다\")\n",
    "        print(f\"2️⃣ 아래 버튼을 클릭하거나 왼쪽 사이드바의 '포트' 탭을 확인하세요\")\n",
    "        \n",
    "        # 새창에서 열기\n",
    "        try:\n",
    "            from google.colab import output\n",
    "            print(\"🖥️ 새창에서 ChipChat을 열 수 있는 버튼을 생성 중...\")\n",
    "            output.serve_kernel_port_as_window(port)\n",
    "            print(\"✅ 새창 열기 버튼이 생성되었습니다!\")\n",
    "            print(\"🔘 위에 나타난 버튼을 클릭하면 새창에서 ChipChat이 열립니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 새창 버튼 생성 실패: {e}\")\n",
    "            print(\"💡 대신 다음 방법들을 시도해보세요:\")\n",
    "            print(f\"   • 왼쪽 사이드바 → '포트' 탭 → {port} 포트 클릭\")\n",
    "            print(f\"   • 직접 URL 접속: https://localhost:{port} (Colab 환경에서)\")\n",
    "    \n",
    "    # 통합 앱 사용 안내\n",
    "    print(f\"\\n💡 ChipChat 통합 앱 사용 방법:\")\n",
    "    print(f\"  • 🎯 앱이 시작되면 모드를 선택하세요\")\n",
    "    print(f\"  • ⚡ 경량 모드: 즉시 사용 가능 (기본 텍스트 검색)\")\n",
    "    print(f\"  • 🤖 전체 모드: AI 기능 포함 (초기화 버튼 클릭 필요)\")\n",
    "    print(f\"  • 🔄 언제든지 모드 전환 가능\")\n",
    "    print(f\"  • 📊 시스템 상태는 메인 화면에서 확인\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ 서버 시작에 실패했습니다.\")\n",
    "    print(\"🔍 가능한 원인:\")\n",
    "    print(\"  • 필요한 파일이 누락되었을 수 있습니다\")\n",
    "    print(\"  • API 키 설정에 문제가 있을 수 있습니다\")\n",
    "    print(\"  • 의존성 라이브러리 설치에 문제가 있을 수 있습니다\")\n",
    "    print(\"\\n💡 해결 방법:\")\n",
    "    print(\"  • 앱이 시작되면 경량 모드를 먼저 시도해보세요\")\n",
    "    print(\"  • 2-3단계를 다시 실행해보세요\")\n",
    "    print(\"  • 런타임을 재시작하고 처음부터 다시 시도해보세요\")\n",
    "\n",
    "# 프로세스 저장 (5단계에서 사용)\n",
    "globals()['streamlit_process'] = process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🛑 5단계: 서버 중지 { display-mode: \"form\" }\n",
    "#@markdown 작업을 마치면 서버를 중지합니다.\n",
    "\n",
    "import os\n",
    "import signal\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# 서버 중지 여부 확인\n",
    "stop_server = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if stop_server:\n",
    "    print(\"🛑 서버 종료 프로세스를 시작합니다...\")\n",
    "    \n",
    "    # ngrok 터널 종료 (ngrok 사용한 경우에만)\n",
    "    try:\n",
    "        from pyngrok import ngrok\n",
    "        ngrok.kill()\n",
    "        print(\"✅ ngrok 터널이 종료되었습니다.\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"ℹ️ ngrok 종료: {str(e)}\")\n",
    "    \n",
    "    # 4단계에서 생성된 프로세스 먼저 종료\n",
    "    terminated_process = False\n",
    "    if 'streamlit_process' in globals():\n",
    "        try:\n",
    "            process = globals()['streamlit_process']\n",
    "            if process and process.poll() is None:\n",
    "                print(\"🔄 4단계에서 실행된 Streamlit 프로세스를 종료 중...\")\n",
    "                process.terminate()\n",
    "                time.sleep(3)\n",
    "                \n",
    "                if process.poll() is None:\n",
    "                    print(\"⚡ 강제 종료를 시도합니다...\")\n",
    "                    process.kill()\n",
    "                    time.sleep(2)\n",
    "                \n",
    "                print(\"✅ Streamlit 프로세스가 정상적으로 종료되었습니다.\")\n",
    "                terminated_process = True\n",
    "            else:\n",
    "                print(\"ℹ️ Streamlit 프로세스가 이미 종료되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 프로세스 종료 중 오류: {e}\")\n",
    "    \n",
    "    # 추가적으로 모든 streamlit 프로세스 종료\n",
    "    try:\n",
    "        print(\"🔍 남은 Streamlit 프로세스를 검색 중...\")\n",
    "        result = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "        if result.stdout.strip():\n",
    "            pids = result.stdout.strip().split('\\n')\n",
    "            print(f\"📋 발견된 Streamlit 프로세스: {len(pids)}개\")\n",
    "            \n",
    "            subprocess.run(['pkill', '-f', 'streamlit'], check=False)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            result_after = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "            if not result_after.stdout.strip():\n",
    "                print(\"✅ 모든 Streamlit 프로세스가 정리되었습니다.\")\n",
    "            else:\n",
    "                print(\"⚠️ 일부 프로세스가 여전히 실행 중일 수 있습니다.\")\n",
    "        else:\n",
    "            print(\"✅ 실행 중인 Streamlit 프로세스가 없습니다.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 프로세스 정리 중 오류가 발생했습니다: {e}\")\n",
    "        print(\"💡 수동으로 런타임을 재시작하여 서버를 종료할 수 있습니다.\")\n",
    "    \n",
    "    # 포트 사용 상태 확인\n",
    "    try:\n",
    "        import socket\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        result = sock.connect_ex(('localhost', 8501))\n",
    "        sock.close()\n",
    "        \n",
    "        if result != 0:\n",
    "            print(\"✅ 포트 8501이 해제되었습니다.\")\n",
    "        else:\n",
    "            print(\"⚠️ 포트 8501이 아직 사용 중입니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ℹ️ 포트 상태 확인 실패: {e}\")\n",
    "    \n",
    "    print(\"\\n📋 서버 종료 완료!\")\n",
    "    print(\"💡 완전한 정리를 위해 런타임을 재시작하는 것을 권장합니다.\")\n",
    "    print(\"🔄 런타임 → 세션 재시작을 통해 모든 프로세스를 완전히 종료할 수 있습니다.\")\n",
    "else:\n",
    "    print(\"ℹ️ 서버 중지가 취소되었습니다.\")\n",
    "    print(\"💡 서버를 중지하려면 위의 체크박스를 선택하고 다시 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ 문제 해결\n",
    "\n",
    "**애플리케이션이 실행되지 않는 경우:**\n",
    "\n",
    "1. **API 키 확인**: OpenAI API 키가 올바르게 입력되었는지 확인\n",
    "2. **세션 재시작**: 런타임 → 세션 재시작 후 처음부터 다시 실행\n",
    "3. **JSON 파일 확인**: 전처리된 JSON 파일이 올바른 경로에 존재하는지 확인\n",
    "\n",
    "**사용 중 문제가 발생하는 경우:**\n",
    "- 브라우저를 새로고침하세요\n",
    "- 네트워크 연결 상태를 확인하세요\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

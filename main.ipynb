{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5o_CS8EAuL_"
      },
      "source": [
        "# 💬 ChipChat - 데이터시트 챗봇\n",
        "\n",
        "**전처리된 데이터시트 JSON 파일을 기반으로 질의응답을 수행하는 챗봇입니다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 시작하기 전에\n",
        "\n",
        "이 노트북은 Google Colab에서 개선된 ChipChat 앱을 실행하는 방법을 제공합니다.\n",
        "\n",
        "⚠️ **중요**: 이 노트북은 반드시 **새로운 Colab 세션**에서 실행해주세요.\n",
        "- 이전에 `prep_main.ipynb`를 실행했다면, 새로운 세션을 시작해주세요.\n",
        "- 이는 의존성 충돌과 경로 문제를 방지하기 위함입니다.\n",
        "\n",
        "## ✨ 새로운 기능들 (v2.0)\n",
        "- 🤖 **AI Agent 시스템**: LangGraph 기반 스마트 에이전트\n",
        "- 🔧 **3가지 Tool 자동 선택**: chipDB 검색, 벡터스토어 검색, PDF 처리\n",
        "- 📊 **ChipDB.csv 연동**: 부품 사양 요약 데이터베이스 활용\n",
        "- 🎯 **다중 LLM 지원**: OpenAI와 Claude 모델 선택 가능\n",
        "- 📄 **실시간 PDF 업로드**: 새 데이터시트 자동 처리 및 통합\n",
        "- 🔍 **고급 필터링**: 부품번호, 제조사, 카테고리별 검색\n",
        "- 🛠️ **프롬프트 커스터마이징**: 시스템 프롬프트 자유 수정\n",
        "- 🏷️ **메타데이터 추적**: 소스 정보 표시\n",
        "\n",
        "## 📋 사용 방법\n",
        "아래 셀들을 **순서대로 실행**만 하면 됩니다. (각 셀의 ▶️ 버튼을 클릭)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8pJCAhKAuMA"
      },
      "outputs": [],
      "source": [
        "#@title ✅ 1단계: Google Drive 연동 { display-mode: \"form\" }\n",
        "#@markdown Google Drive를 연동하여 전처리된 JSON 파일과 벡터 스토어를 관리합니다.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔄 Google Drive 마운트 중...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 폴더 설정\n",
        "prep_json_folder = Path('/content/drive/MyDrive/prep_json')  # chipDB.csv 위치\n",
        "vectorstore_folder = Path('/content/drive/MyDrive/vectorstore')\n",
        "prompt_templates_folder = Path('/content/drive/MyDrive/prompt_templates')\n",
        "\n",
        "# 필요한 폴더들 생성\n",
        "vectorstore_folder.mkdir(parents=True, exist_ok=True)\n",
        "prompt_templates_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\n✅ Google Drive 연동 완료!\")\n",
        "print(f\"📁 전처리 데이터 폴더: {prep_json_folder}\")\n",
        "print(f\"📁 벡터 스토어 폴더: {vectorstore_folder}\")\n",
        "print(f\"📁 프롬프트 템플릿 폴더: {prompt_templates_folder}\")\n",
        "\n",
        "# chipDB.csv 파일 확인\n",
        "chipdb_file = prep_json_folder / 'chipDB.csv'\n",
        "if chipdb_file.exists():\n",
        "    # 파일 크기 확인 (적절한 단위로 표시)\n",
        "    file_size_bytes = chipdb_file.stat().st_size\n",
        "    if file_size_bytes < 1024:\n",
        "        file_size_str = f\"{file_size_bytes} bytes\"\n",
        "    elif file_size_bytes < 1024 * 1024:\n",
        "        file_size_str = f\"{file_size_bytes / 1024:.1f} KB\"\n",
        "    else:\n",
        "        file_size_str = f\"{file_size_bytes / 1024 / 1024:.1f} MB\"\n",
        "    \n",
        "    print(f\"\\n📊 chipDB.csv 발견: {file_size_str}\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ chipDB.csv 파일이 없습니다: {chipdb_file}\")\n",
        "\n",
        "# Vectorstore 파일 확인 (하위 폴더 포함)\n",
        "vectorstore_files = []\n",
        "for ext in ['*.index', '*.faiss', '*.pkl', '*.parquet']:\n",
        "    vectorstore_files.extend(list(vectorstore_folder.glob(f\"**/{ext}\")))\n",
        "\n",
        "print(f\"\\n🗄️ 발견된 Vectorstore 파일: {len(vectorstore_files)}개\")\n",
        "vectorstore_folders = set()\n",
        "for vs_file in vectorstore_files[:10]:  # 처음 10개만 표시\n",
        "    relative_path = vs_file.relative_to(vectorstore_folder)\n",
        "    vectorstore_folders.add(str(relative_path.parent))\n",
        "    print(f\" - {relative_path}\")\n",
        "\n",
        "if len(vectorstore_files) > 10:\n",
        "    print(f\" ... 외 {len(vectorstore_files) - 10}개\")\n",
        "\n",
        "# 발견된 vectorstore 폴더들 표시\n",
        "if vectorstore_folders and vectorstore_folders != {'.'}:\n",
        "    print(f\"\\n📁 Vectorstore 폴더들:\")\n",
        "    for folder in sorted(vectorstore_folders):\n",
        "        if folder != '.':\n",
        "            print(f\" - {folder}\")\n",
        "\n",
        "# 상태 확인 및 경고\n",
        "if not chipdb_file.exists() and not vectorstore_files:\n",
        "    print(\"\\n⚠️ chipDB.csv와 Vectorstore가 모두 없습니다.\")\n",
        "    print(\"💡 prep_main.ipynb를 먼저 실행하여 데이터를 전처리해주세요.\")\n",
        "elif not chipdb_file.exists():\n",
        "    print(\"\\n⚠️ chipDB.csv 파일이 없습니다. prep_main.ipynb로 chipDB.csv를 생성해주세요.\")\n",
        "elif not vectorstore_files:\n",
        "    print(\"\\n⚠️ Vectorstore가 없습니다. prep_main.ipynb로 Vectorstore를 생성해주세요.\")\n",
        "else:\n",
        "    print(\"\\n✅ chipDB.csv와 Vectorstore가 모두 준비되었습니다!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0UGei9FAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 📥 2단계: 필요한 라이브러리 설치 { display-mode: \"form\" }\n",
        "#@markdown 필요한 라이브러리들을 설치합니다.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"📥 필요한 라이브러리 설치 중...\")\n",
        "\n",
        "# GitHub 저장소 클론\n",
        "try:\n",
        "    if not Path('chipchat_demo').exists():\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat_demo.git'], check=True)\n",
        "        print(\"✅ GitHub 저장소 클론 완료\")\n",
        "    else:\n",
        "        print(\"✅ GitHub 저장소 이미 존재\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ GitHub 클론 실패: {str(e)}\")\n",
        "\n",
        "# 디렉토리 이동\n",
        "os.chdir('chipchat_demo')\n",
        "\n",
        "# requirements.txt 설치\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
        "    print(\"✅ Requirements 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Requirements 설치 실패: {str(e)}\")\n",
        "\n",
        "# 추가 패키지 설치 (Colab 전용)\n",
        "try:\n",
        "    subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
        "    print(\"✅ pyngrok 설치 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ pyngrok 설치 실패: {str(e)}\")\n",
        "\n",
        "# 현재 디렉토리 설정\n",
        "import sys\n",
        "current_dir = Path(os.getcwd())\n",
        "sys.path.append(str(current_dir))\n",
        "sys.path.append(str(current_dir / 'src'))\n",
        "\n",
        "# 새로운 디렉토리 구조 추가\n",
        "src_dir = current_dir / 'src'\n",
        "if src_dir.exists():\n",
        "    sys.path.append(str(src_dir))\n",
        "    for subdir in ['config', 'models', 'utils', 'app']:\n",
        "        subdir_path = src_dir / subdir\n",
        "        if subdir_path.exists():\n",
        "            sys.path.append(str(subdir_path))\n",
        "\n",
        "print(\"\\n✅ 라이브러리 설치 및 경로 설정 완료!\")\n",
        "print(\"\\n📋 지원되는 LLM 모델:\")\n",
        "print(\"🔸 OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
        "print(\"🔸 Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 🚀 2-1단계: 로깅 시스템 초기화 및 모델 사전 다운로드 { display-mode: \"form\" }\n",
        "#@markdown HuggingFace 모델을 Google Drive에 캐싱하여 빠른 로딩을 지원합니다.\n",
        "\n",
        "import time\n",
        "from src.utils.logger import get_logger\n",
        "from src.utils.model_cache import get_model_cache\n",
        "\n",
        "# 로깅 시스템 초기화\n",
        "print(\"📊 로깅 시스템 초기화 중...\")\n",
        "logger = get_logger()\n",
        "logger.log_system_info()\n",
        "logger.info(\"Main notebook 실행 시작\")\n",
        "\n",
        "# 모델 캐시 시스템 초기화\n",
        "print(\"\\n🗄️ 모델 캐시 시스템 초기화 중...\")\n",
        "model_cache = get_model_cache()\n",
        "cache_info = model_cache.get_cache_info()\n",
        "\n",
        "print(f\"📁 캐시 디렉토리: {cache_info['cache_dir']}\")\n",
        "print(f\"📦 캐시된 모델 수: {cache_info['model_count']}\")\n",
        "print(f\"💾 전체 캐시 크기: {cache_info['total_size_mb']:.2f} MB\")\n",
        "\n",
        "if cache_info['models']:\n",
        "    print(\"\\n✅ 캐시된 모델:\")\n",
        "    for model in cache_info['models']:\n",
        "        print(f\"  - {model}\")\n",
        "\n",
        "# 모델 사전 다운로드 옵션\n",
        "download_model = True #@param {type:\"boolean\"}\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" #@param {type:\"string\"}\n",
        "\n",
        "if download_model:\n",
        "    print(f\"\\n🔄 모델 다운로드 또는 캐시 확인: {model_name}\")\n",
        "    \n",
        "    @logger.measure_time(\"모델 준비\")\n",
        "    def prepare_model():\n",
        "        # 캐시 확인\n",
        "        if model_cache.is_model_cached(model_name):\n",
        "            print(\"✅ 모델이 이미 캐시되어 있습니다.\")\n",
        "            # Google Drive에서 로드\n",
        "            if model_cache.load_model_from_cache(model_name):\n",
        "                print(\"✅ 캐시에서 모델 로드 완료!\")\n",
        "                return True\n",
        "        \n",
        "        # 캐시에 없으면 다운로드\n",
        "        print(\"📥 모델을 다운로드합니다...\")\n",
        "        try:\n",
        "            from langchain_huggingface import HuggingFaceEmbeddings\n",
        "            \n",
        "            # 모델 다운로드 (초기화를 통해)\n",
        "            start_time = time.time()\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=model_name,\n",
        "                model_kwargs={'device': 'cpu'}\n",
        "            )\n",
        "            download_time = time.time() - start_time\n",
        "            \n",
        "            print(f\"✅ 모델 다운로드 완료! (소요 시간: {download_time:.2f}초)\")\n",
        "            \n",
        "            # Google Drive에 캐시 저장\n",
        "            print(\"💾 모델을 Google Drive에 캐시 중...\")\n",
        "            if model_cache.save_model_to_cache(model_name):\n",
        "                print(\"✅ 모델 캐시 저장 완료!\")\n",
        "            else:\n",
        "                print(\"⚠️ 모델 캐시 저장 실패 (다음 실행 시 다시 다운로드됩니다)\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"모델 준비 실패: {e}\")\n",
        "            print(f\"❌ 모델 준비 실패: {e}\")\n",
        "            return False\n",
        "    \n",
        "    # 모델 준비 실행\n",
        "    success = prepare_model()\n",
        "    \n",
        "    if success:\n",
        "        print(\"\\n🎉 모델 준비 완료! 이제 Streamlit 앱이 더 빠르게 로드됩니다.\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ 모델 준비에 실패했습니다. 하지만 계속 진행할 수 있습니다.\")\n",
        "\n",
        "# 성능 요약 표시\n",
        "print(\"\\n📊 현재까지의 성능 요약:\")\n",
        "perf_summary = logger.get_performance_summary()\n",
        "for op, stats in perf_summary.items():\n",
        "    print(f\"\\n🔹 {op}:\")\n",
        "    print(f\"   - 평균 시간: {stats['avg_time']:.2f}초\")\n",
        "    print(f\"   - 성공: {stats['success_count']}회, 실패: {stats['fail_count']}회\")\n",
        "\n",
        "print(\"\\n✅ 모든 준비가 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfx37NsUAuMA"
      },
      "outputs": [],
      "source": [
        "#@title 🔑 3단계: API 키 설정 { display-mode: \"form\" }\n",
        "#@markdown AI 서비스의 API 키를 입력하여 챗봇을 설정합니다.\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "claude_api_key = \"\" #@param {type:\"string\"}\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# API 키 유효성 검사\n",
        "if not openai_api_key and not claude_api_key and not hf_token:\n",
        "    print(\"⚠️ API 키가 입력되지 않았습니다.\")\n",
        "    print(\"💡 최소 하나 이상의 API 키를 입력해주세요.\")\n",
        "    print(\"• OpenAI API 키: https://platform.openai.com/api-keys\")\n",
        "    print(\"• Claude API 키: https://console.anthropic.com/keys\")\n",
        "    print(\"• HuggingFace 토큰: https://huggingface.co/settings/tokens\")\n",
        "else:\n",
        "    # 환경 변수 설정\n",
        "    if openai_api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        print(\"✅ OpenAI API 키 설정 완료!\")\n",
        "        \n",
        "    if claude_api_key:\n",
        "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
        "        print(\"✅ Claude API 키 설정 완료!\")\n",
        "    \n",
        "    if hf_token:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        print(\"✅ HuggingFace 토큰 설정 완료!\")\n",
        "    \n",
        "    # Streamlit 시크릿 파일 생성\n",
        "    secrets_dir = Path(\".streamlit\")\n",
        "    secrets_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    secrets = {}\n",
        "    if openai_api_key:\n",
        "        secrets[\"openai_api_key\"] = openai_api_key\n",
        "    if claude_api_key:\n",
        "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
        "    if hf_token:\n",
        "        secrets[\"hf_token\"] = hf_token\n",
        "    \n",
        "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
        "        for key, value in secrets.items():\n",
        "            f.write(f'{key} = \"{value}\"\\n')\n",
        "    \n",
        "    # 토큰 저장\n",
        "    try:\n",
        "        from src.config.token_manager import TokenManager\n",
        "        token_manager = TokenManager()\n",
        "        \n",
        "        if openai_api_key:\n",
        "            token_manager.set_token('openai', openai_api_key)\n",
        "        \n",
        "        if claude_api_key:\n",
        "            token_manager.set_token('anthropic', claude_api_key)\n",
        "        \n",
        "        if hf_token:\n",
        "            token_manager.set_token('huggingface', hf_token)\n",
        "            \n",
        "        print(\"✅ 토큰 관리자에 API 키 저장 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 토큰 저장 중 오류가 발생했습니다: {str(e)}\")\n",
        "    \n",
        "    # 기본 프롬프트 템플릿 생성\n",
        "    default_template = {\n",
        "        \"pre\": \"당신은 전자 부품 데이터시트에 대해 응답하는 도우미입니다. 제공된 컨텍스트 정보를 기반으로 질문에 답변하세요.\",\n",
        "        \"post\": \"검색된 정보를 바탕으로 명확하고 간결하게 답변해주세요.\"\n",
        "    }\n",
        "    \n",
        "    template_file = prompt_templates_folder / \"default_template.json\"\n",
        "    if not template_file.exists():\n",
        "        with open(template_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(default_template, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "        print(\"✅ 기본 프롬프트 템플릿이 생성되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyju4JQQAuMB"
      },
      "outputs": [],
      "source": [
        "#@title 📊 4단계: Streamlit 서버 실행 { display-mode: \"form\" }\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# 간소화된 ChipChat 앱 실행\n",
        "app_file = \"src/app/streamlit_app.py\"\n",
        "port = 8501\n",
        "\n",
        "print(f\"🎯 ChipChat 멀티턴 챗봇 실행\")\n",
        "print(f\"📝 설명: LangGraph 기반 멀티에이전트 챗봇\")\n",
        "print(f\"📁 파일: {app_file}\")\n",
        "print(f\"🌐 포트: {port}\")\n",
        "print(f\"\")\n",
        "print(f\"✨ 주요 기능:\")\n",
        "print(f\"  • 🤖 자동 도구 선택 (ChipDB, Vectorstore)\")\n",
        "print(f\"  • 💬 멀티턴 대화 지원\")\n",
        "print(f\"  • 🔧 LLM 모델 선택 가능\")\n",
        "print(f\"  • 📊 실시간 성능 모니터링\")\n",
        "\n",
        "# 환경 변수 설정\n",
        "os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
        "os.environ['JSON_FOLDER_PATH'] = str(prep_json_folder)  # chipDB.csv가 있는 폴더\n",
        "os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
        "\n",
        "# 로깅 정보 표시\n",
        "if 'logger' in globals():\n",
        "    logger.info(\"Streamlit 앱 시작 준비\", extra={\n",
        "        \"vectorstore_path\": str(vectorstore_folder),\n",
        "        \"json_folder_path\": str(prep_json_folder),\n",
        "        \"prompt_templates_path\": str(prompt_templates_folder),\n",
        "        \"port\": port\n",
        "    })\n",
        "\n",
        "# 로그 출력 함수\n",
        "def print_output(process):\n",
        "    \"\"\"실시간으로 프로세스 출력을 표시 (중요한 로그만)\"\"\"\n",
        "    important_keywords = [\n",
        "        'You can now view your Streamlit app',\n",
        "        'Local URL:',\n",
        "        'Network URL:', \n",
        "        'External URL:',\n",
        "        'ERROR',\n",
        "        'CRITICAL',\n",
        "        'WARNING',\n",
        "        'started server',\n",
        "        'Server started',\n",
        "        'Running on',\n",
        "        'ModuleNotFoundError',\n",
        "        'ImportError',\n",
        "        'Exception'\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if line:\n",
        "                # universal_newlines=True로 설정했으므로 이미 str 형태\n",
        "                line_text = line.strip() if isinstance(line, str) else line.decode('utf-8').strip()\n",
        "                \n",
        "                # 중요한 키워드가 포함된 로그만 표시\n",
        "                if line_text and any(keyword.lower() in line_text.lower() for keyword in important_keywords):\n",
        "                    print(f\"📋 [Streamlit] {line_text}\")\n",
        "                elif 'streamlit' in line_text.lower() and ('ready' in line_text.lower() or 'starting' in line_text.lower()):\n",
        "                    print(f\"📋 [Streamlit] {line_text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 로그 출력 중 오류: {e}\")\n",
        "\n",
        "# 서버 상태 확인 함수\n",
        "def check_server_status(port, max_attempts=30):\n",
        "    \"\"\"서버가 실제로 시작되었는지 확인\"\"\"\n",
        "    print(f\"🔍 포트 {port}에서 서버 시작 상태를 확인 중...\")\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = requests.get(f\"http://localhost:{port}\", timeout=2)\n",
        "            if response.status_code == 200:\n",
        "                print(f\"✅ 서버가 정상적으로 시작되었습니다! (시도 {attempt + 1}/{max_attempts})\")\n",
        "                return True\n",
        "        except requests.exceptions.RequestException:\n",
        "            if attempt < max_attempts - 1:\n",
        "                print(f\"⏳ 서버 시작 대기 중... ({attempt + 1}/{max_attempts})\")\n",
        "                time.sleep(2)\n",
        "            else:\n",
        "                print(f\"❌ 서버 시작 확인 실패 (시도 {attempt + 1}/{max_attempts})\")\n",
        "    return False\n",
        "\n",
        "# Streamlit 실행 함수\n",
        "def run_streamlit_unified(app_file, port):\n",
        "    print(\"🔧 Streamlit 명령어 설정 중...\")\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \n",
        "        app_file,\n",
        "        f\"--server.port={port}\", \n",
        "        \"--server.address=0.0.0.0\",  # 외부 접속 허용\n",
        "        \"--server.headless=true\",\n",
        "        \"--browser.serverAddress=localhost\",\n",
        "        \"--browser.gatherUsageStats=false\",\n",
        "        \"--logger.level=info\"  # 더 자세한 로그\n",
        "    ]\n",
        "    \n",
        "    print(f\"📋 실행 명령어: {' '.join(cmd)}\")\n",
        "    print(\"🚀 Streamlit 프로세스 시작...\")\n",
        "    \n",
        "    process = subprocess.Popen(\n",
        "        cmd, \n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,  # stderr를 stdout으로 리다이렉트\n",
        "        universal_newlines=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "    \n",
        "    return process\n",
        "\n",
        "# ngrok 사용 여부 선택\n",
        "use_ngrok = False #@param {type:\"boolean\"}\n",
        "ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"\\n📝 현재 설정:\")\n",
        "print(f\"  • 포트: {port}\")\n",
        "print(f\"  • Vectorstore 경로: {vectorstore_folder}\")\n",
        "print(f\"  • JSON 폴더 경로: {prep_json_folder}\")\n",
        "print(f\"  • 프롬프트 템플릿 경로: {prompt_templates_folder}\")\n",
        "print(f\"  • ngrok 사용: {use_ngrok}\")\n",
        "\n",
        "# 기존 Streamlit 프로세스 종료\n",
        "print(\"\\n🔄 기존 Streamlit 프로세스 정리 중...\")\n",
        "try:\n",
        "    subprocess.run(['pkill', '-f', 'streamlit'], check=False, capture_output=True)\n",
        "    time.sleep(2)\n",
        "    print(\"✅ 기존 프로세스 정리 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ 프로세스 정리 중 오류 (무시 가능): {e}\")\n",
        "\n",
        "# 통합 Streamlit 서버 실행\n",
        "process = run_streamlit_unified(app_file, port)\n",
        "\n",
        "# 별도 스레드에서 로그 출력\n",
        "log_thread = threading.Thread(target=print_output, args=(process,), daemon=True)\n",
        "log_thread.start()\n",
        "\n",
        "# 서버 시작 상태 확인\n",
        "server_started = check_server_status(port)\n",
        "\n",
        "if server_started:\n",
        "    if use_ngrok and ngrok_token:\n",
        "        # ngrok 사용 (외부 접속 가능한 공개 URL)\n",
        "        try:\n",
        "            print(\"\\n🌐 ngrok 터널 생성 중...\")\n",
        "            from pyngrok import ngrok\n",
        "            ngrok.set_auth_token(ngrok_token)\n",
        "            public_url = ngrok.connect(port).public_url\n",
        "            print(f\"✅ ngrok 터널 생성 완료!\")\n",
        "            print(f\"\\n🔗 다음 URL을 통해 ChipChat에 접속할 수 있습니다:\")\n",
        "            print(f\"📱 {public_url}\")\n",
        "            print(\"\\n📌 이 URL은 세션이 유지되는 동안에만 유효합니다.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ ngrok 연결 실패: {str(e)}\")\n",
        "            print(\"🔄 Google Colab 내장 기능으로 전환합니다.\")\n",
        "            use_ngrok = False\n",
        "\n",
        "    if not use_ngrok:\n",
        "        # Google Colab 내장 기능 사용 - 새창에서 열기\n",
        "        print(f\"\\n✅ 서버가 성공적으로 시작되었습니다!\")\n",
        "        print(f\"\\n🔗 ChipChat에 접속하는 방법:\")\n",
        "        print(f\"1️⃣ 포트 {port}에서 실행 중입니다\")\n",
        "        print(f\"2️⃣ 아래 버튼을 클릭하거나 왼쪽 사이드바의 '포트' 탭을 확인하세요\")\n",
        "        \n",
        "        # 새창에서 열기 (사용자 선호)\n",
        "        try:\n",
        "            from google.colab import output\n",
        "            print(\"🖥️ 새창에서 ChipChat을 열 수 있는 버튼을 생성 중...\")\n",
        "            output.serve_kernel_port_as_window(port)\n",
        "            print(\"✅ 새창 열기 버튼이 생성되었습니다!\")\n",
        "            print(\"🔘 위에 나타난 버튼을 클릭하면 새창에서 ChipChat이 열립니다.\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 새창 버튼 생성 실패: {e}\")\n",
        "            print(\"💡 대신 다음 방법들을 시도해보세요:\")\n",
        "            print(f\"   • 왼쪽 사이드바 → '포트' 탭 → {port} 포트 클릭\")\n",
        "            print(f\"   • 직접 URL 접속: https://localhost:{port} (Colab 환경에서)\")\n",
        "    \n",
        "    # 통합 앱 사용 안내\n",
        "    print(f\"\\n💡 ChipChat 통합 앱 사용 방법:\")\n",
        "    print(f\"  • 🎯 앱이 시작되면 모드를 선택하세요\")\n",
        "    print(f\"  • ⚡ 경량 모드: 즉시 사용 가능 (기본 텍스트 검색)\")\n",
        "    print(f\"  • 🤖 전체 모드: AI 기능 포함 (초기화 버튼 클릭 필요)\")\n",
        "    print(f\"  • 🔄 언제든지 모드 전환 가능\")\n",
        "    print(f\"  • 📊 시스템 상태는 메인 화면에서 확인\")\n",
        "    print(f\"  • 브라우저에서 새로고침을 시도해보세요\")\n",
        "    print(f\"  • 문제 발생 시 아래 중요한 로그를 확인해주세요\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n❌ 서버 시작에 실패했습니다.\")\n",
        "    print(\"🔍 가능한 원인:\")\n",
        "    print(\"  • 필요한 파일이 누락되었을 수 있습니다\")\n",
        "    print(\"  • API 키 설정에 문제가 있을 수 있습니다\")\n",
        "    print(\"  • 의존성 라이브러리 설치에 문제가 있을 수 있습니다\")\n",
        "    print(\"\\n💡 해결 방법:\")\n",
        "    print(\"  • 앱이 시작되면 경량 모드를 먼저 시도해보세요\")\n",
        "    print(\"  • 2-3단계를 다시 실행해보세요\")\n",
        "    print(\"  • 런타임을 재시작하고 처음부터 다시 시도해보세요\")\n",
        "\n",
        "# 프로세스 저장 (5단계에서 사용)\n",
        "globals()['streamlit_process'] = process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og5mck4_AuMB"
      },
      "outputs": [],
      "source": [
        "#@title 🛑 5단계: 서버 중지 { display-mode: \"form\" }\n",
        "#@markdown 작업을 마치면 서버를 중지합니다.\n",
        "\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# 서버 중지 여부 확인\n",
        "stop_server = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if stop_server:\n",
        "    print(\"🛑 서버 종료 프로세스를 시작합니다...\")\n",
        "    \n",
        "    # ngrok 터널 종료 (ngrok 사용한 경우에만)\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.kill()\n",
        "        print(\"✅ ngrok 터널이 종료되었습니다.\")\n",
        "    except ImportError:\n",
        "        # pyngrok이 import되지 않은 경우 (정상적인 상황)\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        # ngrok 관련 다른 오류\n",
        "        print(f\"ℹ️ ngrok 종료: {str(e)}\")\n",
        "    \n",
        "    # 4단계에서 생성된 프로세스 먼저 종료\n",
        "    terminated_process = False\n",
        "    if 'streamlit_process' in globals():\n",
        "        try:\n",
        "            process = globals()['streamlit_process']\n",
        "            if process and process.poll() is None:  # 프로세스가 아직 실행 중인지 확인\n",
        "                print(\"🔄 4단계에서 실행된 Streamlit 프로세스를 종료 중...\")\n",
        "                process.terminate()\n",
        "                time.sleep(3)\n",
        "                \n",
        "                # 강제 종료가 필요한 경우\n",
        "                if process.poll() is None:\n",
        "                    print(\"⚡ 강제 종료를 시도합니다...\")\n",
        "                    process.kill()\n",
        "                    time.sleep(2)\n",
        "                \n",
        "                print(\"✅ Streamlit 프로세스가 정상적으로 종료되었습니다.\")\n",
        "                terminated_process = True\n",
        "            else:\n",
        "                print(\"ℹ️ Streamlit 프로세스가 이미 종료되었습니다.\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 프로세스 종료 중 오류: {e}\")\n",
        "    \n",
        "    # 추가적으로 모든 streamlit 프로세스 종료 (혹시 놓친 프로세스가 있을 경우)\n",
        "    try:\n",
        "        print(\"🔍 남은 Streamlit 프로세스를 검색 중...\")\n",
        "        # 실행 중인 streamlit 프로세스 확인\n",
        "        result = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
        "        if result.stdout.strip():\n",
        "            pids = result.stdout.strip().split('\\n')\n",
        "            print(f\"📋 발견된 Streamlit 프로세스: {len(pids)}개\")\n",
        "            \n",
        "            # 모든 streamlit 프로세스 종료\n",
        "            subprocess.run(['pkill', '-f', 'streamlit'], check=False)\n",
        "            time.sleep(2)\n",
        "            \n",
        "            # 종료 확인\n",
        "            result_after = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
        "            if not result_after.stdout.strip():\n",
        "                print(\"✅ 모든 Streamlit 프로세스가 정리되었습니다.\")\n",
        "            else:\n",
        "                print(\"⚠️ 일부 프로세스가 여전히 실행 중일 수 있습니다.\")\n",
        "        else:\n",
        "            print(\"✅ 실행 중인 Streamlit 프로세스가 없습니다.\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 프로세스 정리 중 오류가 발생했습니다: {e}\")\n",
        "        print(\"💡 수동으로 런타임을 재시작하여 서버를 종료할 수 있습니다.\")\n",
        "    \n",
        "    # 포트 사용 상태 확인\n",
        "    try:\n",
        "        import socket\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('localhost', 8501))\n",
        "        sock.close()\n",
        "        \n",
        "        if result != 0:\n",
        "            print(\"✅ 포트 8501이 해제되었습니다.\")\n",
        "        else:\n",
        "            print(\"⚠️ 포트 8501이 아직 사용 중입니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ℹ️ 포트 상태 확인 실패: {e}\")\n",
        "    \n",
        "    print(\"\\n📋 서버 종료 완료!\")\n",
        "    print(\"💡 완전한 정리를 위해 런타임을 재시작하는 것을 권장합니다.\")\n",
        "    print(\"🔄 런타임 → 세션 재시작을 통해 모든 프로세스를 완전히 종료할 수 있습니다.\")\n",
        "else:\n",
        "    print(\"ℹ️ 서버 중지가 취소되었습니다.\")\n",
        "    print(\"💡 서버를 중지하려면 위의 체크박스를 선택하고 다시 실행해주세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuVxGUEAuMB"
      },
      "source": [
        "---\n",
        "\n",
        "## 🛠️ 문제 해결\n",
        "\n",
        "**애플리케이션이 실행되지 않는 경우:**\n",
        "\n",
        "1. **API 키 확인**: OpenAI API 키가 올바르게 입력되었는지 확인\n",
        "2. **세션 재시작**: 런타임 → 세션 재시작 후 처음부터 다시 실행\n",
        "3. **JSON 파일 확인**: 전처리된 JSON 파일이 Google Drive에 존재하는지 확인\n",
        "\n",
        "**사용 중 문제가 발생하는 경우:**\n",
        "- 브라우저를 새로고침하세요\n",
        "- 네트워크 연결 상태를 확인하세요\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

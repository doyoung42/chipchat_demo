{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ’¬ ChipChat - ë°ì´í„°ì‹œíŠ¸ ì±—ë´‡\n",
    "\n",
    "**ì „ì²˜ë¦¬ëœ ë°ì´í„°ì‹œíŠ¸ JSON íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ChipChat ì•±ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ë¡œì»¬ í™˜ê²½ê³¼ Google Colab í™˜ê²½ ëª¨ë‘ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## âœ¨ ì£¼ìš” ê¸°ëŠ¥ë“¤\n",
    "- ğŸ¤– **AI Agent ì‹œìŠ¤í…œ**: LangGraph ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì—ì´ì „íŠ¸\n",
    "- ğŸ”§ **3ê°€ì§€ Tool ìë™ ì„ íƒ**: chipDB ê²€ìƒ‰, ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰, PDF ì²˜ë¦¬\n",
    "- ğŸ“Š **ChipDB.csv ì—°ë™**: ë¶€í’ˆ ì‚¬ì–‘ ìš”ì•½ ë°ì´í„°ë² ì´ìŠ¤ í™œìš©\n",
    "- ğŸ¯ **ë‹¤ì¤‘ LLM ì§€ì›**: OpenAIì™€ Claude ëª¨ë¸ ì„ íƒ ê°€ëŠ¥\n",
    "- ğŸ“„ **ì‹¤ì‹œê°„ PDF ì—…ë¡œë“œ**: ìƒˆ ë°ì´í„°ì‹œíŠ¸ ìë™ ì²˜ë¦¬ ë° í†µí•©\n",
    "- ğŸ” **ê³ ê¸‰ í•„í„°ë§**: ë¶€í’ˆë²ˆí˜¸, ì œì¡°ì‚¬, ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰\n",
    "- ğŸ› ï¸ **í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ììœ  ìˆ˜ì •\n",
    "- ğŸ·ï¸ **ë©”íƒ€ë°ì´í„° ì¶”ì **: ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ\n",
    "\n",
    "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
    "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title âœ… 1ë‹¨ê³„: í™˜ê²½ ì„¤ì • { display-mode: \"form\" }\n",
    "#@markdown ë¡œì»¬ ë˜ëŠ” Google Drive í™˜ê²½ì„ ì„ íƒí•˜ê³  ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# í™˜ê²½ ì„ íƒ í† ê¸€\n",
    "use_google_drive = False #@param {type:\"boolean\"}\n",
    "#@markdown âœ… ì²´í¬: Google Drive ì‚¬ìš© (Colab í™˜ê²½) | âŒ ì²´í¬í•´ì œ: ë¡œì»¬ í™˜ê²½ ì‚¬ìš©\n",
    "\n",
    "# config.json íŒŒì¼ ê²½ë¡œ\n",
    "config_file = Path('prep/config.json')\n",
    "\n",
    "if config_file.exists():\n",
    "    # ê¸°ì¡´ config.json ë¡œë“œ\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸\n",
    "    config['environment']['use_google_drive'] = use_google_drive\n",
    "    \n",
    "    # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(\"âœ… config.json ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âŒ config.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ê¸°ë³¸ config.json ìƒì„±\n",
    "    default_config = {\n",
    "        \"environment\": {\n",
    "            \"use_google_drive\": use_google_drive,\n",
    "            \"description\": \"Environment selection: true for Google Drive (Colab), false for local\"\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"google_drive\": {\n",
    "                \"base_path\": \"/content/drive/MyDrive\",\n",
    "                \"prep_json_folder\": \"/content/drive/MyDrive/prep_json\",\n",
    "                \"vectorstore_folder\": \"/content/drive/MyDrive/vectorstore\",\n",
    "                \"prompt_templates_folder\": \"/content/drive/MyDrive/prompts\",\n",
    "                \"model_cache_folder\": \"/content/drive/MyDrive/hf_model_cache\",\n",
    "                \"logs_folder\": \"/content/drive/MyDrive/chipchat_logs\",\n",
    "                \"prep_datasheets_folder\": \"/content/drive/MyDrive/datasheets\",\n",
    "                \"prep_prep_json_folder\": \"/content/drive/MyDrive/prep_json\",\n",
    "                \"prep_vectorstore_folder\": \"/content/drive/MyDrive/vectorstore\"\n",
    "            },\n",
    "                    \"local\": {\n",
    "            \"base_path\": \".\",\n",
    "            \"prep_json_folder\": \"./prep/prep_json\",\n",
    "            \"vectorstore_folder\": \"./prep/vectorstore\",\n",
    "            \"prompt_templates_folder\": \"./prompts\",\n",
    "            \"model_cache_folder\": \"./hf_model_cache\",\n",
    "            \"logs_folder\": \"./logs\",\n",
    "            \"prep_datasheets_folder\": \"./prep/datasheets\",\n",
    "            \"prep_prep_json_folder\": \"./prep/prep_json\",\n",
    "            \"prep_vectorstore_folder\": \"./prep/vectorstore\"\n",
    "        }\n",
    "        },\n",
    "        \"vectorstore\": {\n",
    "            \"default_name\": \"datasheet_vectors_final\"\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            \"supported_llm\": {\n",
    "                \"openai\": [\n",
    "                    \"gpt-4o-mini\",\n",
    "                    \"gpt-4o\",\n",
    "                    \"gpt-3.5-turbo\"\n",
    "                ],\n",
    "                \"claude\": [\n",
    "                    \"claude-3-sonnet-20240229\",\n",
    "                    \"claude-3-haiku-20240307\",\n",
    "                    \"claude-3-opus-20240229\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"pdf_processing\": {\n",
    "            \"pages_per_chunk\": 3,\n",
    "            \"chunk_overlap\": 1,\n",
    "            \"output_formats\": {\n",
    "                \"save_filtered_pdf\": True,\n",
    "                \"save_summary_only\": False,\n",
    "                \"save_combined\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(default_config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    config = default_config\n",
    "    print(\"âœ… ê¸°ë³¸ config.json ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "# í˜„ì¬ í™˜ê²½ ì„¤ì • í‘œì‹œ\n",
    "env_type = \"Google Drive\" if use_google_drive else \"ë¡œì»¬\"\n",
    "current_paths = config['paths']['google_drive' if use_google_drive else 'local']\n",
    "\n",
    "print(f\"\\nğŸŒ {env_type} í™˜ê²½ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“‹ ì„¤ì •ëœ ê²½ë¡œë“¤:\")\n",
    "for key, path in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        print(f\"  â€¢ {key.replace('_', ' ').title()}: {path}\")\n",
    "\n",
    "# Google Drive ë§ˆìš´íŠ¸ (í•„ìš”í•œ ê²½ìš°)\n",
    "if use_google_drive:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        print(\"\\nğŸ”„ Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"âœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ Google Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. í™˜ê²½ ì„¤ì •ì„ ë¡œì»¬ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\")\n",
    "        config['environment']['use_google_drive'] = False\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "        current_paths = config['paths']['local']\n",
    "        print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ìœ¼ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "print(\"\\nğŸ“ í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...\")\n",
    "for key, path_str in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        path = Path(path_str)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  âœ… {path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“¥ 2ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
    "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# config.jsonì—ì„œ í™˜ê²½ ì„¤ì • ì½ê¸°\n",
    "config_file = Path('prep/config.json')\n",
    "use_google_drive = False\n",
    "\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    use_google_drive = config.get('environment', {}).get('use_google_drive', False)\n",
    "\n",
    "print(\"ğŸ“¥ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
    "\n",
    "# í™˜ê²½ë³„ ì„¤ì¹˜ ê³¼ì •\n",
    "if use_google_drive:\n",
    "    print(\"ğŸŒ Google Colab í™˜ê²½ ì„¤ì •...\")\n",
    "    \n",
    "    # GitHub ì €ì¥ì†Œ í´ë¡  (Colab í™˜ê²½)\n",
    "    try:\n",
    "        if not Path('src').exists():  # src í´ë”ê°€ ì—†ìœ¼ë©´ í´ë¡  í•„ìš”\n",
    "            print(\"ğŸ”„ GitHub ì €ì¥ì†Œ í´ë¡  ì¤‘...\")\n",
    "            subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat_demo.git', 'temp_clone'], check=True)\n",
    "            \n",
    "            # í•„ìš”í•œ íŒŒì¼ë“¤ ë³µì‚¬\n",
    "            import shutil\n",
    "            if Path('temp_clone/src').exists():\n",
    "                shutil.copytree('temp_clone/src', 'src', dirs_exist_ok=True)\n",
    "            if Path('temp_clone/requirements.txt').exists():\n",
    "                shutil.copy2('temp_clone/requirements.txt', 'requirements.txt')\n",
    "            \n",
    "            # ì„ì‹œ í´ë” ì‚­ì œ\n",
    "            shutil.rmtree('temp_clone')\n",
    "            print(\"âœ… GitHub ì €ì¥ì†Œ í´ë¡  ë° íŒŒì¼ ë³µì‚¬ ì™„ë£Œ\")\n",
    "        else:\n",
    "            print(\"âœ… ì†ŒìŠ¤ ì½”ë“œ ì´ë¯¸ ì¡´ì¬\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ GitHub í´ë¡  ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    # Colab ì „ìš© íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "    try:\n",
    "        subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
    "        print(\"âœ… pyngrok (ì™¸ë¶€ ì ‘ì†ìš©) ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ pyngrok ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ ì„¤ì •...\")\n",
    "    \n",
    "    # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ì´ë¯¸ git cloneë˜ì–´ ìˆë‹¤ê³  ê°€ì •\n",
    "    if Path('src').exists():\n",
    "        print(\"âœ… ì†ŒìŠ¤ ì½”ë“œ í™•ì¸ ì™„ë£Œ (ë¡œì»¬ ì €ì¥ì†Œ)\")\n",
    "    else:\n",
    "        print(\"âŒ src í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ GitHubì—ì„œ ì €ì¥ì†Œë¥¼ cloneí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        print(\"   git clone https://github.com/doyoung42/chipchat_demo.git\")\n",
    "\n",
    "# requirements.txt ì„¤ì¹˜\n",
    "if use_google_drive:\n",
    "    if Path('requirements.txt').exists():\n",
    "        try:\n",
    "            subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
    "            print(\"âœ… Requirements ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Requirements ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ requirements.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# Python path ì„¤ì •\n",
    "import sys\n",
    "current_dir = Path(os.getcwd())\n",
    "sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir / 'src'))\n",
    "\n",
    "# ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì¶”ê°€\n",
    "src_dir = current_dir / 'src'\n",
    "if src_dir.exists():\n",
    "    sys.path.append(str(src_dir))\n",
    "    for subdir in ['config', 'models', 'utils', 'app']:\n",
    "        subdir_path = src_dir / subdir\n",
    "        if subdir_path.exists():\n",
    "            sys.path.append(str(subdir_path))\n",
    "\n",
    "print(\"\\nâœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ê²½ë¡œ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ“‹ ì§€ì›ë˜ëŠ” LLM ëª¨ë¸:\")\n",
    "print(\"ğŸ”¸ OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
    "print(\"ğŸ”¸ Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸš€ 2-1ë‹¨ê³„: ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ { display-mode: \"form\" }\n",
    "#@markdown HuggingFace ëª¨ë¸ì„ ìºì‹±í•˜ì—¬ ë¹ ë¥¸ ë¡œë”©ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "import time\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.model_cache import get_model_cache\n",
    "\n",
    "# ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(\"ğŸ“Š ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "logger = get_logger()\n",
    "logger.log_system_info()\n",
    "logger.info(\"Main notebook ì‹¤í–‰ ì‹œì‘\")\n",
    "\n",
    "# ëª¨ë¸ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(\"\\nğŸ—„ï¸ ëª¨ë¸ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "model_cache = get_model_cache()\n",
    "cache_info = model_cache.get_cache_info()\n",
    "\n",
    "print(f\"ğŸ“ ìºì‹œ ë””ë ‰í† ë¦¬: {cache_info['cache_dir']}\")\n",
    "print(f\"ğŸ“¦ ìºì‹œëœ ëª¨ë¸ ìˆ˜: {cache_info['model_count']}\")\n",
    "print(f\"ğŸ’¾ ì „ì²´ ìºì‹œ í¬ê¸°: {cache_info['total_size_mb']:.2f} MB\")\n",
    "\n",
    "if cache_info['models']:\n",
    "    print(\"\\nâœ… ìºì‹œëœ ëª¨ë¸:\")\n",
    "    for model in cache_info['models']:\n",
    "        print(f\"  - {model}\")\n",
    "\n",
    "# ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ì˜µì…˜\n",
    "download_model = True #@param {type:\"boolean\"}\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" #@param {type:\"string\"}\n",
    "\n",
    "if download_model:\n",
    "    print(f\"\\nğŸ”„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìºì‹œ í™•ì¸: {model_name}\")\n",
    "    \n",
    "    @logger.measure_time(\"ëª¨ë¸ ì¤€ë¹„\")\n",
    "    def prepare_model():\n",
    "        # ìºì‹œ í™•ì¸\n",
    "        if model_cache.is_model_cached(model_name):\n",
    "            print(\"âœ… ëª¨ë¸ì´ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            # ìºì‹œì—ì„œ ë¡œë“œ\n",
    "            if model_cache.load_model_from_cache(model_name):\n",
    "                print(\"âœ… ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "                return True\n",
    "        \n",
    "        # ìºì‹œì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ\n",
    "        print(\"ğŸ“¥ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "        try:\n",
    "            from langchain_huggingface import HuggingFaceEmbeddings\n",
    "            \n",
    "            # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì´ˆê¸°í™”ë¥¼ í†µí•´)\n",
    "            start_time = time.time()\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            download_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {download_time:.2f}ì´ˆ)\")\n",
    "            \n",
    "            # ìºì‹œì— ì €ì¥\n",
    "            print(\"ğŸ’¾ ëª¨ë¸ì„ ìºì‹œì— ì €ì¥ ì¤‘...\")\n",
    "            if model_cache.save_model_to_cache(model_name):\n",
    "                pass  # save_model_to_cacheì—ì„œ ì´ë¯¸ ì €ì¥ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¶œë ¥í•¨\n",
    "            else:\n",
    "                print(\"âš ï¸ ëª¨ë¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨ (ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨: {e}\")\n",
    "            print(f\"âŒ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # ëª¨ë¸ ì¤€ë¹„ ì‹¤í–‰\n",
    "    success = prepare_model()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! ì´ì œ Streamlit ì•±ì´ ë” ë¹ ë¥´ê²Œ ë¡œë“œë©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ëª¨ë¸ ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê³„ì† ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì„±ëŠ¥ ìš”ì•½ í‘œì‹œ\n",
    "print(\"\\nğŸ“Š í˜„ì¬ê¹Œì§€ì˜ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "perf_summary = logger.get_performance_summary()\n",
    "for op, stats in perf_summary.items():\n",
    "    print(f\"\\nğŸ”¹ {op}:\")\n",
    "    print(f\"   - í‰ê·  ì‹œê°„: {stats['avg_time']:.2f}ì´ˆ\")\n",
    "    print(f\"   - ì„±ê³µ: {stats['success_count']}íšŒ, ì‹¤íŒ¨: {stats['fail_count']}íšŒ\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”‘ 3ë‹¨ê³„: API í‚¤ ì„¤ì • { display-mode: \"form\" }\n",
    "#@markdown AI ì„œë¹„ìŠ¤ì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì—¬ ì±—ë´‡ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "openai_api_key = \"\" #@param {type:\"string\"}\n",
    "claude_api_key = \"\" #@param {type:\"string\"}\n",
    "hf_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬\n",
    "if not openai_api_key and not claude_api_key and not hf_token:\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"â€¢ OpenAI API í‚¤: https://platform.openai.com/api-keys\")\n",
    "    print(\"â€¢ Claude API í‚¤: https://console.anthropic.com/keys\")\n",
    "    print(\"â€¢ HuggingFace í† í°: https://huggingface.co/settings/tokens\")\n",
    "else:\n",
    "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    if openai_api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        print(\"âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
    "        \n",
    "    if claude_api_key:\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
    "        print(\"âœ… Claude API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    if hf_token:\n",
    "        os.environ[\"HF_TOKEN\"] = hf_token\n",
    "        print(\"âœ… HuggingFace í† í° ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    # Streamlit ì‹œí¬ë¦¿ íŒŒì¼ ìƒì„±\n",
    "    secrets_dir = Path(\".streamlit\")\n",
    "    secrets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    secrets = {}\n",
    "    if openai_api_key:\n",
    "        secrets[\"openai_api_key\"] = openai_api_key\n",
    "    if claude_api_key:\n",
    "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
    "    if hf_token:\n",
    "        secrets[\"hf_token\"] = hf_token\n",
    "    \n",
    "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
    "        for key, value in secrets.items():\n",
    "            f.write(f'{key} = \"{value}\"\\n')\n",
    "    \n",
    "    # í† í° ì €ì¥\n",
    "    try:\n",
    "        from src.config.token_manager import TokenManager\n",
    "        token_manager = TokenManager()\n",
    "        \n",
    "        if openai_api_key:\n",
    "            token_manager.set_token('openai', openai_api_key)\n",
    "        \n",
    "        if claude_api_key:\n",
    "            token_manager.set_token('anthropic', claude_api_key)\n",
    "        \n",
    "        if hf_token:\n",
    "            token_manager.set_token('huggingface', hf_token)\n",
    "            \n",
    "        print(\"âœ… í† í° ê´€ë¦¬ìì— API í‚¤ ì €ì¥ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í† í° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì´ì œ PromptManagerê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    print(\"âœ… í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“Š 4ë‹¨ê³„: Streamlit ì„œë²„ ì‹¤í–‰ (ë¡œì»¬ ìµœì í™”) { display-mode: \"form\" }\n",
    "#@markdown ë¡œì»¬ í™˜ê²½ì— ìµœì í™”ëœ ê°„ë‹¨í•œ Streamlit ì‹¤í–‰\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# í™˜ê²½ í™•ì¸\n",
    "config_file = Path('prep/config.json')\n",
    "is_colab_env = False\n",
    "\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    is_colab_env = config.get('environment', {}).get('use_google_drive', False)\n",
    "\n",
    "# ì•± ì„¤ì •\n",
    "app_file = \"src/app/streamlit_app.py\"\n",
    "port = 8501\n",
    "\n",
    "print(f\"ğŸš€ ChipChat {'(Google Colab)' if is_colab_env else '(ë¡œì»¬)'} ì‹œì‘ ì¤‘...\")\n",
    "print(f\"ğŸ“ íŒŒì¼: {app_file}\")\n",
    "print(f\"ğŸŒ í¬íŠ¸: {port}\")\n",
    "print(f\"âœ¨ ì£¼ìš” ê¸°ëŠ¥: AI ì—ì´ì „íŠ¸, ë©€í‹°í„´ ëŒ€í™”, LLM ëª¨ë¸ ì„ íƒ\")\n",
    "\n",
    "# í™˜ê²½ë³„ ì²˜ë¦¬\n",
    "if not is_colab_env:\n",
    "    # ë¡œì»¬ í™˜ê²½ (ê°„ì†Œí™”)\n",
    "    print(\"\\nğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ (ì¡°ìš©íˆ)\n",
    "    try:\n",
    "        subprocess.run(['pkill', '-f', 'streamlit'], \n",
    "                      check=False, capture_output=True, text=True)\n",
    "        time.sleep(1)\n",
    "        print(\"âœ… ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ê°„ë‹¨í•œ Streamlit ëª…ë ¹ì–´\n",
    "    cmd = [\n",
    "        \"streamlit\", \"run\", \n",
    "        app_file,\n",
    "        f\"--server.port={port}\", \n",
    "        \"--server.address=localhost\",\n",
    "        \"--server.headless=true\",\n",
    "        \"--browser.gatherUsageStats=false\",\n",
    "        \"--logger.level=warning\"  # ë¡œê·¸ ìµœì†Œí™”\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”§ Streamlit ì‹œì‘ ì¤‘...\")\n",
    "    \n",
    "    # ë¡œì»¬ í™˜ê²½ì—ì„œë„ ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€ìš©)\n",
    "    try:\n",
    "        from src.utils.config_manager import get_config_manager\n",
    "        config = get_config_manager()\n",
    "        vectorstore_folder = config.get_path('vectorstore_folder')\n",
    "        prep_json_folder = config.get_path('prep_json_folder')\n",
    "        prompt_templates_folder = config.get_path('prompt_templates_folder')\n",
    "    except:\n",
    "        vectorstore_folder = './vectorstore'\n",
    "        prep_json_folder = './prep_json'\n",
    "        prompt_templates_folder = './prompt_templates'\n",
    "\n",
    "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
    "    os.environ['JSON_FOLDER_PATH'] = str(prep_json_folder)\n",
    "    os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
    "    \n",
    "    try:\n",
    "        # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ë¡œê·¸ ìµœì†Œí™”)\n",
    "        process = subprocess.Popen(\n",
    "            cmd, \n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # ì ì‹œ ëŒ€ê¸°\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ìƒíƒœ í™•ì¸\n",
    "        if process.poll() is None:  # ì‹¤í–‰ ì¤‘\n",
    "            print(\"âœ… ChipChatì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            print(f\"\\nğŸ”— ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ ì£¼ì†Œë¡œ ì ‘ì†í•˜ì„¸ìš”:\")\n",
    "            print(f\"ğŸŒ http://localhost:{port}\")\n",
    "            print(f\"\\nğŸ’¡ ì‚¬ìš© ë°©ë²•:\")\n",
    "            print(f\"  â€¢ ì„¤ì • í˜ì´ì§€ì—ì„œ LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”\")\n",
    "            print(f\"  â€¢ AI ì—ì´ì „íŠ¸ê°€ ìë™ìœ¼ë¡œ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤\")\n",
    "            print(f\"  â€¢ ì¢…ë£Œí•˜ë ¤ë©´ 5ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "            \n",
    "            # í”„ë¡œì„¸ìŠ¤ ì €ì¥ (5ë‹¨ê³„ì—ì„œ ì‚¬ìš©)\n",
    "            globals()['streamlit_process'] = process\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ Streamlit ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            print(\"ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ë³´ì„¸ìš”:\")\n",
    "            print(\"  â€¢ requirements.txtê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€\")\n",
    "            print(\"  â€¢ API í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€\")\n",
    "            print(\"  â€¢ src í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        print(\"ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•´ë³´ì„¸ìš”:\")\n",
    "        print(f\"   streamlit run {app_file} --server.port={port}\")\n",
    "\n",
    "else:\n",
    "    # Google Colab í™˜ê²½ (ê¸°ì¡´ ë³µì¡í•œ ë¡œì§ ì‹¤í–‰)\n",
    "    print(\"ğŸŒ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "    print(\"âš ï¸ Google Colab ê¸°ëŠ¥ì€ í˜„ì¬ ë²„ì „ì—ì„œ ê°„ì†Œí™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ì´ì „ ë²„ì „ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    # ê¸°ë³¸ ë³€ìˆ˜ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€ìš©)\n",
    "    vectorstore_folder = './vectorstore'\n",
    "    prep_json_folder = './prep_json'\n",
    "    prompt_templates_folder = './prompt_templates'\n",
    "    \n",
    "    # í”„ë¡œì„¸ìŠ¤ ì €ì¥ (5ë‹¨ê³„ì—ì„œ ì‚¬ìš©)\n",
    "    globals()['streamlit_process'] = None\n",
    "    \n",
    "    print(\"ğŸ’¡ Google Colabì—ì„œ ìˆ˜ë™ ì‹¤í–‰í•˜ë ¤ë©´:\")\n",
    "    print(f\"   streamlit run {app_file} --server.port={port}\")\n",
    "\n",
    "# 4ë‹¨ê³„ ì™„ë£Œ - í™˜ê²½ë³„ ë¶„ê¸°ë¡œ ì²˜ë¦¬ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ›‘ 5ë‹¨ê³„: ì„œë²„ ì¤‘ì§€ { display-mode: \"form\" }\n",
    "#@markdown ì‘ì—…ì„ ë§ˆì¹˜ë©´ ì„œë²„ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import signal\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# ì„œë²„ ì¤‘ì§€ ì—¬ë¶€ í™•ì¸\n",
    "stop_server = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if stop_server:\n",
    "    print(\"ğŸ›‘ ì„œë²„ ì¢…ë£Œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ngrok í„°ë„ ì¢…ë£Œ (ngrok ì‚¬ìš©í•œ ê²½ìš°ì—ë§Œ)\n",
    "    try:\n",
    "        from pyngrok import ngrok\n",
    "        ngrok.kill()\n",
    "        print(\"âœ… ngrok í„°ë„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸ ngrok ì¢…ë£Œ: {str(e)}\")\n",
    "    \n",
    "    # 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ í”„ë¡œì„¸ìŠ¤ ë¨¼ì € ì¢…ë£Œ\n",
    "    terminated_process = False\n",
    "    if 'streamlit_process' in globals():\n",
    "        try:\n",
    "            process = globals()['streamlit_process']\n",
    "            if process and process.poll() is None:\n",
    "                print(\"ğŸ”„ 4ë‹¨ê³„ì—ì„œ ì‹¤í–‰ëœ Streamlit í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œ ì¤‘...\")\n",
    "                process.terminate()\n",
    "                time.sleep(3)\n",
    "                \n",
    "                if process.poll() is None:\n",
    "                    print(\"âš¡ ê°•ì œ ì¢…ë£Œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "                    process.kill()\n",
    "                    time.sleep(2)\n",
    "                \n",
    "                print(\"âœ… Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                terminated_process = True\n",
    "            else:\n",
    "                print(\"â„¹ï¸ Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # ì¶”ê°€ì ìœ¼ë¡œ ëª¨ë“  streamlit í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ\n",
    "    try:\n",
    "        print(\"ğŸ” ë‚¨ì€ Streamlit í”„ë¡œì„¸ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘...\")\n",
    "        result = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "        if result.stdout.strip():\n",
    "            pids = result.stdout.strip().split('\\n')\n",
    "            print(f\"ğŸ“‹ ë°œê²¬ëœ Streamlit í”„ë¡œì„¸ìŠ¤: {len(pids)}ê°œ\")\n",
    "            \n",
    "            subprocess.run(['pkill', '-f', 'streamlit'], check=False)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            result_after = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "            if not result_after.stdout.strip():\n",
    "                print(\"âœ… ëª¨ë“  Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ì¼ë¶€ í”„ë¡œì„¸ìŠ¤ê°€ ì—¬ì „íˆ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âœ… ì‹¤í–‰ ì¤‘ì¸ Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "        print(\"ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ì—¬ ì„œë²„ë¥¼ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # í¬íŠ¸ ì‚¬ìš© ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        import socket\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        result = sock.connect_ex(('localhost', 8501))\n",
    "        sock.close()\n",
    "        \n",
    "        if result != 0:\n",
    "            print(\"âœ… í¬íŠ¸ 8501ì´ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ í¬íŠ¸ 8501ì´ ì•„ì§ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸ í¬íŠ¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ ì„œë²„ ì¢…ë£Œ ì™„ë£Œ!\")\n",
    "    print(\"ğŸ’¡ ì™„ì „í•œ ì •ë¦¬ë¥¼ ìœ„í•´ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ”„ ëŸ°íƒ€ì„ â†’ ì„¸ì…˜ ì¬ì‹œì‘ì„ í†µí•´ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ì „íˆ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ ì„œë²„ ì¤‘ì§€ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ë¬¸ì œ í•´ê²°\n",
    "\n",
    "**ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°:**\n",
    "\n",
    "1. **API í‚¤ í™•ì¸**: OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "2. **ì„¸ì…˜ ì¬ì‹œì‘**: ëŸ°íƒ€ì„ â†’ ì„¸ì…˜ ì¬ì‹œì‘ í›„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹¤í–‰\n",
    "3. **JSON íŒŒì¼ í™•ì¸**: ì „ì²˜ë¦¬ëœ JSON íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "\n",
    "**ì‚¬ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:**\n",
    "- ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”\n",
    "- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

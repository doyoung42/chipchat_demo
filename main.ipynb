{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Datasheet Analyzer\n",
    "\n",
    "**AIë¥¼ í™œìš©í•œ ë°ì´í„°ì‹œíŠ¸ ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤. ì½”ë”© ì§€ì‹ ì—†ì´ë„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
    "\n",
    "**[í•„ìˆ˜] GPU ì„¤ì •:** \n",
    "1. ìƒë‹¨ ë©”ë‰´ â†’ **ëŸ°íƒ€ì„** â†’ **ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½**\n",
    "2. **í•˜ë“œì›¨ì–´ ê°€ì†ê¸°: GPU**ë¡œ ì„¤ì •\n",
    "3. **ì €ì¥** í´ë¦­\n",
    "\n",
    "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
    "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title âœ… 1ë‹¨ê³„: GPU ì„¤ì • í™•ì¸ { display-mode: \"form\" }\n",
    "#@markdown GPUê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "import torch\n",
    "print(\"ğŸ” ì‹œìŠ¤í…œ í™•ì¸ ì¤‘...\\n\")\n",
    "\n",
    "# GPU í™•ì¸\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "\n",
    "# PyTorch GPU í™•ì¸\n",
    "print(f\"\\nğŸ“ PyTorch ë²„ì „: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_name}\")\n",
    "    print(\"ğŸ‰ ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"âš ï¸ ìƒë‹¨ ë©”ë‰´ì—ì„œ ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ GPUë¡œ ì„¤ì •í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“¥ 2ë‹¨ê³„: í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ { display-mode: \"form\" }\n",
    "#@markdown GitHubì—ì„œ ìµœì‹  ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“¥ Datasheet Analyzer ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ì‚­ì œ í›„ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "if os.path.exists('autodatasheet'):\n",
    "    !rm -rf autodatasheet\n",
    "    print(\"ğŸ”„ ê¸°ì¡´ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# Repository ë³µì œ\n",
    "!git clone https://github.com/doyoung42/autodatasheet.git\n",
    "%cd autodatasheet\n",
    "\n",
    "print(\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°:\")\n",
    "!find . -maxdepth 2 -type d | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”§ 3ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
    "#@markdown í”„ë¡œê·¸ë¨ ì‹¤í–‰ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤. (1-2ë¶„ ì†Œìš”)\n",
    "\n",
    "print(\"ğŸ”§ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
    "print(\"â° ì•½ 1-2ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Colab ì „ìš© ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "!pip install streamlit-option-menu -q\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "print(\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ API í† í°ì„ ì„¤ì •í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”‘ 4ë‹¨ê³„: API í† í° ì„¤ì • { display-mode: \"form\" }\n",
    "#@markdown ì‚¬ìš©í•˜ì‹¤ AI ì„œë¹„ìŠ¤ì˜ API í† í°ì„ ì…ë ¥í•˜ì„¸ìš”. (HuggingFace ì…ë ¥ í•„ìˆ˜)\n",
    "\n",
    "huggingface_token = \"\" #@param {type:\"string\"}\n",
    "openai_token = \"\" #@param {type:\"string\"}\n",
    "anthropic_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# ì‹œìŠ¤í…œ ê²½ë¡œ ì„¤ì •\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir / 'src'))\n",
    "\n",
    "src_dir = current_dir / 'src'\n",
    "if src_dir.exists():\n",
    "    sys.path.append(str(src_dir))\n",
    "    for subdir in ['config', 'models', 'utils']:\n",
    "        subdir_path = src_dir / subdir\n",
    "        if subdir_path.exists():\n",
    "            sys.path.append(str(subdir_path))\n",
    "\n",
    "# í† í° ì €ì¥\n",
    "try:\n",
    "    from config.token_manager import TokenManager\n",
    "    token_manager = TokenManager()\n",
    "    \n",
    "    saved_tokens = []\n",
    "    \n",
    "    if huggingface_token.strip():\n",
    "        token_manager.set_token('huggingface', huggingface_token.strip())\n",
    "        saved_tokens.append('HuggingFace')\n",
    "    \n",
    "    if openai_token.strip():\n",
    "        token_manager.set_token('openai', openai_token.strip())\n",
    "        saved_tokens.append('OpenAI')\n",
    "    \n",
    "    if anthropic_token.strip():\n",
    "        token_manager.set_token('anthropic', anthropic_token.strip())\n",
    "        saved_tokens.append('Anthropic')\n",
    "    \n",
    "    if saved_tokens:\n",
    "        print(f\"âœ… {', '.join(saved_tokens)} API í† í°ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ‰ í† í° ì„¤ì • ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì…ë ¥ëœ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ìµœì†Œ 1ê°œ ì´ìƒì˜ API í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        \n",
    "        print(\"\\nğŸ“š API í† í° ë°œê¸‰ ë°©ë²•:\")\n",
    "        print(\"â€¢ HuggingFace: https://huggingface.co/settings/tokens\")\n",
    "        print(\"â€¢ OpenAI: https://platform.openai.com/api-keys\")\n",
    "        print(\"â€¢ Anthropic: https://console.anthropic.com/\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ í† í° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "    print(\"ğŸ”§ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸš€ 5ë‹¨ê³„: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ { display-mode: \"form\" }\n",
    "#@markdown ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸš€ Datasheet Analyzer ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "print(\"â° ì•½ 10ì´ˆ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "def run_streamlit():\n",
    "    \"\"\"ë°±ê·¸ë¼ìš´ë“œì—ì„œ Streamlit ì‹¤í–‰\"\"\"\n",
    "    try:\n",
    "        env = os.environ.copy()\n",
    "        env.update({\n",
    "            'STREAMLIT_SERVER_HEADLESS': 'true',\n",
    "            'STREAMLIT_SERVER_PORT': '8501',\n",
    "            'STREAMLIT_SERVER_ADDRESS': '0.0.0.0',\n",
    "            'STREAMLIT_BROWSER_SERVER_ADDRESS': '0.0.0.0',\n",
    "            'STREAMLIT_SERVER_MAX_UPLOAD_SIZE': '200',\n",
    "            'STREAMLIT_SERVER_ENABLE_CORS': 'false',\n",
    "            'STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION': 'false',\n",
    "            'PYTHONPATH': f\"{Path.cwd()}:{Path.cwd()}/src\"\n",
    "        })\n",
    "        \n",
    "        subprocess.run([\n",
    "            'streamlit', 'run', 'src/app/streamlit_app.py',\n",
    "            '--server.port=8501',\n",
    "            '--server.address=0.0.0.0',\n",
    "            '--server.maxUploadSize=200',\n",
    "            '--server.enableCORS=false',\n",
    "            '--server.enableXsrfProtection=false'\n",
    "        ], env=env, capture_output=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰\n",
    "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "# ì„œë²„ ì‹œì‘ ëŒ€ê¸°\n",
    "print(\"â³ ì„œë²„ ì¤€ë¹„ ì¤‘...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# ì›¹ URL ìƒì„±\n",
    "try:\n",
    "    from google.colab.output import eval_js\n",
    "    url = eval_js('google.colab.kernel.proxyPort(8501)')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ‰ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"\\nğŸ”— ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:\")\n",
    "    print(f\"ğŸ“± {url}\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nğŸ’¡ ì‚¬ìš© íŒ:\")\n",
    "    print(\"â€¢ ë§í¬ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—´ì–´ì„œ ì‚¬ìš©í•˜ì„¸ìš”\")\n",
    "    print(\"â€¢ íŒŒì¼ ì—…ë¡œë“œëŠ” ìµœëŒ€ 200MBê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ URL ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "    print(\"ğŸ”§ ìˆ˜ë™ìœ¼ë¡œ í¬íŠ¸ 8501ì— ì ‘ì†í•´ë³´ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› ï¸ ë¬¸ì œ í•´ê²°\n",
    "\n",
    "**ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°:**\n",
    "\n",
    "1. **GPU ì„¤ì • í™•ì¸**: ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ GPU ì„¤ì •\n",
    "2. **ì„¸ì…˜ ì¬ì‹œì‘**: ëŸ°íƒ€ì„ â†’ ì„¸ì…˜ ì¬ì‹œì‘ í›„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹¤í–‰\n",
    "3. **í† í° í™•ì¸**: API í† í°ì´ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "**ì‚¬ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:**\n",
    "- ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”\n",
    "- íŒŒì¼ í¬ê¸°ê°€ 200MBë¥¼ ì´ˆê³¼í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\n",
    "- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ì§€ì›\n",
    "\n",
    "ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ GitHub ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”:\n",
    "ğŸ”— https://github.com/doyoung42/autodatasheet/issues\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

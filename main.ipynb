{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ’¬ ChipChat - ë°ì´í„°ì‹œíŠ¸ ì±—ë´‡\n",
    "\n",
    "**ì „ì²˜ë¦¬ëœ ë°ì´í„°ì‹œíŠ¸ JSON íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ì‹œì‘í•˜ê¸° ì „ì—\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ChipChat ì•±ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ë¡œì»¬ í™˜ê²½ê³¼ Google Colab í™˜ê²½ ëª¨ë‘ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## âœ¨ ì£¼ìš” ê¸°ëŠ¥ë“¤\n",
    "- ğŸ¤– **AI Agent ì‹œìŠ¤í…œ**: LangGraph ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì—ì´ì „íŠ¸\n",
    "- ğŸ”§ **3ê°€ì§€ Tool ìë™ ì„ íƒ**: chipDB ê²€ìƒ‰, ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰, PDF ì²˜ë¦¬\n",
    "- ğŸ“Š **ChipDB.csv ì—°ë™**: ë¶€í’ˆ ì‚¬ì–‘ ìš”ì•½ ë°ì´í„°ë² ì´ìŠ¤ í™œìš©\n",
    "- ğŸ¯ **ë‹¤ì¤‘ LLM ì§€ì›**: OpenAIì™€ Claude ëª¨ë¸ ì„ íƒ ê°€ëŠ¥\n",
    "- ğŸ“„ **ì‹¤ì‹œê°„ PDF ì—…ë¡œë“œ**: ìƒˆ ë°ì´í„°ì‹œíŠ¸ ìë™ ì²˜ë¦¬ ë° í†µí•©\n",
    "- ğŸ” **ê³ ê¸‰ í•„í„°ë§**: ë¶€í’ˆë²ˆí˜¸, ì œì¡°ì‚¬, ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰\n",
    "- ğŸ› ï¸ **í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ììœ  ìˆ˜ì •\n",
    "- ğŸ·ï¸ **ë©”íƒ€ë°ì´í„° ì¶”ì **: ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ\n",
    "\n",
    "## ğŸ“‹ ì‚¬ìš© ë°©ë²•\n",
    "ì•„ë˜ ì…€ë“¤ì„ **ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. (ê° ì…€ì˜ â–¶ï¸ ë²„íŠ¼ì„ í´ë¦­)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title âœ… 1ë‹¨ê³„: í™˜ê²½ ì„¤ì • { display-mode: \"form\" }\n",
    "#@markdown ë¡œì»¬ ë˜ëŠ” Google Drive í™˜ê²½ì„ ì„ íƒí•˜ê³  ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# í™˜ê²½ ì„ íƒ í† ê¸€\n",
    "use_google_drive = False #@param {type:\"boolean\"}\n",
    "#@markdown âœ… ì²´í¬: Google Drive ì‚¬ìš© (Colab í™˜ê²½) | âŒ ì²´í¬í•´ì œ: ë¡œì»¬ í™˜ê²½ ì‚¬ìš©\n",
    "\n",
    "# config.json íŒŒì¼ ê²½ë¡œ\n",
    "config_file = Path('config.json')\n",
    "\n",
    "if config_file.exists():\n",
    "    # ê¸°ì¡´ config.json ë¡œë“œ\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸\n",
    "    config['environment']['use_google_drive'] = use_google_drive\n",
    "    \n",
    "    # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(\"âœ… config.json ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âŒ config.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ê¸°ë³¸ config.json ìƒì„±\n",
    "    default_config = {\n",
    "        \"environment\": {\n",
    "            \"use_google_drive\": use_google_drive,\n",
    "            \"description\": \"Environment selection: true for Google Drive (Colab), false for local\"\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"google_drive\": {\n",
    "                \"base_path\": \"/content/drive/MyDrive\",\n",
    "                \"prep_json_folder\": \"/content/drive/MyDrive/prep_json\",\n",
    "                \"vectorstore_folder\": \"/content/drive/MyDrive/vectorstore\",\n",
    "                \"prompt_templates_folder\": \"/content/drive/MyDrive/prompt_templates\",\n",
    "                \"model_cache_folder\": \"/content/drive/MyDrive/hf_model_cache\",\n",
    "                \"logs_folder\": \"/content/drive/MyDrive/chipchat_logs\"\n",
    "            },\n",
    "            \"local\": {\n",
    "                \"base_path\": \".\",\n",
    "                \"prep_json_folder\": \"./prep_json\",\n",
    "                \"vectorstore_folder\": \"./vectorstore\",\n",
    "                \"prompt_templates_folder\": \"./prompt_templates\",\n",
    "                \"model_cache_folder\": \"./hf_model_cache\",\n",
    "                \"logs_folder\": \"./logs\"\n",
    "            }\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            \"supported_llm\": {\n",
    "                \"openai\": [\"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"],\n",
    "                \"claude\": [\"claude-3-sonnet\", \"claude-3-haiku\", \"claude-3-opus\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(default_config, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    config = default_config\n",
    "    print(\"âœ… ê¸°ë³¸ config.json ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "# í˜„ì¬ í™˜ê²½ ì„¤ì • í‘œì‹œ\n",
    "env_type = \"Google Drive\" if use_google_drive else \"ë¡œì»¬\"\n",
    "current_paths = config['paths']['google_drive' if use_google_drive else 'local']\n",
    "\n",
    "print(f\"\\nğŸŒ {env_type} í™˜ê²½ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“‹ ì„¤ì •ëœ ê²½ë¡œë“¤:\")\n",
    "for key, path in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        print(f\"  â€¢ {key.replace('_', ' ').title()}: {path}\")\n",
    "\n",
    "# Google Drive ë§ˆìš´íŠ¸ (í•„ìš”í•œ ê²½ìš°)\n",
    "if use_google_drive:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        print(\"\\nğŸ”„ Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"âœ… Google Drive ì—°ë™ ì™„ë£Œ!\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ Google Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. í™˜ê²½ ì„¤ì •ì„ ë¡œì»¬ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\")\n",
    "        config['environment']['use_google_drive'] = False\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "        current_paths = config['paths']['local']\n",
    "        print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ìœ¼ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "print(\"\\nğŸ“ í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...\")\n",
    "for key, path_str in current_paths.items():\n",
    "    if key != 'base_path':\n",
    "        path = Path(path_str)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  âœ… {path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“¥ 2ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ { display-mode: \"form\" }\n",
    "#@markdown í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“¥ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
    "\n",
    "# GitHub ì €ì¥ì†Œ í´ë¡  (ë¡œì»¬ í™˜ê²½ì´ ì•„ë‹Œ ê²½ìš°)\n",
    "try:\n",
    "    if not Path('src').exists():  # src í´ë”ê°€ ì—†ìœ¼ë©´ í´ë¡  í•„ìš”\n",
    "        print(\"ğŸ”„ GitHub ì €ì¥ì†Œ í´ë¡  ì¤‘...\")\n",
    "        subprocess.run(['git', 'clone', 'https://github.com/doyoung42/chipchat_demo.git', 'temp_clone'], check=True)\n",
    "        \n",
    "        # í•„ìš”í•œ íŒŒì¼ë“¤ ë³µì‚¬\n",
    "        import shutil\n",
    "        if Path('temp_clone/src').exists():\n",
    "            shutil.copytree('temp_clone/src', 'src', dirs_exist_ok=True)\n",
    "        if Path('temp_clone/requirements.txt').exists():\n",
    "            shutil.copy2('temp_clone/requirements.txt', 'requirements.txt')\n",
    "        \n",
    "        # ì„ì‹œ í´ë” ì‚­ì œ\n",
    "        shutil.rmtree('temp_clone')\n",
    "        print(\"âœ… í•„ìš”í•œ íŒŒì¼ë“¤ ë³µì‚¬ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âœ… ì†ŒìŠ¤ ì½”ë“œ ì´ë¯¸ ì¡´ì¬\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ GitHub í´ë¡  ì‹¤íŒ¨: {str(e)}\")\n",
    "    print(\"ğŸ’¡ ë¡œì»¬ í™˜ê²½ì—ì„œ ì´ë¯¸ íŒŒì¼ë“¤ì´ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# requirements.txt ì„¤ì¹˜\n",
    "if Path('requirements.txt').exists():\n",
    "    try:\n",
    "        subprocess.run(['pip', 'install', '-r', 'requirements.txt', '-q'], check=True)\n",
    "        print(\"âœ… Requirements ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Requirements ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}\")\n",
    "else:\n",
    "    print(\"âš ï¸ requirements.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab ì „ìš©)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    subprocess.run(['pip', 'install', 'pyngrok==7.0.1', '-q'], check=True)\n",
    "    print(\"âœ… pyngrok ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½: pyngrok ì„¤ì¹˜ ìƒëµ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ pyngrok ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# Python path ì„¤ì •\n",
    "import sys\n",
    "current_dir = Path(os.getcwd())\n",
    "sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir / 'src'))\n",
    "\n",
    "# ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì¶”ê°€\n",
    "src_dir = current_dir / 'src'\n",
    "if src_dir.exists():\n",
    "    sys.path.append(str(src_dir))\n",
    "    for subdir in ['config', 'models', 'utils', 'app']:\n",
    "        subdir_path = src_dir / subdir\n",
    "        if subdir_path.exists():\n",
    "            sys.path.append(str(subdir_path))\n",
    "\n",
    "print(\"\\nâœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ê²½ë¡œ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ“‹ ì§€ì›ë˜ëŠ” LLM ëª¨ë¸:\")\n",
    "print(\"ğŸ”¸ OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\")\n",
    "print(\"ğŸ”¸ Claude: claude-3-sonnet, claude-3-haiku, claude-3-opus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸš€ 2-1ë‹¨ê³„: ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ { display-mode: \"form\" }\n",
    "#@markdown HuggingFace ëª¨ë¸ì„ ìºì‹±í•˜ì—¬ ë¹ ë¥¸ ë¡œë”©ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "import time\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.model_cache import get_model_cache\n",
    "\n",
    "# ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(\"ğŸ“Š ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "logger = get_logger()\n",
    "logger.log_system_info()\n",
    "logger.info(\"Main notebook ì‹¤í–‰ ì‹œì‘\")\n",
    "\n",
    "# ëª¨ë¸ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(\"\\nğŸ—„ï¸ ëª¨ë¸ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "model_cache = get_model_cache()\n",
    "cache_info = model_cache.get_cache_info()\n",
    "\n",
    "print(f\"ğŸ“ ìºì‹œ ë””ë ‰í† ë¦¬: {cache_info['cache_dir']}\")\n",
    "print(f\"ğŸ“¦ ìºì‹œëœ ëª¨ë¸ ìˆ˜: {cache_info['model_count']}\")\n",
    "print(f\"ğŸ’¾ ì „ì²´ ìºì‹œ í¬ê¸°: {cache_info['total_size_mb']:.2f} MB\")\n",
    "\n",
    "if cache_info['models']:\n",
    "    print(\"\\nâœ… ìºì‹œëœ ëª¨ë¸:\")\n",
    "    for model in cache_info['models']:\n",
    "        print(f\"  - {model}\")\n",
    "\n",
    "# ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ì˜µì…˜\n",
    "download_model = True #@param {type:\"boolean\"}\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" #@param {type:\"string\"}\n",
    "\n",
    "if download_model:\n",
    "    print(f\"\\nğŸ”„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìºì‹œ í™•ì¸: {model_name}\")\n",
    "    \n",
    "    @logger.measure_time(\"ëª¨ë¸ ì¤€ë¹„\")\n",
    "    def prepare_model():\n",
    "        # ìºì‹œ í™•ì¸\n",
    "        if model_cache.is_model_cached(model_name):\n",
    "            print(\"âœ… ëª¨ë¸ì´ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            # ìºì‹œì—ì„œ ë¡œë“œ\n",
    "            if model_cache.load_model_from_cache(model_name):\n",
    "                print(\"âœ… ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "                return True\n",
    "        \n",
    "        # ìºì‹œì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ\n",
    "        print(\"ğŸ“¥ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "        try:\n",
    "            from langchain_huggingface import HuggingFaceEmbeddings\n",
    "            \n",
    "            # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì´ˆê¸°í™”ë¥¼ í†µí•´)\n",
    "            start_time = time.time()\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            download_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {download_time:.2f}ì´ˆ)\")\n",
    "            \n",
    "            # ìºì‹œì— ì €ì¥\n",
    "            print(\"ğŸ’¾ ëª¨ë¸ì„ ìºì‹œì— ì €ì¥ ì¤‘...\")\n",
    "            if model_cache.save_model_to_cache(model_name):\n",
    "                print(\"âœ… ëª¨ë¸ ìºì‹œ ì €ì¥ ì™„ë£Œ!\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ëª¨ë¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨ (ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨: {e}\")\n",
    "            print(f\"âŒ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # ëª¨ë¸ ì¤€ë¹„ ì‹¤í–‰\n",
    "    success = prepare_model()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! ì´ì œ Streamlit ì•±ì´ ë” ë¹ ë¥´ê²Œ ë¡œë“œë©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ëª¨ë¸ ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê³„ì† ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì„±ëŠ¥ ìš”ì•½ í‘œì‹œ\n",
    "print(\"\\nğŸ“Š í˜„ì¬ê¹Œì§€ì˜ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "perf_summary = logger.get_performance_summary()\n",
    "for op, stats in perf_summary.items():\n",
    "    print(f\"\\nğŸ”¹ {op}:\")\n",
    "    print(f\"   - í‰ê·  ì‹œê°„: {stats['avg_time']:.2f}ì´ˆ\")\n",
    "    print(f\"   - ì„±ê³µ: {stats['success_count']}íšŒ, ì‹¤íŒ¨: {stats['fail_count']}íšŒ\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”‘ 3ë‹¨ê³„: API í‚¤ ì„¤ì • { display-mode: \"form\" }\n",
    "#@markdown AI ì„œë¹„ìŠ¤ì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì—¬ ì±—ë´‡ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "openai_api_key = \"\" #@param {type:\"string\"}\n",
    "claude_api_key = \"\" #@param {type:\"string\"}\n",
    "hf_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬\n",
    "if not openai_api_key and not claude_api_key and not hf_token:\n",
    "    print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"â€¢ OpenAI API í‚¤: https://platform.openai.com/api-keys\")\n",
    "    print(\"â€¢ Claude API í‚¤: https://console.anthropic.com/keys\")\n",
    "    print(\"â€¢ HuggingFace í† í°: https://huggingface.co/settings/tokens\")\n",
    "else:\n",
    "    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    if openai_api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        print(\"âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
    "        \n",
    "    if claude_api_key:\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = claude_api_key\n",
    "        print(\"âœ… Claude API í‚¤ ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    if hf_token:\n",
    "        os.environ[\"HF_TOKEN\"] = hf_token\n",
    "        print(\"âœ… HuggingFace í† í° ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    # Streamlit ì‹œí¬ë¦¿ íŒŒì¼ ìƒì„±\n",
    "    secrets_dir = Path(\".streamlit\")\n",
    "    secrets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    secrets = {}\n",
    "    if openai_api_key:\n",
    "        secrets[\"openai_api_key\"] = openai_api_key\n",
    "    if claude_api_key:\n",
    "        secrets[\"anthropic_api_key\"] = claude_api_key\n",
    "    if hf_token:\n",
    "        secrets[\"hf_token\"] = hf_token\n",
    "    \n",
    "    with open(secrets_dir / \"secrets.toml\", \"w\") as f:\n",
    "        for key, value in secrets.items():\n",
    "            f.write(f'{key} = \"{value}\"\\n')\n",
    "    \n",
    "    # í† í° ì €ì¥\n",
    "    try:\n",
    "        from src.config.token_manager import TokenManager\n",
    "        token_manager = TokenManager()\n",
    "        \n",
    "        if openai_api_key:\n",
    "            token_manager.set_token('openai', openai_api_key)\n",
    "        \n",
    "        if claude_api_key:\n",
    "            token_manager.set_token('anthropic', claude_api_key)\n",
    "        \n",
    "        if hf_token:\n",
    "            token_manager.set_token('huggingface', hf_token)\n",
    "            \n",
    "        print(\"âœ… í† í° ê´€ë¦¬ìì— API í‚¤ ì €ì¥ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í† í° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "    \n",
    "    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    default_template = {\n",
    "        \"pre\": \"ë‹¹ì‹ ì€ ì „ì ë¶€í’ˆ ë°ì´í„°ì‹œíŠ¸ì— ëŒ€í•´ ì‘ë‹µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\",\n",
    "        \"post\": \"ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\n",
    "    }\n",
    "    \n",
    "    # config.jsonì—ì„œ ê²½ë¡œ ì½ê¸°\n",
    "    try:\n",
    "        from src.utils.config_manager import get_config_manager\n",
    "        config = get_config_manager()\n",
    "        prompt_templates_folder = Path(config.get_path('prompt_templates_folder'))\n",
    "    except:\n",
    "        prompt_templates_folder = Path('./prompt_templates')\n",
    "    \n",
    "    template_file = prompt_templates_folder / \"default_template.json\"\n",
    "    if not template_file.exists():\n",
    "        with open(template_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(default_template, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        print(\"âœ… ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“Š 4ë‹¨ê³„: Streamlit ì„œë²„ ì‹¤í–‰ { display-mode: \"form\" }\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# ê°„ì†Œí™”ëœ ChipChat ì•± ì‹¤í–‰\n",
    "app_file = \"src/app/streamlit_app.py\"\n",
    "port = 8501\n",
    "\n",
    "print(f\"ğŸ¯ ChipChat ë©€í‹°í„´ ì±—ë´‡ ì‹¤í–‰\")\n",
    "print(f\"ğŸ“ ì„¤ëª…: LangGraph ê¸°ë°˜ ë©€í‹°ì—ì´ì „íŠ¸ ì±—ë´‡\")\n",
    "print(f\"ğŸ“ íŒŒì¼: {app_file}\")\n",
    "print(f\"ğŸŒ í¬íŠ¸: {port}\")\n",
    "print(f\"\")\n",
    "print(f\"âœ¨ ì£¼ìš” ê¸°ëŠ¥:\")\n",
    "print(f\"  â€¢ ğŸ¤– ìë™ ë„êµ¬ ì„ íƒ (ChipDB, Vectorstore)\")\n",
    "print(f\"  â€¢ ğŸ’¬ ë©€í‹°í„´ ëŒ€í™” ì§€ì›\")\n",
    "print(f\"  â€¢ ğŸ”§ LLM ëª¨ë¸ ì„ íƒ ê°€ëŠ¥\")\n",
    "print(f\"  â€¢ ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "\n",
    "# config.jsonì—ì„œ ê²½ë¡œ ì½ê¸°\n",
    "try:\n",
    "    from src.utils.config_manager import get_config_manager\n",
    "    config = get_config_manager()\n",
    "    vectorstore_folder = config.get_path('vectorstore_folder')\n",
    "    prep_json_folder = config.get_path('prep_json_folder')\n",
    "    prompt_templates_folder = config.get_path('prompt_templates_folder')\n",
    "except:\n",
    "    vectorstore_folder = './vectorstore'\n",
    "    prep_json_folder = './prep_json'\n",
    "    prompt_templates_folder = './prompt_templates'\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ['VECTORSTORE_PATH'] = str(vectorstore_folder)\n",
    "os.environ['JSON_FOLDER_PATH'] = str(prep_json_folder)\n",
    "os.environ['PROMPT_TEMPLATES_PATH'] = str(prompt_templates_folder)\n",
    "\n",
    "# ë¡œê¹… ì •ë³´ í‘œì‹œ\n",
    "if 'logger' in globals():\n",
    "    logger.info(\"Streamlit ì•± ì‹œì‘ ì¤€ë¹„\", extra={\n",
    "        \"vectorstore_path\": str(vectorstore_folder),\n",
    "        \"json_folder_path\": str(prep_json_folder),\n",
    "        \"prompt_templates_path\": str(prompt_templates_folder),\n",
    "        \"port\": port\n",
    "    })\n",
    "\n",
    "# ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜\n",
    "def print_output(process):\n",
    "    \"\"\"ì‹¤ì‹œê°„ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ì„ í‘œì‹œ (ì¤‘ìš”í•œ ë¡œê·¸ë§Œ)\"\"\"\n",
    "    important_keywords = [\n",
    "        'You can now view your Streamlit app',\n",
    "        'Local URL:',\n",
    "        'Network URL:', \n",
    "        'External URL:',\n",
    "        'ERROR',\n",
    "        'CRITICAL',\n",
    "        'WARNING',\n",
    "        'started server',\n",
    "        'Server started',\n",
    "        'Running on',\n",
    "        'ModuleNotFoundError',\n",
    "        'ImportError',\n",
    "        'Exception'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            if line:\n",
    "                line_text = line.strip() if isinstance(line, str) else line.decode('utf-8').strip()\n",
    "                \n",
    "                # ì¤‘ìš”í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¡œê·¸ë§Œ í‘œì‹œ\n",
    "                if line_text and any(keyword.lower() in line_text.lower() for keyword in important_keywords):\n",
    "                    print(f\"ğŸ“‹ [Streamlit] {line_text}\")\n",
    "                elif 'streamlit' in line_text.lower() and ('ready' in line_text.lower() or 'starting' in line_text.lower()):\n",
    "                    print(f\"ğŸ“‹ [Streamlit] {line_text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë¡œê·¸ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì„œë²„ ìƒíƒœ í™•ì¸ í•¨ìˆ˜\n",
    "def check_server_status(port, max_attempts=30):\n",
    "    \"\"\"ì„œë²„ê°€ ì‹¤ì œë¡œ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    print(f\"ğŸ” í¬íŠ¸ {port}ì—ì„œ ì„œë²„ ì‹œì‘ ìƒíƒœë¥¼ í™•ì¸ ì¤‘...\")\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = requests.get(f\"http://localhost:{port}\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"âœ… ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! (ì‹œë„ {attempt + 1}/{max_attempts})\")\n",
    "                return True\n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(f\"â³ ì„œë²„ ì‹œì‘ ëŒ€ê¸° ì¤‘... ({attempt + 1}/{max_attempts})\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"âŒ ì„œë²„ ì‹œì‘ í™•ì¸ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_attempts})\")\n",
    "    return False\n",
    "\n",
    "# Streamlit ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_streamlit_unified(app_file, port):\n",
    "    print(\"ğŸ”§ Streamlit ëª…ë ¹ì–´ ì„¤ì • ì¤‘...\")\n",
    "    cmd = [\n",
    "        \"streamlit\", \"run\", \n",
    "        app_file,\n",
    "        f\"--server.port={port}\", \n",
    "        \"--server.address=0.0.0.0\",\n",
    "        \"--server.headless=true\",\n",
    "        \"--browser.serverAddress=localhost\",\n",
    "        \"--browser.gatherUsageStats=false\",\n",
    "        \"--logger.level=info\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ“‹ ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
    "    print(\"ğŸš€ Streamlit í”„ë¡œì„¸ìŠ¤ ì‹œì‘...\")\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        cmd, \n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    return process\n",
    "\n",
    "# ngrok ì‚¬ìš© ì—¬ë¶€ ì„ íƒ\n",
    "use_ngrok = False #@param {type:\"boolean\"}\n",
    "ngrok_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "print(\"\\nğŸ“ í˜„ì¬ ì„¤ì •:\")\n",
    "print(f\"  â€¢ í¬íŠ¸: {port}\")\n",
    "print(f\"  â€¢ Vectorstore ê²½ë¡œ: {vectorstore_folder}\")\n",
    "print(f\"  â€¢ JSON í´ë” ê²½ë¡œ: {prep_json_folder}\")\n",
    "print(f\"  â€¢ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê²½ë¡œ: {prompt_templates_folder}\")\n",
    "print(f\"  â€¢ ngrok ì‚¬ìš©: {use_ngrok}\")\n",
    "\n",
    "# ê¸°ì¡´ Streamlit í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ\n",
    "print(\"\\nğŸ”„ ê¸°ì¡´ Streamlit í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘...\")\n",
    "try:\n",
    "    subprocess.run(['pkill', '-f', 'streamlit'], check=False, capture_output=True)\n",
    "    time.sleep(2)\n",
    "    print(\"âœ… ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}\")\n",
    "\n",
    "# í†µí•© Streamlit ì„œë²„ ì‹¤í–‰\n",
    "process = run_streamlit_unified(app_file, port)\n",
    "\n",
    "# ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¡œê·¸ ì¶œë ¥\n",
    "log_thread = threading.Thread(target=print_output, args=(process,), daemon=True)\n",
    "log_thread.start()\n",
    "\n",
    "# ì„œë²„ ì‹œì‘ ìƒíƒœ í™•ì¸\n",
    "server_started = check_server_status(port)\n",
    "\n",
    "if server_started:\n",
    "    if use_ngrok and ngrok_token:\n",
    "        # ngrok ì‚¬ìš© (ì™¸ë¶€ ì ‘ì† ê°€ëŠ¥í•œ ê³µê°œ URL)\n",
    "        try:\n",
    "            print(\"\\nğŸŒ ngrok í„°ë„ ìƒì„± ì¤‘...\")\n",
    "            from pyngrok import ngrok\n",
    "            ngrok.set_auth_token(ngrok_token)\n",
    "            public_url = ngrok.connect(port).public_url\n",
    "            print(f\"âœ… ngrok í„°ë„ ìƒì„± ì™„ë£Œ!\")\n",
    "            print(f\"\\nğŸ”— ë‹¤ìŒ URLì„ í†µí•´ ChipChatì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "            print(f\"ğŸ“± {public_url}\")\n",
    "            print(\"\\nğŸ“Œ ì´ URLì€ ì„¸ì…˜ì´ ìœ ì§€ë˜ëŠ” ë™ì•ˆì—ë§Œ ìœ íš¨í•©ë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ngrok ì—°ê²° ì‹¤íŒ¨: {str(e)}\")\n",
    "            print(\"ğŸ”„ Google Colab ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.\")\n",
    "            use_ngrok = False\n",
    "\n",
    "    if not use_ngrok:\n",
    "        # Google Colab ë‚´ì¥ ê¸°ëŠ¥ ì‚¬ìš©\n",
    "        print(f\"\\nâœ… ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(f\"\\nğŸ”— ChipChatì— ì ‘ì†í•˜ëŠ” ë°©ë²•:\")\n",
    "        print(f\"1ï¸âƒ£ í¬íŠ¸ {port}ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤\")\n",
    "        print(f\"2ï¸âƒ£ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'í¬íŠ¸' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”\")\n",
    "        \n",
    "        # ìƒˆì°½ì—ì„œ ì—´ê¸°\n",
    "        try:\n",
    "            from google.colab import output\n",
    "            print(\"ğŸ–¥ï¸ ìƒˆì°½ì—ì„œ ChipChatì„ ì—´ ìˆ˜ ìˆëŠ” ë²„íŠ¼ì„ ìƒì„± ì¤‘...\")\n",
    "            output.serve_kernel_port_as_window(port)\n",
    "            print(\"âœ… ìƒˆì°½ ì—´ê¸° ë²„íŠ¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            print(\"ğŸ”˜ ìœ„ì— ë‚˜íƒ€ë‚œ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ìƒˆì°½ì—ì„œ ChipChatì´ ì—´ë¦½ë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ìƒˆì°½ ë²„íŠ¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            print(\"ğŸ’¡ ëŒ€ì‹  ë‹¤ìŒ ë°©ë²•ë“¤ì„ ì‹œë„í•´ë³´ì„¸ìš”:\")\n",
    "            print(f\"   â€¢ ì™¼ìª½ ì‚¬ì´ë“œë°” â†’ 'í¬íŠ¸' íƒ­ â†’ {port} í¬íŠ¸ í´ë¦­\")\n",
    "            print(f\"   â€¢ ì§ì ‘ URL ì ‘ì†: https://localhost:{port} (Colab í™˜ê²½ì—ì„œ)\")\n",
    "    \n",
    "    # í†µí•© ì•± ì‚¬ìš© ì•ˆë‚´\n",
    "    print(f\"\\nğŸ’¡ ChipChat í†µí•© ì•± ì‚¬ìš© ë°©ë²•:\")\n",
    "    print(f\"  â€¢ ğŸ¯ ì•±ì´ ì‹œì‘ë˜ë©´ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”\")\n",
    "    print(f\"  â€¢ âš¡ ê²½ëŸ‰ ëª¨ë“œ: ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥ (ê¸°ë³¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰)\")\n",
    "    print(f\"  â€¢ ğŸ¤– ì „ì²´ ëª¨ë“œ: AI ê¸°ëŠ¥ í¬í•¨ (ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ í•„ìš”)\")\n",
    "    print(f\"  â€¢ ğŸ”„ ì–¸ì œë“ ì§€ ëª¨ë“œ ì „í™˜ ê°€ëŠ¥\")\n",
    "    print(f\"  â€¢ ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœëŠ” ë©”ì¸ í™”ë©´ì—ì„œ í™•ì¸\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâŒ ì„œë²„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ” ê°€ëŠ¥í•œ ì›ì¸:\")\n",
    "    print(\"  â€¢ í•„ìš”í•œ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(\"  â€¢ API í‚¤ ì„¤ì •ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(\"  â€¢ ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"  â€¢ ì•±ì´ ì‹œì‘ë˜ë©´ ê²½ëŸ‰ ëª¨ë“œë¥¼ ë¨¼ì € ì‹œë„í•´ë³´ì„¸ìš”\")\n",
    "    print(\"  â€¢ 2-3ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”\")\n",
    "    print(\"  â€¢ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ê³  ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”\")\n",
    "\n",
    "# í”„ë¡œì„¸ìŠ¤ ì €ì¥ (5ë‹¨ê³„ì—ì„œ ì‚¬ìš©)\n",
    "globals()['streamlit_process'] = process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ›‘ 5ë‹¨ê³„: ì„œë²„ ì¤‘ì§€ { display-mode: \"form\" }\n",
    "#@markdown ì‘ì—…ì„ ë§ˆì¹˜ë©´ ì„œë²„ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "import signal\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# ì„œë²„ ì¤‘ì§€ ì—¬ë¶€ í™•ì¸\n",
    "stop_server = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if stop_server:\n",
    "    print(\"ğŸ›‘ ì„œë²„ ì¢…ë£Œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ngrok í„°ë„ ì¢…ë£Œ (ngrok ì‚¬ìš©í•œ ê²½ìš°ì—ë§Œ)\n",
    "    try:\n",
    "        from pyngrok import ngrok\n",
    "        ngrok.kill()\n",
    "        print(\"âœ… ngrok í„°ë„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸ ngrok ì¢…ë£Œ: {str(e)}\")\n",
    "    \n",
    "    # 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ í”„ë¡œì„¸ìŠ¤ ë¨¼ì € ì¢…ë£Œ\n",
    "    terminated_process = False\n",
    "    if 'streamlit_process' in globals():\n",
    "        try:\n",
    "            process = globals()['streamlit_process']\n",
    "            if process and process.poll() is None:\n",
    "                print(\"ğŸ”„ 4ë‹¨ê³„ì—ì„œ ì‹¤í–‰ëœ Streamlit í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œ ì¤‘...\")\n",
    "                process.terminate()\n",
    "                time.sleep(3)\n",
    "                \n",
    "                if process.poll() is None:\n",
    "                    print(\"âš¡ ê°•ì œ ì¢…ë£Œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "                    process.kill()\n",
    "                    time.sleep(2)\n",
    "                \n",
    "                print(\"âœ… Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                terminated_process = True\n",
    "            else:\n",
    "                print(\"â„¹ï¸ Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # ì¶”ê°€ì ìœ¼ë¡œ ëª¨ë“  streamlit í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ\n",
    "    try:\n",
    "        print(\"ğŸ” ë‚¨ì€ Streamlit í”„ë¡œì„¸ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘...\")\n",
    "        result = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "        if result.stdout.strip():\n",
    "            pids = result.stdout.strip().split('\\n')\n",
    "            print(f\"ğŸ“‹ ë°œê²¬ëœ Streamlit í”„ë¡œì„¸ìŠ¤: {len(pids)}ê°œ\")\n",
    "            \n",
    "            subprocess.run(['pkill', '-f', 'streamlit'], check=False)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            result_after = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n",
    "            if not result_after.stdout.strip():\n",
    "                print(\"âœ… ëª¨ë“  Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ì¼ë¶€ í”„ë¡œì„¸ìŠ¤ê°€ ì—¬ì „íˆ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âœ… ì‹¤í–‰ ì¤‘ì¸ Streamlit í”„ë¡œì„¸ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "        print(\"ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ì—¬ ì„œë²„ë¥¼ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # í¬íŠ¸ ì‚¬ìš© ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        import socket\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        result = sock.connect_ex(('localhost', 8501))\n",
    "        sock.close()\n",
    "        \n",
    "        if result != 0:\n",
    "            print(\"âœ… í¬íŠ¸ 8501ì´ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ í¬íŠ¸ 8501ì´ ì•„ì§ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸ í¬íŠ¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ ì„œë²„ ì¢…ë£Œ ì™„ë£Œ!\")\n",
    "    print(\"ğŸ’¡ ì™„ì „í•œ ì •ë¦¬ë¥¼ ìœ„í•´ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ”„ ëŸ°íƒ€ì„ â†’ ì„¸ì…˜ ì¬ì‹œì‘ì„ í†µí•´ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ì „íˆ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ ì„œë²„ ì¤‘ì§€ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ë¬¸ì œ í•´ê²°\n",
    "\n",
    "**ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°:**\n",
    "\n",
    "1. **API í‚¤ í™•ì¸**: OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "2. **ì„¸ì…˜ ì¬ì‹œì‘**: ëŸ°íƒ€ì„ â†’ ì„¸ì…˜ ì¬ì‹œì‘ í›„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹¤í–‰\n",
    "3. **JSON íŒŒì¼ í™•ì¸**: ì „ì²˜ë¦¬ëœ JSON íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "\n",
    "**ì‚¬ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:**\n",
    "- ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”\n",
    "- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
